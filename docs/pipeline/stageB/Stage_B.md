Below is a comprehensive Stage B design—a “nearly foolproof” neural network architecture to predict RNA torsion angles (α, β, γ, δ, ε, ζ, χ, plus optional sugar pucker) from (1) sequence and (2) 2D adjacency (secondary-structure info) generated by Stage A. It follows Geometric Deep Learning (GDL) principles—representing the RNA chain as a graph with nodes (residues) and edges (base pairs, backbone connections)—and uses a Graph Transformer approach to capture both local and nonlocal interactions. The outline below maps out the concepts, the pseudo code, and the architecture in a cohesive plan.

⸻

1. Domain, Inputs & Outputs

1.1 Inputs
	1.	RNA Sequence
	•	Length N. Each residue is one of \{A,\,C,\,G,\,U\} or a token for modifications.
	2.	2D Adjacency (Base-Pair Matrix) from Stage A
	•	N\times N matrix, e.g. adj[i][j] = \begin{cases}1 & \text{if paired}\\0&\text{otherwise}\end{cases}
	•	Or a real-value [0,1] indicating base-pair probability.
	3.	(Optional) Extra Node/Residue Features
	•	MSA-based profiles or deletion scores if available.
	•	Additional secondary-structure meta (e.g. hairpin loops, non-canonical pairs).

1.2 Outputs

For each residue i, predict the backbone torsion angles:
\alpha_i,\;\beta_i,\;\gamma_i,\;\delta_i,\;\epsilon_i,\;\zeta_i,\;\chi_i
Optionally, also a sugar pucker angle or pseudorotation parameter P_i. Typically these are in [- \pi, \pi].

1.3 Constraints & Goals
	•	Angles are periodic → we must handle wraparound (often with a sine/cosine representation).
	•	Secondary-structure constraints: long-range base pairs, local backbone adjacency, possibly pseudoknots.
	•	Geometric consistency: each angle depends on local neighbors but also distant pairing.

⸻

2. Graph Representation & GDL Principles

We represent the RNA chain as a graph G=(V,E):
	•	Nodes: V = \{1,2,\dots, N\} for the N nucleotides.
	•	Edges:
	1.	Backbone edges: connect i \leftrightarrow i+1.
	2.	Base-pair edges: from the adjacency matrix, connect i \leftrightarrow j if predicted to pair.
	3.	(Optional) Short-range edges for i \leftrightarrow i+2 or i–i+3, if you want more local context.

GDL demands the network be equivariant under node permutations—here, the adjacency is fixed by the chain indexing and base pairing, so we just do local message passing over these edges.

⸻

3. Node & Edge Feature Construction

3.1 Node Features \mathbf{n}_i

For residue i:
	•	Sequence One-Hot: \mathrm{OneHot}(A/C/G/U).
	•	Base-Pair Stats from adjacency: e.g. sum of row i in adj, or “1 if unpaired.”
	•	(Optional) MSA features: average profile or other summary of evolutionary info.

Concatenate all into \mathbf{n}_i \in \mathbb{R}^{d_n}. Then we embed it with a linear layer:
\mathbf{h}_i^{(0)} = \mathrm{Linear}(\mathbf{n}_i).

3.2 Edge Features \mathbf{e}_{ij}

For each edge (i,j):
	•	Base-Pair Probability \text{adj}_{ij}.
	•	Type: “Backbone” vs. “Long-range” (or “canonical pair” vs. “non-canonical”).
	•	Sequence Distance \Delta = |i-j| if relevant (binned or clipped).

Combine into \mathbf{e}{ij}\in \mathbb{R}^{d_e}. Then embed:
\mathbf{g}{ij}^{(0)} = \mathrm{LinearEdge}(\mathbf{e}_{ij}).

⸻

4. Graph Transformer (Multi-Head Attention + Message Passing)

We now process the node embeddings \{\mathbf{h}i\} and edge embeddings \{\mathbf{g}{ij}\} through a stack of L blocks. Each block updates edges from nodes, then updates nodes from edges in a manner akin to “Node->Edge->Node” or an AlphaFold-like “pair-bias attention.”

4.1 Pseudocode Skeleton

Below is a simplified pass:

def GraphTransformer(nodes, edges, adjacency, L=6, c_hidden=128):
    # nodes: [N, d_n], edges: dict((i,j)-> e_ij), adjacency: edge list or adjacency matrix

    # 1) Initial embeddings
    h = Linear(nodes)               # shape [N, c_hidden]
    g = {}
    for (i,j) in adjacency:
        g[(i,j)] = LinearEdge(edges[(i,j)])  # shape [c_edge]

    # 2) Stacking L blocks
    for layer in range(L):
        # (a) Node->Edge update
        for (i,j) in adjacency:
            x_ij = concat(h[i], h[j], g[(i,j)])
            g[(i,j)] += MLP_edge[layer]( x_ij )

        # (b) Edge->Node with multi-head attention
        new_h = zeros_like(h)
        for i in range(N):
            # gather from neighbors
            neighbors = adjacency.neighbors(i) 
            # compute attention scores for j in neighbors
            # apply softmax, then sum up weighted features of h[j], 
            # possibly also using g[(i,j)] as bias
            new_h[i] = h[i] + ...
        
        h = LayerNorm(h + new_h)  # residual

    return h, g

Details:
	•	Edge→Node attention can be done with typical “scaled dot-product” but also add a bias from g[(i,j)].
	•	The “triangle multiplication” or “pairformer” style from AF can be integrated if desired for more advanced geometry capture.

⸻

5. Angle Prediction Head & Loss

5.1 Output Angles

After the final block, each node i has \mathbf{h}_i^{(\mathrm{final})}. We feed it into a small MLP to get either direct angles \hat{\theta}_i\in \mathbb{R}^{7} or a 2D representation:

angles_i = MLP_final(h[i])  # shape [7*2]
# interpret as (sin_alpha, cos_alpha, sin_beta, cos_beta, ...)

Then
\hat{\alpha}i = \mathrm{atan2}\Bigl(\mathrm{sin}\\alpha_i,\;\mathrm{cos}\_\alpha_i\Bigr)
and similarly for the other angles \beta_i, \gamma_i,\dots.

5.2 Loss Function

We compare \hat{\theta}_i with ground-truth \theta_i (extracted from known 3D structures). For each angle, we can do an MSE or SmoothL1 in angle space or in (\sin, cos) space:

L = \frac{1}{N\times 7}\sum_{i=1}^N \sum_{\phi\in\{\alpha,\dots,\chi\}} \bigl[\mathrm{wrap}\!(\hat{\phi}_i - \phi_i)\bigr]^2
where wrap ensures angles remain in [-\pi,\pi].

Optional:
	•	Add a prior term to keep angles near known distributions for A-form RNA.
	•	Or do partial coordinate reconstruction (Stage C) in training for a 3D RMSD-based regularizer.

⸻

6. Training Data & Procedure

6.1 Data Prep
	1.	Gather PDB RNA structures or curated sets.
	2.	For each chain:
	•	Compute torsion angles from 3D coords (using your “torsion_angles.md” method).
	•	Generate adjacency from the ground truth or from your Stage A (RFold). Possibly train on both.
	•	Build node and edge feature arrays.

6.2 Training Steps
	•	Forward Pass: GraphTransformer + final angle head → \hat{\theta}_i.
	•	Loss: MSE on angles or (\sin,\cos) difference.
	•	Optimization: Adam or AdamW, typical LR scheduling.
	•	Validation: measure angle-level MSE on a held-out set, or do a re-build in Stage C → coordinate RMSD check.

⸻

7. Practical Pseudocode (End-to-End)

Below is a more fully integrated snippet combining everything:

########################################
# STAGE B: TORSION PREDICTOR
########################################

import torch
import torch.nn as nn

class TorsionPredictor(nn.Module):
    def __init__(self, d_node, d_edge, c_hidden, n_layers, n_angles=7):
        super().__init__()
        # Embedding layers
        self.node_embed = nn.Linear(d_node, c_hidden)
        self.edge_embed = nn.Linear(d_edge, c_hidden)
        
        # Graph Transformer blocks
        self.blocks = nn.ModuleList([
            GraphTransformerBlock(c_hidden) for _ in range(n_layers)
        ])
        
        # Final angle MLP
        # We output 2 * n_angles if we do sin/cos per angle
        self.out_mlp = nn.Linear(c_hidden, 2*n_angles)
    
    def forward(self, node_feats, edge_feats, adjacency):
        """
        node_feats: [N, d_node]
        edge_feats: dict((i,j)-> [d_edge]) or adjacency matrix
        adjacency: list or set of edges
        """
        N = node_feats.shape[0]
        
        # 1) Node, edge embeddings
        h = self.node_embed(node_feats)  # [N, c_hidden]
        g = {}
        for (i,j) in adjacency:
            g[(i,j)] = self.edge_embed(edge_feats[(i,j)])  # [c_hidden]
        
        # 2) Graph Transformer blocks
        for block in self.blocks:
            h, g = block(h, g, adjacency)
        
        # 3) Predict angles
        angles_out = self.out_mlp(h)   # shape [N, 2*n_angles]
        return angles_out

class GraphTransformerBlock(nn.Module):
    def __init__(self, c_hidden):
        super().__init__()
        # define sub-layers, MLPs, etc.
        self.edge_mlp = nn.Sequential(nn.Linear(3*c_hidden, c_hidden),
                                      nn.ReLU(),
                                      nn.Linear(c_hidden, c_hidden))
        self.node_attn = NodeEdgeAttention(c_hidden)
        self.ln_nodes = nn.LayerNorm(c_hidden)
        self.ln_edges = nn.LayerNorm(c_hidden)
    
    def forward(self, h, g, adjacency):
        # Node->Edge update
        for (i,j) in adjacency:
            # concat node embeddings + current edge embedding
            cat_ij = torch.cat([h[i], h[j], g[(i,j)]], dim=-1)
            g_new = self.edge_mlp(cat_ij)
            g[(i,j)] = self.ln_edges(g[(i,j)] + g_new)
        
        # Edge->Node update with attention
        h_new = self.node_attn(h, g, adjacency)
        h = self.ln_nodes(h + h_new)
        
        return h, g

class NodeEdgeAttention(nn.Module):
    """Example single-head for simplicity. Could do multi-head for more power."""
    def __init__(self, c_hidden):
        super().__init__()
        self.q_proj = nn.Linear(c_hidden, c_hidden)
        self.k_proj = nn.Linear(c_hidden, c_hidden)
        self.v_proj = nn.Linear(c_hidden, c_hidden)
        self.bias_proj = nn.Linear(c_hidden, 1) # to transform edge embedding into scalar bias
        self.out_proj = nn.Linear(c_hidden, c_hidden)
    
    def forward(self, h, g, adjacency):
        N = h.shape[0]
        q = self.q_proj(h)  # [N, c_hidden]
        k = self.k_proj(h)  # [N, c_hidden]
        v = self.v_proj(h)  # [N, c_hidden]
        
        h_out = h.new_zeros(h.shape)
        
        for i in range(N):
            # gather neighbors
            neighbors = adjacency.neighbors(i)
            scores = []
            vs = []
            for j in neighbors:
                # Dot-product
                score_ij = (q[i]*k[j]).sum()
                # Add edge bias
                score_ij += self.bias_proj(g[(i,j)])
                # store
                scores.append(score_ij)
                vs.append(v[j])
            
            # softmax over neighbors
            attn_weights = torch.softmax(torch.stack(scores), dim=0)  # shape [#neighbors]
            
            # Weighted sum
            msg = 0
            for idx, j in enumerate(neighbors):
                msg += attn_weights[idx] * vs[idx]
            
            # transform
            msg = self.out_proj(msg)
            h_out[i] = msg
        
        return h_out

########################################
# ANGLE LOSS EXAMPLE
########################################

def angle_loss(angles_out, angles_true):
    """
    angles_out: [N, 2*n_angles]
      e.g. if n_angles=7, shape is [N,14]
    angles_true: [N, n_angles] in [-pi, pi]
    """
    # reshape angles_out
    # angles_out[i] => sin_alpha, cos_alpha, sin_beta, cos_beta, ...
    
    # convert to predicted angles
    # sin_phi = angles_out[:, 2*k], cos_phi = angles_out[:, 2*k+1]
    # phi_pred = atan2(sin_phi, cos_phi)
    # measure difference with angles_true
    pass

This is a sketch. You can refine to multi-head attention, more sophisticated pairwise interactions, etc.

⸻

8. Why This Approach Is “Nearly Foolproof”
	1.	Graph + Adjacency: Directly encodes base pairs, backbone edges. Permutation-invariant wrt node ordering.
	2.	Local + Global: The Transformer or multi-head design easily merges local backbone constraints with distant base pairs.
	3.	Angle Periodicity: The sine–cosine output and atan2 avoid angle wrapping pitfalls.
	4.	Easy to Scale: The block structure can handle large N with efficient GPU usage.
	5.	Add Physical/Knowledge-based Terms: You can integrate a known distribution prior (e.g. typical A-form angles) or partial coordinate RMSD for extra geometry enforcement.
	6.	Integration with Stage C: Once angles are predicted, you feed them into forward kinematics to get 3D coordinates.

⸻

Final Thoughts

This plan systematically addresses each step:
	•	Domain: an RNA chain as a graph (Stage A adjacency).
	•	Architecture: Graph Transformer layers handle local and long-range edges.
	•	Angle Head: outputs \sin,\cos pairs for each torsion angle.
	•	Loss: angle-based MSE or partial 3D-based.

Following these steps should yield a robust, “foolproof” Stage B Torsion Predictor that harnesses well-established GDL techniques and handles the complexities of RNA 2D→3D angle inference effectively.