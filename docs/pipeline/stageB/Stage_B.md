# ğŸš€ Stage B: Comprehensive RNA Torsion Angle Predictor

---

## ğŸ“Œ Domain, Inputs & Outputs

### ğŸ“¥ Inputs

1. **RNA Sequence**
   - Length: **N** residues
   - Residues: `{A, C, G, U}` or modification tokens

2. **2D Adjacency (Base-Pair Matrix)** (from Stage A)
   - Matrix size: **N Ã— N**
   - Values:
     - Binary (`1` paired, `0` unpaired), or
     - Real-valued probabilities `[0,1]`

3. **Optional Node Features**
   - MSA-based evolutionary profiles
   - Secondary-structure metadata (e.g., hairpin loops, non-canonical pairs)

---

## ğŸ¯ Outputs

For each residue **i**, predict backbone torsion angles:
- Angles: **Î±, Î², Î³, Î´, Îµ, Î¶, Ï‡**
- Optional: **Sugar pucker angle or pseudorotation (Páµ¢)**
  - Range: `[-Ï€, Ï€]`

### ğŸ”§ Constraints & Goals
- **Angle periodicity**: Use sine/cosine representation to manage wraparound
- **Secondary-structure constraints**: base-pairing, backbone continuity, possible pseudoknots
- **Geometric consistency**: influenced by local and distant residues

---

## ğŸŒ Graph Representation & GDL Principles

Represent RNA as graph **G=(V,E)**:
- Nodes (**V**): Residues `{1, 2, ..., N}`
- Edges (**E**):
  1. Backbone edges: **i â†” i+1**
  2. Base-pair edges from adjacency: **i â†” j**
  3. Optional short-range edges: **i â†” i+2**, **i â†” i+3** (enhanced local context)

ğŸ“Œ Equivariant under node permutations (adjacency fixed by indexing & base pairing).

---

## ğŸ§© Node & Edge Feature Construction

### ğŸ”¹ Node Features (**náµ¢**)
- Sequence One-Hot (`A/C/G/U`)
- Base-Pair Stats: Sum row from adjacency; indicator "unpaired"
- Optional: MSA evolutionary profiles

Concatenate and embed:
```
ğ’‰áµ¢â½â°â¾ = Linear(náµ¢)
```

### ğŸ”¸ Edge Features (**eáµ¢â±¼**)
- Base-Pair Probability (`adj[i,j]`)
- Type: **Backbone** vs. **Long-range** (canonical/non-canonical)
- Sequence distance: `|i-j|` (binned/clipped)

Embed edges:
```
ğ’ˆáµ¢â±¼â½â°â¾ = LinearEdge(eáµ¢â±¼)
```

---

## âš™ï¸ Graph Transformer Architecture

Employ **Multi-Head Attention + Message Passing**:

### ğŸ“‹ Detailed Pseudocode

```python
def GraphTransformer(nodes, edges, adjacency, L=6, c_hidden=128):
    h = Linear(nodes)  # [N, c_hidden]
    g = {(i,j): LinearEdge(edges[(i,j)]) for (i,j) in adjacency}

    for layer in range(L):
        # Nodeâ†’Edge update
        for (i,j) in adjacency:
            x_ij = concat(h[i], h[j], g[(i,j)])
            g[(i,j)] += MLP_edge[layer](x_ij)

        # Edgeâ†’Node update (Multi-head Attention)
        new_h = zeros_like(h)
        for i in range(N):
            neighbors = adjacency.neighbors(i)
            attn_scores, vs = [], []
            for j in neighbors:
                score = dot(q_proj(h[i]), k_proj(h[j])) + bias_proj(g[(i,j)])
                attn_scores.append(score)
                vs.append(v_proj(h[j]))
            weights = softmax(attn_scores)
            new_h[i] = sum(weight * vs[j] for j, weight in enumerate(attn_scores))
        h = LayerNorm(h + new_h)

    return h, g
```
- Use edge embedding biases in attention.
- Optional: integrate "pairformer" or AF triangle multiplication.

---

## ğŸ² Angle Prediction Head & Loss

### ğŸ¯ Angle Output
Final node embedding (`háµ¢â½finalâ¾`) via MLP:
```
anglesáµ¢ = MLP_final(h[i])  # [7Ã—2] (sin/cos)
```
Then:
```
Î±áµ¢ = atan2(sin_Î±áµ¢, cos_Î±áµ¢), etc.
```

### ğŸ“ Loss Function
```
L = (1/(NÃ—7)) âˆ‘áµ¢ âˆ‘Ï† [wrap(Î¸Ì‚áµ¢ - Î¸áµ¢)]Â²
```
- Optional:
  - Angle prior (A-form RNA distributions)
  - 3D coordinate-based regularization (Stage C)

---

## ğŸ”§ Configuration (Hydra)

Stage B utilizes Hydra for configuration management, allowing parameters for both TorsionBERT and Pairformer to be specified in YAML files and overridden via the command line.

The configuration is split into two main files located in `rna_predict/conf/model/`:

* `stageB_torsion.yaml`: Configures the TorsionBERT model.
* `stageB_pairformer.yaml`: Configures the Pairformer model.

These are automatically included via the `defaults` list in the main `rna_predict/conf/default.yaml` configuration file.

### Key Configuration Parameters

Below are snippets showing important parameters you can configure:

**TorsionBERT (`rna_predict/conf/model/stageB_torsion.yaml`)**

```yaml
# rna_predict/conf/model/stageB_torsion.yaml
torsion_bert:
  model_name_or_path: "sayby/rna_torsionbert"
  device: "cpu"          # "cpu" or "cuda"
  angle_mode: "sin_cos"  # "sin_cos", "radians", or "degrees"
  num_angles: 7
  max_length: 512
  # ... (LoRA config placeholder)
  lora:
    enabled: false
    # ...
```

**Pairformer (`rna_predict/conf/model/stageB_pairformer.yaml`)**

```yaml
# rna_predict/conf/model/stageB_pairformer.yaml
pairformer:
  n_blocks: 48
  n_heads: 16
  c_z: 128           # Pair representation dimension
  c_s: 384           # Single representation dimension
  dropout: 0.25
  use_memory_efficient_kernel: false
  init_z_from_adjacency: false # Initialize pair features from Stage A adjacency
  use_checkpoint: false        # Enable gradient checkpointing for PairformerStack
  # ... (other params like c_hidden_mul, lora placeholder)
  lora:
    enabled: false
    # ...
```

Refer to the full YAML files for all available options.

### Command-Line Overrides

You can override any parameter from the command line when running the Stage B entry point (`rna_predict.pipeline.stageB.main`). Hydra uses a dot notation to access nested parameters.

**Examples:**

* Run TorsionBERT using 'degrees' angle mode:
    ```bash
    python -m rna_predict.pipeline.stageB.main torsion_bert.angle_mode=degrees
    ```

* Change Pairformer block count:
    ```bash
    python -m rna_predict.pipeline.stageB.main pairformer.n_blocks=24
    ```

* Run on CUDA and use Pairformer memory optimization:
    ```bash
    python -m rna_predict.pipeline.stageB.main torsion_bert.device=cuda pairformer.use_memory_efficient_kernel=true
    ```

* Enable LoRA for TorsionBERT with specific rank:
    ```bash
    python -m rna_predict.pipeline.stageB.main torsion_bert.lora.enabled=true torsion_bert.lora.r=16
    ```

* Initialize Pairformer 'z' embeddings from adjacency matrix:
    ```bash
    python -m rna_predict.pipeline.stageB.main pairformer.init_z_from_adjacency=true
    ```

### HPC Execution

For High Performance Computing (HPC) environments, see the [HPC Integration Guide](../integration/hydra_integration/hpc_overrides.md) for SLURM and GridEngine examples.

**Basic HPC Example:**
```bash
python -m rna_predict.pipeline.stageB.main \
    torsion_bert.device=cuda \
    pairformer.n_blocks=24 \
    +hpc_cluster=slurm \
    hydra.launcher.gpus=1
```

### Typed Configuration (Optional)

For improved validation and type safety, typed dataclasses corresponding to these configurations (e.g., `TorsionBertConfig`, `PairformerConfig`, potentially nested under a `StageBConfig`) may be defined in `rna_predict/conf/config_schema.py`. Refer to that file for details if available.

---

## ï¿½ Training Data & Procedure

### ğŸ—ƒï¸ Data Preparation
- Curate RNA structures (PDB)
- Compute torsion angles & adjacencies
- Assemble node & edge features

### ğŸ“ Training Steps
- Forward pass: GraphTransformer + angle head
- Loss: angle-based MSE or `(sin, cos)` differences
- Optimization: Adam/AdamW, learning rate scheduler
- Validation: angle-level MSE, optional Stageâ€¯C 3D RMSD check

---

## ğŸ Full Python Implementation
Refer to the complete Python implementation provided above, which includes:
- `TorsionPredictor`, `GraphTransformerBlock`, `NodeEdgeAttention`
- Detailed inline comments for clarity
- Fully modular implementation suitable for PyTorch

---

## ğŸ’¡ Why "Nearly Foolproof"?
1. ğŸ“ **Graph Representation**: Explicit pairing & backbone adjacency.
2. ğŸŒ **Local + Global**: Transformer captures interactions at all scales.
3. ğŸ”„ **Angle Periodicity**: Stable sineâ€“cosine encoding.
4. âš¡ **Scalable & Efficient**: Suitable for large datasets.
4. ğŸ“ **Physics-based Priors**: Integrate RNA angle distributions.
5. ğŸ”— **Stageâ€¯C Compatible**: Easily feeds into 3D coordinate reconstruction.

---

## ğŸ–ï¸ Final Thoughts
- Methodically addresses RNA torsion prediction complexities.
- Graph Transformer is flexible, powerful, and scalable.
- Predictive output stable through sine/cosine angle pairs.
- Structured loss function and validation improve robustness.

ğŸ“Œ **Outcome**: Robust, reliable RNA torsion predictor leveraging proven GDL principles.

