The `rna-predict.ipynb` notebook, as described in the context and inferred from the provided file contents and logs, primarily serves as an **inference pipeline** for the Kaggle RNA 3D structure prediction competition. It does not perform model training within the notebook environment but relies on pre-trained models (specifically for Stage B TorsionBERT) loaded from Kaggle datasets or the working directory.

Here's a breakdown of its likely operation and a plan for refactoring it into a simpler, more robust Kaggle wrapper:

**Current Notebook Workflow (Inferred & Contextualized):**

1.  **Environment Setup (Cells 1-4, parts of 12 in the provided notebook example):**
    *   Cleans Kaggle's auto-generated `requirements.txt`.
    *   Lists contents of `/kaggle/input` for an overview of available datasets.
    *   Performs offline installation of Python packages from wheels provided in `/kaggle/input`. This is crucial for Kaggle competitions with internet disabled. The list of packages includes `torch`, `transformers`, `pytorch_lightning`, `hydra-core`, `omegaconf`, `biopython`, `mdanalysis`, and the `rna-predict` package itself.
    *   Sets environment variables like `HF_HUB_OFFLINE=1` to ensure HuggingFace Transformers operate offline.
    *   Creates symbolic links for model checkpoints (e.g., for TorsionBERT and its base DNABERT model) to expected paths in `/kaggle/working/`.

2.  **Core Inference Pipeline (Cells 12, adapted Cell 14 logic):**
    *   **Configuration Loading:** The notebook manually constructs an `OmegaConf` object that mimics the project's Hydra configuration structure (`rna_predict/conf/default.yaml` and `predict.yaml`). Key settings derived from the context and logs include:
        *   `device`: Set to "cpu" or "cuda" based on availability. The provided `dev_run_output.txt` (from `training.py`) indicates the system can detect "mps", but the notebook likely defaults to "cpu" for Kaggle's typical environment unless a GPU is explicitly selected.
        *   `model.stageB.torsion_bert.model_name_or_path`: Points to the local path of the TorsionBERT model (e.g., `/kaggle/working/rna_torsionBERT`).
        *   `model.stageB.torsion_bert.angle_mode`: Set to `"degrees"`.
        *   `model.stageC.method`: Set to `"mp_nerf"`.
        *   `model.stageC.angle_representation`: Set to `"degrees"` (to match Stage B output).
        *   `model.stageC.place_bases`: `True`.
        *   `model.stageC.do_ring_closure`: `True` (as per notebook log context, though `default.yaml` has `False`).
        *   `model.stageC.sugar_pucker`: `"C3'-endo"`.
        *   `prediction.repeats`: `5` (for the 5 required Kaggle predictions).
        *   `prediction.enable_stochastic_inference_for_submission`: `True` (to generate diverse predictions).
        *   `prediction.residue_atom_choice`: This is a critical parameter. The notebook's `create_predictor` cell sets this to `0`. However, for the Kaggle competition (C1' atom), this should be `11` (assuming the atom order from `rna_predict.utils.tensor_utils.types.STANDARD_RNA_ATOMS` where `C1'` is the 12th atom, index 11). This discrepancy is a key point for refactoring.

    *   **Instantiate `RNAPredictor`:** An instance of `RNAPredictor` (from `rna_predict.predict` or `rna_predict.interface`) is created using this manually constructed configuration.

    *   **Load Test Data:** Reads `test_sequences.csv` from `/kaggle/input/stanford-rna-3d-folding/`.

    *   **Iterate and Predict:** For each RNA sequence in the test set:
        *   **Stage B (Torsion Angle Prediction):** `predictor.predict_3d_structure(sequence, stochastic_pass=True, seed=...)` is called. This internally uses `StageBTorsionBertPredictor`.
            *   The TorsionBERT model (`sayby/rna_torsionbert` or a local checkpoint) predicts 7 torsion angles.
            *   The `stochastic_pass=True` enables dropout layers in TorsionBERT, and varying the `seed` across 5 calls generates slightly different angle sets for the 5 required predictions.
            *   The output angles are converted to degrees.
        *   **Stage C (3D Reconstruction):** The predicted torsion angles (in degrees) are passed to `run_stageC` (which internally calls `run_stageC_rna_mpnerf`).
            *   This uses the MP-NeRF based RNA folding logic (`rna_predict.pipeline.stageC.mp_nerf.rna.rna_fold` and `rna_predict.pipeline.stageC.mp_nerf.rna.rna_base_placement`) with standard RNA geometry (from `final_kb_rna.py`).
            *   It reconstructs the 3D coordinates of all atoms for the RNA.
        *   **C1' Atom Extraction:** The coordinates for the C1' atom (or the atom specified by `residue_atom_choice`) of each residue are extracted. This is where the `residue_atom_choice=11` becomes critical. The `RNAPredictor.predict_submission` method uses `reshape_coords` and `extract_atom` for this.

    *   **Assemble Submission:** The C1' coordinates for all 5 predictions for all residues of all test sequences are assembled into a pandas DataFrame. The provided `_collapse_to_one_row_per_residue` (Cell 14 of the notebook) and the logic within `process_test_sequences` (also from Cell 14) handle this, ensuring one row per residue and aligning with the `ID` format (`targetID_resIndex`) from `sample_submission.csv`.

    *   **Save Submission File:** The final DataFrame is saved as `submission.csv`.

3.  **Validation (Cell 16):**
    *   The notebook includes a final cell to perform sanity checks on the generated `submission.csv` against `test_sequences.csv` (e.g., number of rows, missing/extra IDs, per-sequence coverage, column presence, uniqueness of the 5 repeats).

**Analysis of Key Code Components for the Notebook's Workflow:**

*   **`rna_predict.predict.RNAPredictor`:**
    *   `__init__`: Initializes `StageBTorsionBertPredictor` and stores Stage C config.
    *   `predict_3d_structure`: Calls TorsionBERT and then `run_stageC` to get full atom coordinates.
    *   `predict_submission`: This is the main workhorse. It iterates `prediction_config.repeats` times, calling `predict_3d_structure` with `stochastic_pass=True` and a different `seed` each time. It then uses `reshape_coords` and `extract_atom` (with `residue_atom_choice`) to get the specific atom's coordinates, and `coords_to_df` to format them.

*   **`rna_predict.pipeline.stageB.torsion.torsion_bert_predictor.StageBTorsionBertPredictor`:**
    *   Loads the TorsionBERT model and tokenizer.
    *   The `predict_angles_from_sequence` method performs inference. If `stochastic_pass=True`, it sets `self.model.train()` to enable dropout.
    *   The `__call__` method post-processes raw predictions based on `self.angle_mode`. If "degrees", it converts sin/cos outputs (if TorsionBERT outputs them) to degrees. The logs confirm this conversion happens ("Values look like radians, converting to degrees").

*   **`rna_predict.pipeline.stageC.stage_c_reconstruction.run_stageC` and `run_stageC_rna_mpnerf`:**
    *   These functions orchestrate Stage C. `run_stageC_rna_mpnerf` is the core, using `build_scaffolds_rna_from_torsions`, `rna_fold`, and `place_rna_bases` from the `rna_predict.pipeline.stageC.mp_nerf.rna` module.
    *   It takes angles (expected in degrees as per config) and produces 3D atomic coordinates. `atom_metadata` (atom names, residue indices) is also generated here.

*   **`rna_predict.utils.submission`:**
    *   `reshape_coords`: Prepares coordinates for `extract_atom`. If given flat coordinates (all atoms of a sequence), it needs to be able to infer per-residue atom counts or be given coordinates already picked for the target atom. The current version seems to expect either `[N_residues, 1, 3]` (if target atom already picked) or `[N_residues, atoms_per_residue, 3]`.
    *   `extract_atom`: Selects the `atom_idx`-th atom from each residue in a `[N, atoms, 3]` tensor.
    *   `coords_to_df`: Formats the `[N_residues, 3]` C1' coordinates into the multi-column Kaggle submission format.

*   **Configuration Files (`rna_predict/conf/`):**
    *   `default.yaml`: Provides base configurations.
    *   `predict.yaml`: Inherits from `default.yaml` and sets some prediction-specific defaults (e.g., `fast_dev_run=false`).
    *   The notebook's manual config creation largely mirrors `predict.yaml` but explicitly sets `enable_stochastic_inference_for_submission=True` and potentially a different `residue_atom_choice`.

**Refactoring Plan for a Simpler Kaggle Wrapper:**

The existing `RNAPredictor` in `rna_predict.predict.py` is quite close to what's needed. The main issues are ensuring correct configuration (especially `residue_atom_choice`) and streamlining the notebook.

1.  **Simplify Configuration in Notebook:**
    *   Instead of manually building a large OmegaConf object in a notebook cell, the `rna-predict` package should provide a utility function (e.g., in `rna_predict.conf.utils`) to load the default prediction config (`predict.yaml`) and allow targeted overrides.
    *   The notebook would then call:
        ```python
        from rna_predict.conf.utils import get_config, update_config # Assuming get_config exists
        base_cfg = get_config(config_name="predict") 
        
        # Override necessary Kaggle-specific paths and settings
        kaggle_overrides = {
            "device": "cuda" if torch.cuda.is_available() else "cpu",
            "input_csv": "/kaggle/input/stanford-rna-3d-folding/test_sequences.csv",
            "output_dir": "/kaggle/working/", # or a subfolder
            "model.stageB.torsion_bert.model_name_or_path": "/kaggle/input/your-torsionbert-model-dataset/rna_torsionBERT", # Point to Kaggle dataset
            "prediction.residue_atom_choice": 11, # CRITICAL: For C1' atom
            "prediction.enable_stochastic_inference_for_submission": True,
            "prediction.repeats": 5,
            # Potentially set debug_logging to False for cleaner Kaggle logs
            "model.stageB.torsion_bert.debug_logging": False,
            "model.stageC.debug_logging": False,
        }
        cfg = update_config(base_cfg, kaggle_overrides)
        predictor = RNAPredictor(cfg)
        ```

2.  **Ensure C1' Atom Extraction:**
    *   The primary change is setting `cfg.prediction.residue_atom_choice = 11`.
    *   Verify that `rna_predict.pipeline.stageC.mp_nerf.rna.rna_base_placement.place_rna_bases` (called by `run_stageC_rna_mpnerf`) produces `atom_metadata` where the atom names and order allow `extract_atom` with index 11 to reliably pick C1'. `STANDARD_RNA_ATOMS` in `rna_predict.utils.tensor_utils.types` lists "C1'" as the 12th atom (index 11) for all standard bases, which is correct. The `atom_metadata` generated by `run_stageC_rna_mpnerf` uses `STANDARD_RNA_ATOMS` to list atom names, so this should align.

3.  **Use `RNAPredictor.predict_submission` Directly:**
    *   The patched `_predict_submission_patched` in the notebook (Cell 13) is an attempt to handle potentially flat coordinate outputs and prioritizes 'P' atoms. This patch should be **removed**.
    *   The main `RNAPredictor.predict_submission` method in `rna_predict/predict.py` already:
        *   Calls `predict_3d_structure` 5 times with stochasticity.
        *   Uses `reshape_coords` and `extract_atom(..., self.default_atom_choice)` (which will be 11 for C1').
        *   Uses `coords_to_df` to create the multi-column format.
    *   This method should correctly produce a DataFrame with 5 sets of C1' coordinates.

4.  **Streamline Submission Assembly:**
    *   The `process_test_sequences` function (from notebook Cell 14, but adapted) will call the (now correctly configured) `predictor.predict_submission(sequence_string)`.
    *   This will yield a DataFrame for each test sequence. These DataFrames should be concatenated.
    *   The final concatenated DataFrame needs to be merged with `sample_submission.csv` on the `ID` column to ensure correct row order and completeness, then saved.
        ```python
        # Inside process_test_sequences loop
        df_pred_single_sequence = predictor.predict_submission(seq_str)
        # Ensure 'ID' in df_pred_single_sequence matches the Kaggle format targetID_resID
        # (coords_to_df creates 1-based 'resid', RNAPredictor.predict_submission might need to combine with target_id)
        # The current coords_to_df creates ID, resname, resid. The RNAPredictor.predict_submission (if using the patch from notebook)
        # might not format the ID column correctly. If using the original predict_submission, it should be fine.
        # The _collapse_to_one_row_per_residue already handles ID formatting.
        
        # After loop:
        all_predictions_df = pd.concat(list_of_individual_sequence_dfs)
        sample_df = pd.read_csv("/kaggle/input/stanford-rna-3d-folding/sample_submission.csv")
        
        # Merge to ensure correct order and all IDs are present
        # The ID column in all_predictions_df must be correctly formatted as targetID_resID
        submission_df = pd.merge(sample_df[['ID']], all_predictions_df, on='ID', how='left')
        
        # Fill any NaNs in coordinate columns (e.g., if a sequence failed) with 0.0
        coord_cols = [col for col in submission_df.columns if col.startswith(('x_', 'y_', 'z_'))]
        submission_df[coord_cols] = submission_df[coord_cols].fillna(0.0)
        
        submission_df.to_csv("submission.csv", index=False)
        ```

5.  **Training Module (Optional for Inference Notebook):**
    *   The refactoring context mentions a `train_and_evaluate()` module. For a pure Kaggle inference notebook, this is not strictly necessary if using pre-trained models. If training/fine-tuning is desired on Kaggle, `rna_predict/training/train.py` would be the basis, adapted to load Kaggle data and save checkpoints to `/kaggle/working/`.

**Summary of Changes to the Notebook:**

*   **Keep:** Environment setup cells, symlink creation for models.
*   **Modify:**
    *   Configuration: Use a helper to load base config and apply minimal Kaggle-specific overrides, ensuring `prediction.residue_atom_choice = 11`.
    *   Instantiate `RNAPredictor` with this simplified config.
*   **Remove/Replace:**
    *   The custom `_predict_submission_patched` (Cell 13).
    *   The `_collapse_to_one_row_per_residue` can be simplified or integrated into the main loop if `RNAPredictor.predict_submission` is correctly outputting one C1' row per residue with the 5 repeats. The main purpose of `_collapse_to_one_row_per_residue` in the notebook was to handle the 'P' atom selection and ensure one row per residue. With `residue_atom_choice=11`, this should be cleaner.
*   **Adapt:** The main loop in `process_test_sequences` (Cell 14) to call the standard `predictor.predict_submission` and ensure correct `ID` formatting before concatenating and merging with `sample_submission.csv`.

This refactoring makes the notebook a thin wrapper around the core `rna-predict` library, configured for the Kaggle competition's specific requirements (C1' atom, 5 stochastic predictions). It relies on the robustness of `RNAPredictor` and its sub-modules.Okay, let's break down how the `rna-predict.ipynb` notebook likely functions within the project for Kaggle submission and plan its refactoring.

**Understanding the Current Notebook's Inferred Workflow for Kaggle:**

Based on the provided context, the `rna-predict.ipynb` notebook is primarily an **inference pipeline**. It does not perform model training within the Kaggle environment. Its main goal is to take RNA sequences from the competition's test set, predict their 3D structures (specifically, the C1' atom coordinates for each nucleotide), and format these predictions into the required `submission.csv` file.

Here's a step-by-step reconstruction of its operation:

1.  **Environment Setup & Offline Installations:**
    *   The initial cells of a typical Kaggle notebook would handle setting up the environment. This involves:
        *   Cleaning up Kaggle's default `requirements.txt`.
        *   Installing necessary Python packages from pre-downloaded wheel files available in `/kaggle/input/`. This is standard practice for competitions where internet access is disabled during submission runs. Packages would include `torch`, `transformers`, `pytorch_lightning` (though an actual `Trainer` is not used for inference), `hydra-core`, `omegaconf`, `biopython`, `mdanalysis`, and the custom `rna-predict` package itself.
        *   Setting environment variables like `HF_HUB_OFFLINE=1`, `TRANSFORMERS_OFFLINE=1` to ensure HuggingFace libraries don't try to access the internet.
        *   Creating symbolic links: The notebook log mentions `/kaggle/working/rna_torsionBERT`. This implies a pre-trained TorsionBERT model checkpoint is copied or linked from a Kaggle dataset (e.g., from `/kaggle/input/rna-torsion-bert-checkpoint-base/...`) into the working directory where the `RNAPredictor` expects to find it. Similarly for the base DNABERT model (`zhihan1996/DNA_bert_3`).

2.  **Configuration:**
    *   The notebook likely **manually constructs an OmegaConf `DictConfig` object** instead of relying on Hydra's full CLI-based loading (`@hydra.main`). This config object would mirror the structure found in `rna_predict/conf/predict.yaml` and `rna_predict/conf/default.yaml`.
    *   **Key Configuration Settings (inferred from context & logs):**
        *   `device`: Dynamically set to `"cuda"` if available, else `"cpu"`.
        *   `model.stageB.torsion_bert.model_name_or_path`: Path to the local TorsionBERT model checkpoint (e.g., `"/kaggle/working/rna_torsionBERT"`).
        *   `model.stageB.torsion_bert.angle_mode`: Set to `"degrees"` to ensure Stage B outputs angles in degrees.
        *   `model.stageC.method`: `"mp_nerf"` (as confirmed by logs and `mp_nerf.md`).
        *   `model.stageC.angle_representation`: `"degrees"` (to match Stage B's output).
        *   `model.stageC.place_bases`: `True`.
        *   `model.stageC.do_ring_closure`: `True` (from notebook context, though default in `stageC.yaml` is `False`).
        *   `model.stageC.sugar_pucker`: `"C3'-endo"`.
        *   `prediction.repeats`: `5` (Kaggle requires five distinct predictions).
        *   `prediction.enable_stochastic_inference_for_submission`: `True` (This enables dropout in TorsionBERT during inference to generate diverse angle sets for the 5 repeats).
        *   `prediction.residue_atom_choice`: **This is crucial and likely misconfigured in the described notebook.** The Kaggle competition requires C1' atom coordinates. If using the atom order from `rna_predict.utils.tensor_utils.types.STANDARD_RNA_ATOMS`, C1' is at index 11. The notebook log context mentions the toy example used residue atom choice 0 (likely 'P' atom). This needs correction for a valid Kaggle submission.

3.  **Instantiating the Predictor:**
    *   `predictor = RNAPredictor(cfg)` is called, likely using the `RNAPredictor` class from `rna_predict.predict.py` (or `rna_predict.interface.py`).

4.  **Loading Test Data:**
    *   Reads `test_sequences.csv` (e.g., from `/kaggle/input/stanford-rna-3d-folding/test_sequences.csv`) into a pandas DataFrame.

5.  **Iterative Prediction and Submission Assembly:**
    *   The notebook iterates through each sequence in `test_sequences.csv`.
    *   For each sequence:
        *   It calls `predictor.predict_submission(sequence_string)`.
        *   **Inside `RNAPredictor.predict_submission`:**
            *   A loop runs `prediction.repeats` (i.e., 5) times.
            *   In each iteration, `self.predict_3d_structure(sequence, stochastic_pass=True, seed=iteration_seed)` is called.
                *   **Stage B (`StageBTorsionBertPredictor`):**
                    *   Takes the RNA sequence.
                    *   `stochastic_pass=True` sets the TorsionBERT model to `train()` mode, enabling dropout layers. Combined with a different `seed` for each of the 5 calls, this generates slightly varied torsion angle predictions.
                    *   Outputs torsion angles. The log context ("Values look like radians, converting to degrees") and the configured `angle_mode="degrees"` indicate that `StageBTorsionBertPredictor` handles the conversion to degrees.
                *   **Stage C (`run_stageC` using `run_stageC_rna_mpnerf`):**
                    *   Takes the (varied) degree-based torsion angles from Stage B.
                    *   Uses the MP-NeRF based RNA folding logic (from `rna_predict.pipeline.stageC.mp_nerf.rna`) and standard RNA geometry (from `final_kb_rna.py`) to reconstruct full 3D atomic coordinates.
                    *   Returns `coords` (flattened coordinates for all valid atoms) and `atom_metadata` (atom names and residue indices per atom).
            *   After the 5 calls to `predict_3d_structure`, `predict_submission` has 5 sets of full atomic coordinates.
            *   It then uses `reshape_coords` and `extract_atom(coords, atom_idx=cfg.prediction.residue_atom_choice)` to select the coordinates of the **C1' atom (index 11)** for each residue from each of the 5 predicted structures.
            *   Finally, `coords_to_df` formats these 5 sets of C1' coordinates into a DataFrame with columns like `ID, resname, resid, x_1, y_1, z_1, ..., x_5, y_5, z_5`.
        *   The DataFrames resulting from `predictor.predict_submission` for each test sequence are collected.

6.  **Finalizing and Saving `submission.csv`:**
    *   All individual sequence DataFrames are concatenated.
    *   This combined DataFrame is then merged with `sample_submission.csv` (usually on the `ID` column) to ensure the row order and exact set of IDs match the competition's template.
    *   Any missing coordinate values (e.g., if a prediction failed for a residue) are typically filled with `0.0`.
    *   The resulting DataFrame is saved to `/kaggle/working/submission.csv`.
    *   A final sanity check (like Cell 16 in the notebook example) might be run to compare row counts and ID sets with the sample submission.

**Key Code Components Involved:**

*   **`rna_predict.predict.RNAPredictor`**: The main class orchestrating inference.
*   **`rna_predict.pipeline.stageB.torsion.torsion_bert_predictor.StageBTorsionBertPredictor`**: Handles TorsionBERT model loading and angle prediction, including stochastic inference.
*   **`rna_predict.pipeline.stageC.stage_c_reconstruction.run_stageC` (and `run_stageC_rna_mpnerf`)**: Performs 3D reconstruction from angles using MP-NeRF logic.
    *   Relies on: `rna_predict.pipeline.stageC.mp_nerf.rna.rna_fold`, `rna_predict.pipeline.stageC.mp_nerf.rna.rna_base_placement`, `rna_predict.pipeline.stageC.mp_nerf.final_kb_rna.py`.
*   **`rna_predict.utils.submission` (`reshape_coords`, `extract_atom`, `coords_to_df`)**: Utilities for processing coordinates and formatting the submission DataFrame.
*   **`rna_predict.utils.tensor_utils.types.STANDARD_RNA_ATOMS`**: Defines the atom order, crucial for `residue_atom_choice`.
*   **Configuration files in `rna_predict/conf/`**: Define default parameters, overridden by the notebook.

**Plan for Refactoring into a Simpler Kaggle Wrapper:**

The goal is a clean, straightforward Kaggle notebook that uses the `rna-predict` package effectively.

1.  **Environment Setup Cell:**
    *   Keep the offline package installation logic (`%%bash` cell similar to Cell 3 of the notebook example).
    *   Keep symbolic link creation for models (part of Cell 12).
    *   Keep offline mode settings for HuggingFace (part of Cell 12).

2.  **Configuration Cell:**
    *   **Replace manual OmegaConf creation.** Instead, use a utility from `rna_predict.conf.utils` (e.g., `get_config` and `update_config` if they exist, or create a simpler helper).
    *   Load a base configuration (e.g., `predict.yaml`).
    *   Programmatically override essential Kaggle-specific parameters:
        *   `input_csv`: Path to `test_sequences.csv`.
        *   `output_dir`: `/kaggle/working/`.
        *   `model.stageB.torsion_bert.model_name_or_path`: Path to the model in `/kaggle/input/...`.
        *   `device`: Auto-detected (`cuda` or `cpu`).
        *   **`prediction.residue_atom_choice = 11`**: **This is the most critical fix to target C1' atoms.**
        *   `prediction.enable_stochastic_inference_for_submission = True`.
        *   `prediction.repeats = 5`.
        *   Set `debug_logging` flags in various modules to `False` for cleaner Kaggle output.

3.  **Main Prediction Cell:**
    *   Import `RNAPredictor` from `rna_predict.predict`.
    *   Import `pandas`.
    *   Load `test_sequences.csv`.
    *   Instantiate `predictor = RNAPredictor(cfg)`.
    *   Create an empty list `all_sequence_predictions = []`.
    *   Loop through each row in `test_sequences_df`:
        *   Get `target_id` and `sequence_string`.
        *   Call `df_one_sequence = predictor.predict_submission(sequence_string)`.
            *   This call internally handles the 5 stochastic repeats and C1' extraction.
            *   It should return a DataFrame already formatted by `coords_to_df` with columns `ID, resname, resid, x_1, y_1, z_1, ..., x_5, y_5, z_5`.
            *   **Crucially, ensure the `ID` column in `df_one_sequence` is correctly formatted as `target_id + "_" + residue_index`**. The `coords_to_df` function currently creates an `ID` column that is just the 1-based residue index. This needs to be prefixed with `target_id + "_"` after `coords_to_df` is called, likely within `RNAPredictor.predict_submission` or immediately after.
        *   Append `df_one_sequence` to `all_sequence_predictions`.
    *   Concatenate all DataFrames: `final_predictions_df = pd.concat(all_sequence_predictions, ignore_index=True)`.
    *   Load `sample_submission.csv`.
    *   Merge to align order and ensure completeness:
        ```python
        sample_df = pd.read_csv("/kaggle/input/stanford-rna-3d-folding/sample_submission.csv")
        submission_df = pd.merge(sample_df[['ID']], final_predictions_df, on='ID', how='left')
        # Fill NaN coordinates that might arise from failed predictions for some residues/targets
        coord_cols = [col for col in submission_df.columns if col.startswith(('x_', 'y_', 'z_'))]
        submission_df[coord_cols] = submission_df[coord_cols].fillna(0.0)
        # Ensure all columns from sample_submission are present
        for col in sample_df.columns:
            if col not in submission_df.columns:
                 submission_df[col] = np.nan # Or appropriate default
        submission_df = submission_df[sample_df.columns] # Enforce column order
        ```
    *   Save: `submission_df.to_csv("submission.csv", index=False)`.
    *   Print success message and head of the submission file.

4.  **Remove Unnecessary Patches/Cells:**
    *   The custom `_predict_submission_patched` (Cell 13) and `_collapse_to_one_row_per_residue` (Cell 14) from the notebook example become redundant if `RNAPredictor` is correctly configured and its `predict_submission` method robustly handles C1' extraction and formatting. The original `RNAPredictor.predict_submission` in `rna_predict.predict` should be the source of truth, modified if necessary to correctly format the `ID` column.

5.  **Optional Training/Evaluation Module:**
    *   For a pure inference wrapper, the training/evaluation cells (Cells 5-9 in the notebook example, which seem to be for a different XGBoost model unrelated to the RNA_PREDICT pipeline) would be removed or commented out. If actual RNA_PREDICT model training is desired on Kaggle, it would be a separate, more involved notebook using `rna_predict.training.train.py` as a basis.

**Benefits of this Refactoring:**

*   **Simplicity:** The notebook becomes much cleaner, focusing on setup, configuration, and invoking the main prediction logic.
*   **Maintainability:** Core logic resides in the `rna-predict` Python package, making updates easier.
*   **Correctness:** Directly addresses the C1' atom requirement and leverages the existing stochastic prediction mechanism.
*   **Modularity:** Follows the existing plan to separate inference, (optional) training, and submission generation.

This plan ensures that the Kaggle notebook acts as a lightweight, correctly configured interface to the more complex `rna-predict` library, producing a valid submission file. The critical fix is setting `prediction.residue_atom_choice = 11` and ensuring the `ID` column in the output of `predict_submission` is correctly formatted for merging with `sample_submission.csv`.
======
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":87793,"databundleVersionId":12276181,"sourceType":"competition"},{"sourceId":5942070,"sourceType":"datasetVersion","datasetId":3410079},{"sourceId":11026565,"sourceType":"datasetVersion","datasetId":6866703},{"sourceId":11762635,"sourceType":"datasetVersion","datasetId":7384470},{"sourceId":11787394,"sourceType":"datasetVersion","datasetId":7401070},{"sourceId":11787916,"sourceType":"datasetVersion","datasetId":7401477},{"sourceId":11788332,"sourceType":"datasetVersion","datasetId":7401777},{"sourceId":11788337,"sourceType":"datasetVersion","datasetId":7401782},{"sourceId":11788349,"sourceType":"datasetVersion","datasetId":7401791},{"sourceId":11788362,"sourceType":"datasetVersion","datasetId":7401801},{"sourceId":11788374,"sourceType":"datasetVersion","datasetId":7401810},{"sourceId":11788377,"sourceType":"datasetVersion","datasetId":7401813},{"sourceId":11788382,"sourceType":"datasetVersion","datasetId":7401817},{"sourceId":11788386,"sourceType":"datasetVersion","datasetId":7401820},{"sourceId":11788388,"sourceType":"datasetVersion","datasetId":7401822},{"sourceId":11788390,"sourceType":"datasetVersion","datasetId":7401824},{"sourceId":11788491,"sourceType":"datasetVersion","datasetId":7401888},{"sourceId":11788496,"sourceType":"datasetVersion","datasetId":7401891},{"sourceId":11788500,"sourceType":"datasetVersion","datasetId":7401893},{"sourceId":11788503,"sourceType":"datasetVersion","datasetId":7401896},{"sourceId":11788505,"sourceType":"datasetVersion","datasetId":7401898},{"sourceId":11788513,"sourceType":"datasetVersion","datasetId":7401905},{"sourceId":11788517,"sourceType":"datasetVersion","datasetId":7401907},{"sourceId":11788524,"sourceType":"datasetVersion","datasetId":7401913},{"sourceId":11788527,"sourceType":"datasetVersion","datasetId":7401915},{"sourceId":11788542,"sourceType":"datasetVersion","datasetId":7401925},{"sourceId":11788545,"sourceType":"datasetVersion","datasetId":7401927},{"sourceId":11788551,"sourceType":"datasetVersion","datasetId":7401929},{"sourceId":11788558,"sourceType":"datasetVersion","datasetId":7401931},{"sourceId":11788622,"sourceType":"datasetVersion","datasetId":7401980},{"sourceId":11788630,"sourceType":"datasetVersion","datasetId":7401890},{"sourceId":11788641,"sourceType":"datasetVersion","datasetId":7401995},{"sourceId":11788656,"sourceType":"datasetVersion","datasetId":7401827},{"sourceId":11814119,"sourceType":"datasetVersion","datasetId":7420372},{"sourceId":11814128,"sourceType":"datasetVersion","datasetId":7420378},{"sourceId":11814137,"sourceType":"datasetVersion","datasetId":7401990},{"sourceId":11814142,"sourceType":"datasetVersion","datasetId":7420389},{"sourceId":11814146,"sourceType":"datasetVersion","datasetId":7420392},{"sourceId":11814150,"sourceType":"datasetVersion","datasetId":7420395},{"sourceId":11814170,"sourceType":"datasetVersion","datasetId":7420409},{"sourceId":11814175,"sourceType":"datasetVersion","datasetId":7420413},{"sourceId":11814180,"sourceType":"datasetVersion","datasetId":7420416},{"sourceId":11814187,"sourceType":"datasetVersion","datasetId":7420420},{"sourceId":11814259,"sourceType":"datasetVersion","datasetId":7420472},{"sourceId":11814267,"sourceType":"datasetVersion","datasetId":7420479},{"sourceId":11814282,"sourceType":"datasetVersion","datasetId":7420492},{"sourceId":11814553,"sourceType":"datasetVersion","datasetId":7420638},{"sourceId":11831012,"sourceType":"datasetVersion","datasetId":6866398}],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Cell : clean auto-generated requirements file  (run FIRST!)\n# -----------------------------------------------------------\nimport pathlib, shutil, re, textwrap, sys, os\n\nREQ_PATH = pathlib.Path(\"/kaggle/requirements/input_requirements.txt\")\nif REQ_PATH.is_file():\n    cleaned_lines = []\n    for line in REQ_PATH.read_text().splitlines():\n        line = line.strip()\n        if not line or line.startswith(\"#\"):\n            continue                    # â† drop blanks / comments\n        if not line.startswith(\"pip install\"):\n            # keep it but comment it out so the helper ignores it\n            line = f\"# {line}\"\n        cleaned_lines.append(line)\n\n    REQ_PATH.write_text(\"\\n\".join(cleaned_lines) + (\"\\n\" if cleaned_lines else \"\"))\n\n    print(f\"[INFO] requirements cleaned â€“ {len(cleaned_lines)} valid \"\n          f\"pip-install line(s) kept.\")\nelse:\n    print(f\"[INFO] {REQ_PATH} not found â€“ nothing to clean.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:02:29.551618Z","iopub.execute_input":"2025-05-16T19:02:29.552081Z","iopub.status.idle":"2025-05-16T19:02:29.560720Z","shell.execute_reply.started":"2025-05-16T19:02:29.552014Z","shell.execute_reply":"2025-05-16T19:02:29.559195Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%bash\n# Cell: show whatâ€™s inside every mounted Kaggle dataset  ğŸ”\n# --------------------------------------------------------\necho -e \"\\nğŸ“‚  Listing the first two levels of /kaggle/input â€¦\\n\"\n\n# Change depth (-maxdepth) if you want more or fewer levels\nfind /kaggle/input -maxdepth 2 -mindepth 1 -print | sed 's|^|  |'\n\necho -e \"\\nâœ…  Done.\\n\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:02:29.562448Z","iopub.execute_input":"2025-05-16T19:02:29.562808Z","iopub.status.idle":"2025-05-16T19:02:29.661765Z","shell.execute_reply.started":"2025-05-16T19:02:29.562770Z","shell.execute_reply":"2025-05-16T19:02:29.660349Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%bash\n# Cell : offline installs that match the *current* wheel set (lean version)\n# -----------------------------------------------------------------------\nset -euo pipefail\n\n# â”€â”€ let pip look inside EVERY sub-folder of /kaggle/input â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nWHEEL_ROOT=\"/kaggle/input\"\nFIND_LINKS_ARGS=\"\"\nfor d in \"$WHEEL_ROOT\" \"$WHEEL_ROOT\"/*; do\n  FIND_LINKS_ARGS+=\" --find-links $d\"\ndone\n\np () {                 # quiet install; warn (donâ€™t die) if something fails\n  # shellcheck disable=SC2086\n  pip install --no-index $FIND_LINKS_ARGS --quiet \"$@\" \\\n  || echo \"[WARN] install failed â†’ skipped: $*\"\n}\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# 1) Core scientific stack\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\np numpy==1.24.3\np pandas==2.2.3\np scipy==1.10.1\np tqdm==4.67.1\np seaborn==0.12.2\np biopython==1.85\np torch               # pre-installed in the Kaggle image\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# 2)  ML / NLP stack\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\np huggingface_hub==0.31.1      # needs hf-xet (you already uploaded)\np transformers==4.51.3\np pytorch_lightning==2.5.0.post0   # gives us Lightning-core features\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# 3)  Extra deps *rna_predict* really imports\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\np lightning-utilities==0.11.2  # comes with PL wheel but list explicitly\np datasets==3.6.0\np einops==0.8.1\np hypothesis==6.131.15\np black==25.1.0                # needs pathspec 0.12.1 â†’ you uploaded both\np pathspec==0.12.1\np isort==6.0.1\np ruff==0.11.9\np mss==10.0.0\np mdanalysis==2.9.0\np mmtf-python==1.1.3\np GridDataFormats==1.0.2\np mrcfile==1.5.4\np lxml==5.4.0\np dearpygui==2.0.0\np py-cpuinfo==9.0.0\np Pillow                        # pillow-11-2-1 wheel present\np exit-codes==1.3.0             # small helper used by HF-Hub 0.31+\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# 4)  Config utilities\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\np hydra-core==1.3.2\np omegaconf==2.3.0\np ml_collections==1.1.0         # required by Protenix\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# 5)  rna-predict itself  (no-deps so nothing reaches PyPI)\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\npip install --no-index --no-deps --quiet \\\n  /kaggle/input/rna-structure-predict/rna_predict-2.0.3-py3-none-any.whl\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# 6)  Protenix 0.4.6  (wheel, but ignore its heavy deps like RDKit)\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\npip install --no-index --no-deps --quiet \\\n  /kaggle/input/protenix-0-4-6/protenix-0.4.6-py3-none-any.whl \\\n  || echo \"[WARN] Protenix wheel install failed.\"\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# 7)  Runtime shim: make â€œimport lightningâ€ point to pytorch_lightning\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\npython - <<'PY'\nimport sys, importlib, types\ntry:\n    import pytorch_lightning as pl\n    sys.modules.setdefault(\"lightning\", pl)\nexcept ImportError:\n    print(\"[WARN] pytorch_lightning missing â€“ shim not created\")\nPY\n\necho \"âœ…  Offline wheel install phase complete.\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:02:29.665786Z","iopub.execute_input":"2025-05-16T19:02:29.666432Z","iopub.status.idle":"2025-05-16T19:05:08.009084Z","shell.execute_reply.started":"2025-05-16T19:02:29.666376Z","shell.execute_reply":"2025-05-16T19:05:08.008145Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ---\n# Cell: ALL-IN-ONE Environment Setup  (no uninstalls, no online pip)\n# ---\n\nimport sys, subprocess, shutil, os, platform\n\ndef run_and_print(cmd):\n    res = subprocess.run(cmd, capture_output=True, text=True)\n    print(res.stdout, end=\"\")\n    if res.stderr:\n        print(res.stderr, end=\"\")\n\n# â•â•â•â•â•â• 1)  System information (unchanged) â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nprint(\"\\n=== [System Information] ===\")\n\nprint(\"\\n[Python Version]\")\nprint(sys.version)\n\nprint(\"\\n[Kernel and OS Information]\")\nrun_and_print([\"uname\", \"-a\"])\n\nprint(\"\\n[CPU Information]\")\nrun_and_print([\"lscpu\"])\n\nprint(\"\\n[Memory Information]\")\nrun_and_print([\"free\", \"-mh\"])\n\nprint(\"\\n[Disk Information]\")\nrun_and_print([\"lsblk\"])\n\nprint(\"\\n=== [End of System Information] ===\\n\")\n\n# â•â•â•â•â•â• 2)  USER CONFIG  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nRNA_PREDICT_VERSION   = \"2.0.3\"\nBLOCK_SPARSE_WHEEL_IN = (\n    \"/kaggle/input/block-sparse-wheels/\"\n    \"block_sparse_attn-0.0.1cu118torch2.0cxx11abiTRUE-\"\n    \"cp310-cp310-linux_x86_64.whl\"\n)\n# PEP 440-compliant rename (Torch version tag trimmed)\nBLOCK_SPARSE_WHEEL_OUT = (\n    \"/kaggle/working/\"\n    \"block_sparse_attn-0.0.1+cu118torch2.0-\"\n    \"cp310-cp310-linux_x86_64.whl\"\n)\n\n# â•â•â•â•â•â• 3)  Environment-fix helper  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\ndef setup_environment():\n    \"\"\"\n    â‘  Ensure Seaborn (and its deps) is present\n    â‘¡ Copy & install block_sparse_attn wheel   â† optional; see note below\n    â‘¢ Install rna_predict\n    â‘£ Install hydra-core from local wheel\n    â‘¤ Show final versions of key packages\n    \"\"\"\n    # â‘  Make sure Seaborn is available â€“\n    #    Kaggle base image already has 0.12.2 but we pin it explicitly:\n    print(\"[INFO] Making sure Seaborn is installedâ€¦\\n\")\n    run_and_print([\"pip\", \"install\", \"--quiet\", \"seaborn==0.12.2\"])\n\n    # â‘¡ Copy & (optionally) install block_sparse_attn\n    if os.path.exists(BLOCK_SPARSE_WHEEL_IN):\n        try:\n            shutil.copyfile(BLOCK_SPARSE_WHEEL_IN, BLOCK_SPARSE_WHEEL_OUT)\n            print(\"\\n[INFO] Copied block-sparse-attn wheel to working dir.\")\n            print(\"[INFO] Installing block-sparse-attn (no deps)â€¦\\n\")\n            run_and_print([\"pip\", \"install\", \"--no-deps\", \"--quiet\", BLOCK_SPARSE_WHEEL_OUT])\n        except Exception as e:\n            print(f\"[WARN] Could not copy/install block-sparse wheel: {e}\")\n            print(\"       Continue without it if your code doesnâ€™t need it.\")\n    else:\n        print(\"[WARN] block-sparse-attn wheel not found in /kaggle/input â€“ skipped.\")\n\n    # â‘¢ Install rna_predict (pure-py, so --no-deps is fine)\n    rnapred_whl = f\"/kaggle/input/rna-structure-predict/\" \\\n                  f\"rna_predict-{RNA_PREDICT_VERSION}-py3-none-any.whl\"\n    if os.path.exists(rnapred_whl):\n        print(f\"\\n[INFO] Installing rna_predict {RNA_PREDICT_VERSION} â€¦\\n\")\n        run_and_print([\"pip\", \"install\", \"--no-deps\", \"--quiet\", rnapred_whl])\n    else:\n        print(f\"[WARN] {rnapred_whl} not found â€“ skipped.\")\n\n    # â‘£ Install hydra-core from local wheel\n    HYDRA_DIR = \"/kaggle/input/hydra-core-132whl\"\n    if os.path.isdir(HYDRA_DIR):\n        wheels = [f for f in os.listdir(HYDRA_DIR) if f.endswith(\".whl\")]\n        if wheels:\n            for whl in wheels:\n                whl_path = os.path.join(HYDRA_DIR, whl)\n                print(f\"\\n[INFO] Installing hydra-core from {whl_path} â€¦\\n\")\n                run_and_print([\"pip\", \"install\", \"--no-deps\", \"--quiet\", whl_path])\n        else:\n            print(f\"[WARN] No .whl files found in {HYDRA_DIR} â€“ skipped.\")\n    else:\n        print(f\"[WARN] {HYDRA_DIR} not found â€“ skipped.\")\n\n    # â‘¤ Show final versions\n    print(\"\\n=== [Final Package Versions] ===\")\n    for pkg in [\n        \"torch\", \"block-sparse-attn\", \"rna-predict\",\n        \"hydra-core\", \"numpy\", \"scipy\", \"scikit-learn\", \"seaborn\"\n    ]:\n        run_and_print([\"pip\", \"show\", pkg])\n    print(\"=== [End of Final Package Versions] ===\\n\")\n\n# â•â•â•â•â•â• 4)  Run it  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nsetup_environment()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:05:08.010711Z","iopub.execute_input":"2025-05-16T19:05:08.011020Z","iopub.status.idle":"2025-05-16T19:05:51.408073Z","shell.execute_reply.started":"2025-05-16T19:05:08.010992Z","shell.execute_reply":"2025-05-16T19:05:51.406853Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -*- coding: utf-8 -*-\n\"\"\"\nCell 1: ENVIRONMENT SETUP & LOGGING\n-----------------------------------\n\"\"\"\nimport os\nimport sys\nimport logging\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Machine Learning Libraries\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\n\n\n# Logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s [%(levelname)s] %(message)s',\n    handlers=[logging.StreamHandler(sys.stdout)]\n)\nlogging.info(\"Cell 1 complete: Libraries imported and logging initialized.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:05:51.409308Z","iopub.execute_input":"2025-05-16T19:05:51.409608Z","iopub.status.idle":"2025-05-16T19:05:51.416335Z","shell.execute_reply.started":"2025-05-16T19:05:51.409579Z","shell.execute_reply":"2025-05-16T19:05:51.414995Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nCell 2: DATA IMPORT\n-------------------\nHere, we read in train/validation/test CSVs and a sample submission from the Kaggle environment.\nAdjust the paths if needed for your environment.\n\"\"\"\n\n# Example file paths\nTRAIN_SEQUENCES_PATH = \"/kaggle/input/stanford-rna-3d-folding/train_sequences.csv\"\nTRAIN_LABELS_PATH    = \"/kaggle/input/stanford-rna-3d-folding/train_labels.csv\"\nVALID_SEQUENCES_PATH = \"/kaggle/input/stanford-rna-3d-folding/validation_sequences.csv\"\nVALID_LABELS_PATH    = \"/kaggle/input/stanford-rna-3d-folding/validation_labels.csv\"\nTEST_SEQUENCES_PATH  = \"/kaggle/input/stanford-rna-3d-folding/test_sequences.csv\"\nSAMPLE_SUB_PATH      = \"/kaggle/input/stanford-rna-3d-folding/sample_submission.csv\"\n\ntry:\n    train_sequences = pd.read_csv(TRAIN_SEQUENCES_PATH)\n    train_labels = pd.read_csv(TRAIN_LABELS_PATH)\n    validation_sequences = pd.read_csv(VALID_SEQUENCES_PATH)\n    validation_labels = pd.read_csv(VALID_LABELS_PATH)\n    test_sequences = pd.read_csv(TEST_SEQUENCES_PATH)\n    sample_submission = pd.read_csv(SAMPLE_SUB_PATH)\n\n    logging.info(\"Cell 2 complete: Data loaded successfully.\")\nexcept Exception as e:\n    logging.error(f\"Error loading data: {e}\")\n    sys.exit(1)\n\nlogging.info(f\"train_sequences: {train_sequences.shape}, train_labels: {train_labels.shape}\")\nlogging.info(f\"validation_sequences: {validation_sequences.shape}, validation_labels: {validation_labels.shape}\")\nlogging.info(f\"test_sequences: {test_sequences.shape}, sample_submission: {sample_submission.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:05:51.417642Z","iopub.execute_input":"2025-05-16T19:05:51.418020Z","iopub.status.idle":"2025-05-16T19:05:51.764659Z","shell.execute_reply.started":"2025-05-16T19:05:51.417969Z","shell.execute_reply":"2025-05-16T19:05:51.763287Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nCell 3: COMBINE TRAIN + VALIDATION & BASIC EDA\n----------------------------------------------\nWe concatenate the train and validation sets to maximize data. \nThen we do a quick EDA check on shapes, missingness, etc.\n\"\"\"\n\n# Combine sequences and labels\ntrainval_sequences = pd.concat([train_sequences, validation_sequences], ignore_index=True)\ntrainval_labels = pd.concat([train_labels, validation_labels], ignore_index=True)\n\nlogging.info(f\"Combined train+validation sequences: {trainval_sequences.shape}, labels: {trainval_labels.shape}\")\n\n# Quick check for missing\nlogging.info(\"Missing in combined sequences:\\n\" + str(trainval_sequences.isnull().sum()))\nlogging.info(\"Missing in combined labels:\\n\" + str(trainval_labels.isnull().sum()))\n\n# Example EDA: sequence length distribution\ntrainval_sequences['sequence_length'] = trainval_sequences['sequence'].str.len()\n\nplt.figure(figsize=(10,4))\nsns.boxplot(x=trainval_sequences['sequence_length'], color='skyblue')\nplt.title(\"Boxplot of Sequence Length (Train + Validation)\")\nplt.xlabel(\"Sequence Length\")\nplt.show()\n\nlogging.info(\"Cell 3 complete: Basic EDA finished.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:05:51.766234Z","iopub.execute_input":"2025-05-16T19:05:51.766825Z","iopub.status.idle":"2025-05-16T19:05:52.188571Z","shell.execute_reply.started":"2025-05-16T19:05:51.766785Z","shell.execute_reply":"2025-05-16T19:05:52.187427Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nCell 4: HANDLE MISSING COORDINATES & MERGE\n------------------------------------------\nWe replace '-1e18' with np.nan, then merge sequences with labels on target_id.\n\"\"\"\n\n# Replace -1e18 with np.nan in the labels\nfor col in ['x_1','y_1','z_1']:\n    trainval_labels[col] = trainval_labels[col].replace(-1e18, np.nan)\n\nlogging.info(\"Replaced -1e18 with NaN in trainval_labels for x_1, y_1, z_1.\")\n\n# Extract pdb_id, chain_id from ID\ntrainval_labels['pdb_id']   = trainval_labels['ID'].apply(lambda x: x.split('_')[0])\ntrainval_labels['chain_id'] = trainval_labels['ID'].apply(lambda x: x.split('_')[1])\ntrainval_labels['target_id'] = trainval_labels['pdb_id'] + \"_\" + trainval_labels['chain_id']\n\n# Merge\ntrain_data = pd.merge(trainval_labels, trainval_sequences, on='target_id', how='left')\nlogging.info(f\"Merged train_data shape: {train_data.shape}\")\n\n# Quick check\nlogging.info(f\"Missing in x_1: {train_data['x_1'].isnull().sum()}, \"\n             f\"y_1: {train_data['y_1'].isnull().sum()}, \"\n             f\"z_1: {train_data['z_1'].isnull().sum()}\")\n\nlogging.info(\"Cell 4 complete: Merged train_data, ready for group-based imputation.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:05:52.191954Z","iopub.execute_input":"2025-05-16T19:05:52.192298Z","iopub.status.idle":"2025-05-16T19:05:52.663563Z","shell.execute_reply.started":"2025-05-16T19:05:52.192266Z","shell.execute_reply":"2025-05-16T19:05:52.662206Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nCell 5: FEATURE ENGINEERING\n---------------------------\nCreate numerical/categorical features from the 'sequence'.\nWe'll keep 'resname' from the labels as a valuable feature.\n\"\"\"\n\ndef engineer_features(df):\n    \"\"\"\n    Create numerical & (some) categorical features from raw RNA sequence data.\n    \"\"\"\n    df = df.copy()\n    # Sequence-based\n    df['seq_length'] = df['sequence'].str.len()\n    df['A_cnt'] = df['sequence'].str.count('A')\n    df['C_cnt'] = df['sequence'].str.count('C')\n    df['G_cnt'] = df['sequence'].str.count('G')\n    df['U_cnt'] = df['sequence'].str.count('U')\n    df['begin_seq'] = df['sequence'].str[0]\n    df['end_seq']   = df['sequence'].str[-1]\n    \n    # Di-nucleotide counts (example set)\n    for pair in ['AC','AG','AU','CA','CG','CU','GA','GC','GU','UA','UC','UG',\n                 'AA','CC','GG','UU']:\n        df[f'{pair}_cnt'] = df['sequence'].str.count(pair)\n\n    return df\n\n# Apply feature engineering\ntrain_data = engineer_features(train_data)\n\nlogging.info(\"Feature engineering applied to merged train_data.\")\n\n# We'll show an example of newly added columns\nexample_cols = ['seq_length','A_cnt','C_cnt','G_cnt','U_cnt','begin_seq','end_seq','AC_cnt','AA_cnt']\nlogging.info(f\"Columns after FE sample:\\n{train_data[example_cols].head(3)}\")\n\nlogging.info(\"Cell 5 complete: Feature engineering done.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:05:52.665836Z","iopub.execute_input":"2025-05-16T19:05:52.666288Z","iopub.status.idle":"2025-05-16T19:06:35.358204Z","shell.execute_reply.started":"2025-05-16T19:05:52.666252Z","shell.execute_reply":"2025-05-16T19:06:35.356006Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nCell 6: GROUP-BASED IMPUTATION\n------------------------------\nWe impute missing x_1, y_1, z_1 within each (target_id, resname) group.\nFinally, if any NAs remain, we fill them with a global median or drop them.\n\"\"\"\n\n# Perform group-based fill for x_1, y_1, z_1\ntrain_data[['x_1','y_1','z_1']] = (\n    train_data\n    .groupby(['target_id','resname'])[['x_1','y_1','z_1']]\n    .apply(lambda grp: grp.fillna(grp.mean()))\n    .reset_index(level=['target_id','resname'], drop=True)\n)\n\n# In case any remain after group-based mean fill (e.g. group is all NaN), do a global fill\nnum_cols = ['x_1','y_1','z_1']\nglobal_imputer = SimpleImputer(strategy='median')\ntrain_data[num_cols] = global_imputer.fit_transform(train_data[num_cols])\n\n# If you'd prefer to drop any leftover NAs instead:\n# train_data.dropna(subset=['x_1','y_1','z_1'], inplace=True)\n\nlogging.info(\"Group-based imputation + global median fallback complete.\")\n\n# Confirm missing values\nlogging.info(f\"Remaining missing x_1: {train_data['x_1'].isna().sum()}, \"\n             f\"y_1: {train_data['y_1'].isna().sum()}, z_1: {train_data['z_1'].isna().sum()}\")\n\nlogging.info(\"Cell 6 complete: Group-based imputation finished.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:06:35.359808Z","iopub.execute_input":"2025-05-16T19:06:35.360289Z","iopub.status.idle":"2025-05-16T19:06:46.697400Z","shell.execute_reply.started":"2025-05-16T19:06:35.360252Z","shell.execute_reply":"2025-05-16T19:06:46.695816Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nCell 7: PREPARE DATA FOR MODELING\n---------------------------------\nWe'll define the columns we won't use, set up X and y for x_1, y_1, z_1, \nand one-hot encode any relevant categorical columns (including resname).\n\"\"\"\n\n# Unused columns\nunused_cols = [\n    'ID','pdb_id','chain_id','resid',\n    'x_1','y_1','z_1',\n    'sequence','description','temporal_cutoff','all_sequences',\n    'target_id'  # key used for merges\n]\n\n# We'll keep resname, begin_seq, end_seq as features this time\nfeature_cols = [col for col in train_data.columns if col not in unused_cols]\n\n# Make a copy\ntrain_df = train_data.copy()\n\n# Convert to categories\nfor cat_col in ['resname','begin_seq','end_seq']:\n    if cat_col in feature_cols:\n        train_df[cat_col] = train_df[cat_col].astype('category')\n\n# One-hot encode\ntrain_df = pd.get_dummies(train_df, columns=['resname','begin_seq','end_seq'], drop_first=True)\n\n# Our final set of features\nX_cols = [col for col in train_df.columns if col not in unused_cols]\n\nX_full = train_df[X_cols]\ny_x_full = train_df['x_1']\ny_y_full = train_df['y_1']\ny_z_full = train_df['z_1']\n\nlogging.info(f\"Feature matrix shape: {X_full.shape}\")\nlogging.info(\"Cell 7 complete: Prepared data for modeling.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:06:46.698754Z","iopub.execute_input":"2025-05-16T19:06:46.699321Z","iopub.status.idle":"2025-05-16T19:06:47.244815Z","shell.execute_reply.started":"2025-05-16T19:06:46.699153Z","shell.execute_reply":"2025-05-16T19:06:47.243256Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nCell 8: KFold CV for X, Y, Z & Hyperparam Search\n------------------------------------------------\nWe'll do a simplified KFold cross-validation for each coordinate \nto get a sense of good hyperparams, then train final models.\n\"\"\"\n\nfrom sklearn.model_selection import KFold, RandomizedSearchCV\nimport numpy as np\n\n# Example hyperparameter grid (you can expand as needed)\nparam_dist = {\n    'learning_rate': [0.03, 0.05, 0.1],\n    'max_depth': [6, 10, 15],\n    'n_estimators': [500, 800, 1000],\n    'subsample': [0.7, 0.9, 1.0],\n    'colsample_bytree': [0.7, 0.9, 1.0]\n}\n\ndef run_random_search(X, y, param_dist, n_iter=5, cv_splits=3):\n    \"\"\"Simple RandomizedSearchCV for an XGBRegressor using GPU in XGBoost >= 2.0.\"\"\"\n    xgb = XGBRegressor(tree_method='hist', device='cuda', random_state=42)\n    rsearch = RandomizedSearchCV(\n        estimator=xgb,\n        param_distributions=param_dist,\n        n_iter=n_iter,\n        scoring='neg_mean_squared_error',\n        cv=cv_splits,\n        verbose=1,\n        random_state=42\n    )\n    rsearch.fit(X, y)\n    best_model = rsearch.best_estimator_\n    logging.info(f\"Best params: {rsearch.best_params_}, Best CV Score: {rsearch.best_score_}\")\n    return best_model, rsearch.best_params_\n\nlogging.info(\"Starting hyperparam search for X coordinate.\")\n#best_model_x, best_params_x = run_random_search(X_full, y_x_full, param_dist, n_iter=5, cv_splits=3)\n\nlogging.info(\"Starting hyperparam search for Y coordinate.\")\n#best_model_y, best_params_y = run_random_search(X_full, y_y_full, param_dist, n_iter=5, cv_splits=3)\n\nlogging.info(\"Starting hyperparam search for Z coordinate.\")\n#best_model_z, best_params_z = run_random_search(X_full, y_z_full, param_dist, n_iter=5, cv_splits=3)\n\nlogging.info(\"Cell 8 complete: RandomizedSearchCV best params found.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:06:47.246482Z","iopub.execute_input":"2025-05-16T19:06:47.246859Z","iopub.status.idle":"2025-05-16T19:06:47.256247Z","shell.execute_reply.started":"2025-05-16T19:06:47.246826Z","shell.execute_reply":"2025-05-16T19:06:47.254737Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nCell 9: FINAL TRAINING ON FULL DATA\n-----------------------------------\nUse the best hyperparams for each coordinate found in CV. \nRetrain each coordinate model on all data (X_full, y_*_full).\n\"\"\"\n\ndef get_best_xgb(params):\n    \"\"\" Return an XGBRegressor with the given params, using GPU. \"\"\"\n    # Here we override or add 'tree_method' to ensure GPU usage\n    # We can also specify predictor='gpu_predictor' to accelerate inference on GPU\n    model = XGBRegressor(\n        **params,\n        tree_method='hist',   # or tree_method=params.get('tree_method', 'hist')\n        device='cuda',        # ensures GPU usage\n        random_state=42\n    )\n    return model\n\nlogging.info(\"Retraining final model for X coordinate...\")\n#model_x = get_best_xgb(best_params_x)\n#model_x.fit(X_full, y_x_full)\n\nlogging.info(\"Retraining final model for Y coordinate...\")\n#model_y = get_best_xgb(best_params_y)\n#model_y.fit(X_full, y_y_full)\n\nlogging.info(\"Retraining final model for Z coordinate...\")\n#model_z = get_best_xgb(best_params_z)\n#model_z.fit(X_full, y_z_full)\n\nlogging.info(\"Cell 9 complete: Final models trained.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:06:47.257410Z","iopub.execute_input":"2025-05-16T19:06:47.257725Z","iopub.status.idle":"2025-05-16T19:06:47.291639Z","shell.execute_reply.started":"2025-05-16T19:06:47.257695Z","shell.execute_reply":"2025-05-16T19:06:47.289896Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nCell 10: PREPARE & ENGINEER TEST DATA\n-------------------------------------\nâ€¢ Expand test_sequences into (ID, resname, resid)\nâ€¢ Merge residueâ€‘level grid with perâ€‘sequence engineered features\nâ€¢ Align with training feature matrix X_full, fill missing values\n\"\"\"\n\n# ---------- 1. Expand residue grid ----------\ntest_expanded = [\n    [row[\"target_id\"], nt, i]\n    for _, row in test_sequences.iterrows()\n    for i, nt in enumerate(row[\"sequence\"], start=1)\n]\ntest_clean_df = pd.DataFrame(test_expanded, columns=[\"ID\", \"resname\", \"resid\"])\nlogging.info(f\"test_clean_df shape: {test_clean_df.shape} (expanded test sequences)\")\n\n# ---------- 2. Perâ€‘sequence engineered features ----------\ntest_feats = engineer_features(test_sequences)\n\n# Merge â€“ one row per residue, sequenceâ€‘level features broadcast to each residue\ntest_merged = pd.merge(\n    test_clean_df,\n    test_feats.drop(columns=[\"seq_length\"]),   # drop if not needed\n    left_on=\"ID\",\n    right_on=\"target_id\",\n    how=\"left\"\n)\nlogging.info(f\"test_merged shape after merging: {test_merged.shape}\")\n\n# ---------- 3. Clean up ----------\n# Replace sentinel values\nfor col in [\"x_1\", \"y_1\", \"z_1\"]:\n    if col in test_merged.columns:\n        test_merged[col] = test_merged[col].replace(-1e18, np.nan)\n\n# Drop columns not used by the model\ndrop_cols = [\"sequence\", \"description\", \"temporal_cutoff\", \"all_sequences\", \"target_id\"]\ntest_merged.drop(columns=[c for c in drop_cols if c in test_merged.columns], inplace=True, errors=\"ignore\")\n\n# ---------- 4. Categorical handling ----------\ncat_cols = {\"resname\", \"begin_seq\", \"end_seq\"} & set(test_merged.columns)\nfor col in cat_cols:\n    test_merged[col] = test_merged[col].astype(\"category\")\ntest_merged = pd.get_dummies(test_merged, columns=list(cat_cols), drop_first=True)\n\n# ---------- 5. Column alignment ----------\n# Single vectorised reindex instead of perâ€‘column insertion â†’ no fragmentation warning\ntest_merged = test_merged.reindex(columns=X_full.columns, fill_value=0)\n\n# ---------- 6. Missingâ€‘value imputation ----------\n# Fit a NEW median imputer on the training feature matrix (numeric cols only)\nnumeric_cols = X_full.select_dtypes(include=np.number).columns\nfeature_imputer = SimpleImputer(strategy=\"median\")\nfeature_imputer.fit(X_full[numeric_cols])\n\ntest_merged[numeric_cols] = feature_imputer.transform(test_merged[numeric_cols])\n\n# ---------- 7. All done ----------\ntest_merged_imputed = test_merged.copy()\nlogging.info(\"Cell 10 complete: Test data prepared, aligned, and imputed.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:06:47.293225Z","iopub.execute_input":"2025-05-16T19:06:47.293726Z","iopub.status.idle":"2025-05-16T19:06:49.855775Z","shell.execute_reply.started":"2025-05-16T19:06:47.293684Z","shell.execute_reply":"2025-05-16T19:06:49.854293Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!HF_DATASETS_OFFLINE=1 TRANSFORMERS_OFFLINE=1 HF_HOME=/kaggle/working TRANSFORMERS_CACHE=/kaggle/working ln -sf /kaggle/input/rna-torsion-bert-checkpoint-base/kaggle/working/rna_torsionBERT /kaggle/working/rna_torsionBERT","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:06:49.857717Z","iopub.execute_input":"2025-05-16T19:06:49.858361Z","iopub.status.idle":"2025-05-16T19:06:50.048166Z","shell.execute_reply.started":"2025-05-16T19:06:49.858304Z","shell.execute_reply":"2025-05-16T19:06:50.046315Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell: RNA Prediction with TorsionBERT  (offline-ready)\n# ------------------------------------------------------\nimport pandas as pd, torch, os, logging, sys, transformers\nfrom omegaconf import OmegaConf\nfrom functools import partial\n\n# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n# 1) LINK LOCAL CHECKPOINTS â–¸ rna_torsionBERT  &  DNA_Bert_3\n# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nif not os.path.exists(\"/kaggle/working/rna_torsionBERT\"):\n    os.symlink(\n        \"/kaggle/input/rna-torsion-bert-checkpoint-base/kaggle/working/rna_torsionBERT\",\n        \"/kaggle/working/rna_torsionBERT\"\n    )\n\nDNA_BERT_SRC = \"/kaggle/input/dna-bert-rna/DNA_bert_3\"\nDNA_BERT_DST = \"/kaggle/working/zhihan1996/DNA_bert_3\"   # path hard-coded in torsionBERT\nif not os.path.exists(DNA_BERT_DST):\n    os.makedirs(\"/kaggle/working/zhihan1996\", exist_ok=True)\n    os.symlink(DNA_BERT_SRC, DNA_BERT_DST)\n\n# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n# 2) FORCE OFFLINE MODE  +  MAP zhihan1996/* IDs â†’ local folders\n# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nos.environ.update({\n    \"HF_HUB_OFFLINE\":      \"1\",\n    \"HF_DATASETS_OFFLINE\": \"1\",\n    \"TRANSFORMERS_OFFLINE\":\"1\",\n    \"HF_HOME\":             \"/kaggle/working\",\n    \"TRANSFORMERS_CACHE\":  \"/kaggle/working\"\n})\ndef _localize(repo,*a,**kw):\n    \"\"\"\n    Redirect zhihan1996/DNA_bert_* to local paths and\n    force local_files_only for every HF load.\n    \"\"\"\n    if isinstance(repo,str) and repo.startswith(\"zhihan1996/DNA_bert_\"):\n        repo = \"/kaggle/working/\" + repo\n    kw[\"local_files_only\"] = True\n    return repo,a,kw\n# robust monkey-patch (handles partials, repeated patching, etc.)\nfor _cls in (\"AutoConfig\",\"AutoTokenizer\",\"AutoModel\"):\n    obj      = getattr(transformers, _cls)\n    base_cls = obj.func if isinstance(obj, partial) else obj\n    if not hasattr(base_cls, \"from_pretrained\"):\n        continue\n    _orig = base_cls.from_pretrained\n    def _wrap(repo,*a,__o=_orig,**kw):\n        repo,a,kw = _localize(repo,*a,**kw)\n        return __o(repo,*a,**kw)\n    base_cls.from_pretrained = _wrap\n\n# accept DNA-Bert-3 custom config\ntry:\n    from importlib import import_module\n    custom_conf = import_module(\n        \"transformers_modules.DNA_bert_3.configuration_bert\"\n    ).BertConfig\n    transformers.models.bert.modeling_bert.BertModel.config_class = custom_conf\nexcept Exception as e:\n    logging.warning(f\"[WARN] DNA_Bert_3 config patch skipped: {e}\")\n\n# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n# 3) LOGGING & tiny shell helper\n# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nlogging.basicConfig(level=logging.INFO,\n                    format=\"%(asctime)s | %(levelname)s | %(message)s\")\ndef run_and_print(cmd):\n    import subprocess, shlex, textwrap\n    res = subprocess.run(cmd if isinstance(cmd,list) else shlex.split(cmd),\n                         capture_output=True, text=True)\n    if res.stdout: print(res.stdout, end=\"\")\n    if res.stderr: print(\"STDERR:\", textwrap.shorten(res.stderr,400), end=\"\")\n    return res\n\n# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n# 4) ENSURE hydra-core (local wheel) â€“ omegaconf already present\n# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nrun_and_print([\n    \"pip\",\"install\",\"--no-index\",\"--no-deps\",\"--force-reinstall\",\n    \"/kaggle/input/hydra-core-132whl/hydra_core-1.3.2-py3-none-any.whl\"\n])\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:06:50.049993Z","iopub.execute_input":"2025-05-16T19:06:50.050465Z","iopub.status.idle":"2025-05-16T19:06:51.789565Z","shell.execute_reply.started":"2025-05-16T19:06:50.050419Z","shell.execute_reply":"2025-05-16T19:06:51.788183Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n# 5) RNAPredictor CONFIG (Hydra best practices, stochastic inference)\n# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nfrom rna_predict.interface import RNAPredictor\n# Import OmegaConf and torch if not already imported in the cell\nfrom omegaconf import OmegaConf\nimport torch\nimport logging # Ensure logging is imported if you use logger.info\n\nTEST_SEQS  = \"/kaggle/input/stanford-rna-3d-folding/test_sequences.csv\"\nSAMPLE_SUB = \"/kaggle/input/stanford-rna-3d-folding/sample_submission.csv\"\nOUTPUT_CSV = \"submission.csv\"\n\ndef create_predictor():\n    \"\"\"Instantiate RNAPredictor with local checkpoints & GPU/CPU autodetect, matching Hydra config structure.\"\"\"\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    logging.info(f\"Device: {device}\") # Assuming logging is configured\n    cfg = OmegaConf.create({\n        # Top-level keys consistent with a full Hydra config (e.g., default.yaml)\n        \"device\": device,\n        \"seed\": 42, # Good for reproducibility if used by models\n        \"atoms_per_residue\": 44, # Standard value\n        \"extraction_backend\": \"dssr\", # Or \"mdanalysis\" as needed\n\n        \"pipeline\": { # General pipeline settings\n            \"verbose\": True,\n            \"save_intermediates\": True,\n            # output_dir is usually set by Hydra's run directory or overridden\n        },\n\n        \"prediction\": { # Prediction-specific settings\n            \"repeats\": 5,\n            \"residue_atom_choice\": 0,\n            \"enable_stochastic_inference_for_submission\": True, # CRITICAL: Ensures unique predictions\n            # \"submission_seeds\": [42, 101, 2024, 7, 1991],  # Optional: for reproducible stochastic runs\n        },\n\n        \"model\": {\n            # â”€â”€ Stage B: torsion-angle prediction â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n            \"stageB\": {\n                \"torsion_bert\": {\n                    \"model_name_or_path\": \"/kaggle/working/rna_torsionBERT\", # Path to local TorsionBERT model\n                    \"device\": device,\n                    \"angle_mode\": \"degrees\",   # CHANGED: Set to \"degrees\" for consistency with StageC\n                                               # This ensures StageBTorsionBertPredictor outputs angles in degrees.\n                    \"num_angles\": 7,\n                    \"max_length\": 512,\n                    \"checkpoint_path\": None,   # Can be overridden if a specific checkpoint is needed\n                    \"debug_logging\": True,     # Set to False if logs are too verbose\n                    \"init_from_scratch\": False, # Assumes using pretrained TorsionBERT\n                    \"lora\": {                  # LoRA config (currently disabled)\n                        \"enabled\": False,\n                        \"r\": 8,\n                        \"alpha\": 16,\n                        \"dropout\": 0.1,\n                        \"target_modules\": [\"query\", \"value\"],\n                    },\n                }\n                # Pairformer config would go here if used: \"pairformer\": { ... }\n            },\n            # â”€â”€ Stage C: 3D reconstruction (MP-NeRF) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n            \"stageC\": {\n                \"enabled\": True,\n                \"method\": \"mp_nerf\",\n                \"do_ring_closure\": False,       # Consistent with default.yaml; notebook log showed True, adjust if needed.\n                \"place_bases\": True,\n                \"sugar_pucker\": \"C3'-endo\",\n                \"device\": device,\n                \"debug_logging\": True,          # Set to False if logs are too verbose\n                \"angle_representation\": \"degrees\", # StageC expects angles in degrees from StageB\n                \"use_metadata\": False,\n                \"use_memory_efficient_kernel\": False,\n                \"use_deepspeed_evo_attention\": False,\n                \"use_lma\": False,\n                \"inplace_safe\": False,          # Consistent with default.yaml; notebook log showed True.\n                \"chunk_size\": None,\n            },\n            # â”€â”€ Stage D: Diffusion refinement (minimal placeholder) â”€â”€â”€â”€â”€â”€â”€â”€\n            # Add full StageD config if it's actively used in this notebook\n            \"stageD\": {\n                \"enabled\": False, # Set to True if StageD is part of this specific notebook's pipeline\n                \"mode\": \"inference\",\n                \"device\": device,\n                \"debug_logging\": True,\n                # Placeholder for other essential StageD keys if enabled:\n                # \"ref_element_size\": 128,\n                # \"ref_atom_name_chars_size\": 256,\n                # \"profile_size\": 32,\n                # \"model_architecture\": { ... },\n                # \"diffusion\": { ... }\n            },\n        }\n    })\n    return RNAPredictor(cfg)\n\n# Usage example:\npredictor = create_predictor()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:06:51.791335Z","iopub.execute_input":"2025-05-16T19:06:51.791699Z","iopub.status.idle":"2025-05-16T19:06:52.817529Z","shell.execute_reply.started":"2025-05-16T19:06:51.791663Z","shell.execute_reply":"2025-05-16T19:06:52.816481Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# PATCH â–¸ guarantee predict_submission returns ONE ROW per residue  âœ…\n#         â€¢ works both when Stage C gives [L, atoms, 3]  OR  [N_atoms, 3]\n#         â€¢ keeps all original columns created by coords_to_df\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nimport logging, torch, pandas as pd\nfrom rna_predict.interface import RNAPredictor\nfrom rna_predict.utils.submission import coords_to_df, extract_atom, reshape_coords\n\nlog = logging.getLogger(\"rna_predict.patch.flat2res\")\n\ndef _predict_submission_patched(\n    self,\n    sequence: str,\n    prediction_repeats: int | None = None,\n    residue_atom_choice: int | None = None,\n):\n    \"\"\"\n    Collapses per-atom coordinates â†’ one canonical atom per residue.\n    â€¢ Prefers phosphate (â€œPâ€); falls back to first atom per residue.\n    â€¢ Always returns exactly len(sequence) rows, preserving coords_to_df schema.\n    \"\"\"\n    # â”€â”€ original prologue â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    result      = self.predict_3d_structure(sequence)\n    coords_flat = result[\"coords\"]                       # 2-D [N_atoms, 3]\n\n    # ğŸ”§ NEW: make it a plain tensor so .numpy() is allowed\n    if coords_flat.requires_grad:                        # â† the bug-fix\n        coords_flat = coords_flat.detach()\n\n    metadata        = result.get(\"atom_metadata\", {})\n    atom_names      = metadata.get(\"atom_names\", [])\n    residue_indices = metadata.get(\"residue_indices\", [])\n\n    repeats  = prediction_repeats if prediction_repeats is not None else self.default_repeats\n    atom_idx = residue_atom_choice if residue_atom_choice is not None else self.default_atom_choice\n\n    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    # â¶  FLAT-COORDS PATH   (Stage C returned [N_atoms, 3])\n    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    if coords_flat.dim() == 2 and coords_flat.shape[0] != len(sequence):\n        if not atom_names or not residue_indices:\n            log.error(\"[flat-coords] missing atom metadata â†’ falling back to legacy per-atom output\")\n            base = {\n                \"ID\":      range(1, len(coords_flat) + 1),\n                \"resname\": [\"X\"] * len(coords_flat),\n                \"resid\":   range(1, len(coords_flat) + 1),\n            }\n            df = pd.DataFrame(base)\n            for i in range(1, repeats + 1):\n                df[[f\"{ax}_{i}\" for ax in \"xyz\"]] = coords_flat.cpu().numpy()\n            return df\n\n        tmp = pd.DataFrame({\n            \"atom_name\": atom_names,\n            \"res0\":      residue_indices,       # 0-based residue index\n            \"x\": coords_flat[:, 0].cpu().numpy(),\n            \"y\": coords_flat[:, 1].cpu().numpy(),\n            \"z\": coords_flat[:, 2].cpu().numpy(),\n        })\n\n        # pick one atom per residue (prefer P)\n        picked = (tmp[tmp.atom_name == \"P\"]\n                  .drop_duplicates(\"res0\", keep=\"first\")\n                  .sort_values(\"res0\"))\n        if len(picked) != len(sequence):        # fallback if some Pâ€™s missing\n            log.warning(\"[flat-coords] P-selection gave %d/%d rows â€“ using first atom fallback\",\n                        len(picked), len(sequence))\n            picked = (tmp.groupby(\"res0\", as_index=False)\n                         .first()\n                         .sort_values(\"res0\"))\n\n        per_res_coords = torch.tensor(\n            picked[[\"x\", \"y\", \"z\"]].values,\n            dtype=coords_flat.dtype,\n            device=coords_flat.device,\n        )\n\n        return coords_to_df(sequence, per_res_coords, repeats)\n\n    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    # â·  ORIGINAL â€œreshapedâ€ PATH  (Stage C returned [L, atoms, 3])\n    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    coords = reshape_coords(coords_flat, len(sequence))\n    if coords.dim() == 2 and coords.shape[0] != len(sequence):\n        # reshape failed â†’ treat as flat once more\n        log.warning(\"[reshape_coords] produced flat coords â€“ rerouting through flat-coords logic.\")\n        result[\"coords\"] = coords\n        return _predict_submission_patched(self, sequence, prediction_repeats, residue_atom_choice)\n\n    atom_coords = extract_atom(coords, atom_idx)\n    return coords_to_df(sequence, atom_coords, repeats)\n\n# install the patch (simple attribute assignment is enough)\nRNAPredictor.predict_submission = _predict_submission_patched\nlog.info(\"âœ“ RNAPredictor.predict_submission patched (flat-coords fix)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:06:52.818688Z","iopub.execute_input":"2025-05-16T19:06:52.818976Z","iopub.status.idle":"2025-05-16T19:06:52.833843Z","shell.execute_reply.started":"2025-05-16T19:06:52.818951Z","shell.execute_reply":"2025-05-16T19:06:52.832636Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"toy = create_predictor().predict_submission(\"ACGUACGU\", prediction_repeats=1)\nassert len(toy) == 8            # âœ… one row per residue\nprint(toy.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:06:52.835076Z","iopub.execute_input":"2025-05-16T19:06:52.835554Z","iopub.status.idle":"2025-05-16T19:06:54.965454Z","shell.execute_reply.started":"2025-05-16T19:06:52.835511Z","shell.execute_reply":"2025-05-16T19:06:54.964350Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# 6) PREDICTION UTILITIES  â— de-duplication / aggregation safeguard  âœ…\n# -----------------------------------------------------------------------\n# NOTE: This cell assumes RNAPredictor has been patched with the corrected\n#       _predict_submission_patched method in a PREVIOUS cell.\n# Fix: Ensure _collapse_to_one_row_per_residue can correctly infer num_repeats\n#      and handle the original sequence string for resname population.\n# -----------------------------------------------------------------------\nimport numpy as np\nimport pandas as pd\nimport logging\nimport sys # For sys.stdout in logger handler\nimport os # For os.path.exists\n# Assuming create_predictor is defined in a previous cell and available in global scope\n# Assuming RNAPredictor is imported and patched in a previous cell\n\n# Configure logger for this cell if not already done globally\nlogger_cell6 = logging.getLogger(\"rna_predict.cell6_utils\")\nif not logger_cell6.handlers:\n    handler_cell6 = logging.StreamHandler(sys.stdout)\n    formatter_cell6 = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n    handler_cell6.setFormatter(formatter_cell6)\n    logger_cell6.addHandler(handler_cell6)\nlogger_cell6.setLevel(logging.INFO)\n\n\ndef _auto_column(df: pd.DataFrame, pref: list[str]) -> str:\n    \"\"\"Return first column present in *pref* (fallback â†’ df.columns[0]).\"\"\"\n    for c in pref:\n        if c in df.columns:\n            return c\n    if df.columns.empty: # Guard against empty DataFrame columns\n        logger_cell6.warning(\"_auto_column called with DataFrame with no columns.\")\n        return \"\" # Or raise an error, depending on desired behavior\n    return df.columns[0]\n\n\ndef _collapse_to_one_row_per_residue(df_raw: pd.DataFrame, seq_id: str, original_sequence: str, num_repeats: int) -> pd.DataFrame:\n    \"\"\"\n    Ensure the DataFrame has one row per residue with clean IDs and standard columns.\n    This function now primarily serves as a schema enforcer and final sanity check.\n    \"\"\"\n    df = df_raw.copy()\n\n    if df.empty:\n        logger_cell6.warning(f\"_collapse_to_one_row_per_residue received empty DataFrame for seq_id: {seq_id}\")\n        # Define expected columns based on num_repeats for an empty DataFrame\n        cols = [\"ID\", \"resname\", \"resid\"] + [f\"{ax}_{k}\" for k in range(1, num_repeats + 1) for ax in \"xyz\"]\n        return pd.DataFrame(columns=cols)\n\n    # 1ï¸âƒ£ & 2ï¸âƒ£: First repeat/angle only & Canonical atom selection\n    # These steps are assumed to have been handled by the patched `_predict_submission_patched`\n    # The input `df_raw` should ideally be one row per residue with all 5 repeats as columns.\n\n    # 3ï¸âƒ£ Safeguard: Average duplicates if `resid` is not unique (shouldn't happen if patched predict_submission is correct)\n    if \"resid\" in df.columns and not df[\"resid\"].is_unique:\n        logger_cell6.warning(f\"Residues in DataFrame for {seq_id} are not unique. Attempting to average duplicates.\")\n        coord_cols = [c for c in df.columns if c.startswith(('x_', 'y_', 'z_'))]\n        key_cols_present = [k for k in [\"resid\", \"resname\"] if k in df.columns]\n        if key_cols_present:\n            df = (\n                df.groupby(key_cols_present, as_index=False, sort=False)[coord_cols].mean()\n                  .reset_index(drop=True)\n            )\n    \n    # 4ï¸âƒ£ Ensure 'resid' is 1-based sequential and 'ID' is correctly formatted\n    # This is important because the input `df_raw` from the patched `predict_submission`\n    # should already have `len(sequence)` rows.\n    if not df.empty:\n        if \"resid\" not in df.columns or not pd.api.types.is_numeric_dtype(df[\"resid\"]) or df[\"resid\"].isnull().any() or not df[\"resid\"].is_monotonic_increasing:\n             df[\"resid\"] = np.arange(1, len(df) + 1) # Re-create if problematic\n        \n        if \"resname\" not in df.columns: # Ensure resname column exists\n             df[\"resname\"] = list(original_sequence)[:len(df)] if len(original_sequence) >= len(df) else (list(original_sequence) + ['X']*(len(df)-len(original_sequence)))\n        \n        if \"ID\" in df.columns:\n            df = df.drop(columns=\"ID\")\n        df.insert(0, \"ID\", [f\"{seq_id}_{r}\" for r in df[\"resid\"]])\n\n\n    # 5ï¸âƒ£ Ensure all required coordinate columns (x_1..z_5 etc.) exist and have the correct names\n    # The number of repeats is now taken from the argument.\n    expected_coord_cols = [f\"{ax}_{i+1}\" for i in range(num_repeats) for ax in \"xyz\"]\n    final_cols_schema = [\"ID\", \"resname\", \"resid\"] + expected_coord_cols\n    \n    for col in final_cols_schema:\n        if col not in df.columns:\n            logger_cell6.warning(f\"Column '{col}' missing in DataFrame for {seq_id}. Adding with NaNs/defaults.\")\n            if col.startswith(('x_', 'y_', 'z_')):\n                df[col] = np.nan\n            elif col == \"resname\":\n                 df[col] = list(original_sequence)[:len(df)] if len(original_sequence) >= len(df) else (list(original_sequence) + ['X']*(len(df)-len(original_sequence)))\n            elif col == \"resid\" and \"resid\" not in df.columns : # Should have been handled\n                 df[col] = np.arange(1, len(df)+1) if not df.empty else []\n            elif col == \"ID\" and \"ID\" not in df.columns and \"resid\" in df.columns : # Should have been handled\n                 df.insert(0, \"ID\", [f\"{seq_id}_{r}\" for r in df[\"resid\"]])\n            elif not df.empty : # For any other unexpected missing column\n                 df[col] = \"\" \n    \n    # Return only the columns expected in the submission, in the correct order\n    return df[final_cols_schema]\n\n\ndef process_test_sequences(test_csv: str, sample_csv: str, out_csv: str, *, batch: int = 1):\n    \"\"\"Generate submission file after collapsing predictions.\"\"\"\n\n    df_test = pd.read_csv(test_csv)\n    logging.info(\"Loaded %d sequences for processing.\", len(df_test)) # Use global logging or logger_cell6\n\n    # create_predictor() is defined in the preceding cell (Cell 12 in your notebook structure)\n    predictor = create_predictor()\n    # Get number of repeats from the predictor's configuration\n    num_repeats = predictor.prediction_config.repeats\n\n\n    id_col  = _auto_column(df_test, [\"id\", \"ID\", \"seq_id\", \"sequence_id\"])\n    seq_col = _auto_column(df_test, [\"sequence\", \"Sequence\", \"seq\", \"SEQ\"])\n\n    frames: list[pd.DataFrame] = []\n    for start_idx in range(0, len(df_test), batch): # Renamed 'start' to 'start_idx' to avoid conflict\n        end_idx = min(start_idx + batch, len(df_test))\n        logging.info(\"Processing batch: %dâ€“%d\", start_idx + 1, end_idx) # Use global logging or logger_cell6\n        \n        for i in range(start_idx, end_idx):\n            sid = df_test.at[i, id_col]\n            seq_str = df_test.at[i, seq_col] # Store the original sequence string\n\n            # Pass current_target_id to the predictor if your patched method uses it\n            if hasattr(predictor, 'current_target_id'):\n                 predictor.current_target_id = sid\n\n            if not isinstance(seq_str, str) or not seq_str:\n                logging.warning(f\"Skipping invalid or empty sequence for ID {sid} at index {i}.\")\n                # Create an empty DataFrame with correct columns\n                temp_df_empty = pd.DataFrame(columns=[\"ID\", \"resname\", \"resid\"] + [f\"{ax}_{k}\" for k in range(1, num_repeats + 1) for ax in \"xyz\"])\n                frames.append(temp_df_empty)\n                continue\n            \n            try:\n                # The patched predict_submission is called here.\n                # It should return a DataFrame that is already one-row-per-residue.\n                raw_predictions_df  = predictor.predict_submission(seq_str) # No need to pass repeats if it uses self.config\n                \n                # Call _collapse_to_one_row_per_residue for final schema enforcement\n                tidy_predictions_df = _collapse_to_one_row_per_residue(raw_predictions_df, sid, seq_str, num_repeats)\n                frames.append(tidy_predictions_df)\n            except Exception as err:\n                logging.error(\"Sequence %s (ID: %s) failed prediction: %s\", seq_str[:30]+\"...\", sid, err, exc_info=True)\n\n\n    if not frames:\n        logging.error(\"No successful predictions to concatenate. submission.csv will be empty or not created.\")\n        sample_submission_df = pd.read_csv(sample_csv)\n        empty_submission_df = pd.DataFrame(columns=sample_submission_df.columns)\n        empty_submission_df.to_csv(out_csv, index=False)\n        return empty_submission_df\n\n    results_df = pd.concat(frames, ignore_index=True)\n    \n    # Final alignment with sample_submission.csv to ensure exact format and row order\n    try:\n        sample_submission_df = pd.read_csv(sample_csv)\n        \n        # Ensure 'ID' column in results_df matches the sample submission's ID format for merging\n        # The _collapse_to_one_row_per_residue should have formatted 'ID' correctly.\n        \n        # Use a left merge to ensure all IDs from sample_submission are present and in order\n        final_submission_df = pd.merge(sample_submission_df[['ID']], # Only take ID column for merging keys\n                                       results_df, \n                                       on='ID', \n                                       how='left') # Use left merge to keep all sample submission IDs\n        \n        # Fill NaNs for any coordinates that might be missing after the merge (e.g., if a sequence failed or had fewer residues)\n        # The columns in final_submission_df will be based on results_df after the merge.\n        # We need to ensure all columns from sample_submission_df are present.\n        for col in sample_submission_df.columns:\n            if col not in final_submission_df.columns:\n                final_submission_df[col] = np.nan # Add missing columns with NaNs\n            if col.startswith(('x_', 'y_', 'z_')): # Fill NaNs in coordinate columns with 0.0\n                final_submission_df[col] = final_submission_df[col].fillna(0.0)\n            elif col in [\"resname\", \"resid\"] and col in final_submission_df.columns: # Fill NaNs in resname/resid if they exist\n                # This part might need more sophisticated filling if a whole sequence was missing\n                # For now, simple fillna. If `resname` or `resid` are entirely NaN for a sequence,\n                # they will remain NaN unless sample_submission has values for those IDs.\n                # A more robust fill would re-derive from sample_submission for missing ID rows.\n                pass # Let merge handle this; if ID was in sample but not results, resname/resid will be NaN\n\n        # Ensure exact column order and presence as in sample_submission.csv\n        final_submission_df = final_submission_df[sample_submission_df.columns.tolist()]\n\n    except Exception as e:\n        log.error(f\"Error aligning submission with sample_submission.csv: {e}. Saving raw concatenated results.\")\n        final_submission_df = results_df # Fallback to saving whatever was concatenated\n\n    final_submission_df.to_csv(out_csv, index=False)\n    logging.info(\"Saved final submission to â†’ %s  (#rows = %s)\", out_csv, f\"{len(final_submission_df):,}\")\n    return final_submission_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:10:27.588545Z","iopub.execute_input":"2025-05-16T19:10:27.589142Z","iopub.status.idle":"2025-05-16T19:10:27.621046Z","shell.execute_reply.started":"2025-05-16T19:10:27.589084Z","shell.execute_reply":"2025-05-16T19:10:27.619148Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n# 7) TOY SANITY-CHECK â€“ demonstrates collapse function\n# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nprint(\"\\n=== Toy sanity-check ===\")\n# Assuming create_predictor() and _collapse_to_one_row_per_residue are defined\n# in previous cells and available in the global scope.\n# Also assuming predictor is instantiated via predictor = create_predictor()\n\ntoy_sequence = \"ACGUACGU\"\nnum_toy_repeats = 2 # Or get from predictor.prediction_config.repeats if predictor is already created\n\n# Ensure predictor is created if not already (it was in your previous cell structure)\n# If predictor is not yet created in this cell's context, uncomment the next line:\n# predictor = create_predictor() \n# num_toy_repeats = predictor.prediction_config.repeats # More robust way to get repeats\n\ntoy_raw  = predictor.predict_submission(toy_sequence, prediction_repeats=num_toy_repeats)\n\n# Call _collapse_to_one_row_per_residue with the required arguments\ntoy_comp = _collapse_to_one_row_per_residue(toy_raw, \"TOY\", toy_sequence, num_toy_repeats)\nprint(toy_comp.head())\n\n# The uniqueness check for the toy example also needs num_toy_repeats\ncoords_cols_toy = [f\"x_{i+1}\" for i in range(num_toy_repeats)] + \\\n                  [f\"y_{i+1}\" for i in range(num_toy_repeats)] + \\\n                  [f\"z_{i+1}\" for i in range(num_toy_repeats)]\nunique_structs_toy = set()\nif not toy_raw.empty: # Check if toy_raw is not empty before proceeding\n    for i in range(num_toy_repeats): \n        x_col, y_col, z_col = f\"x_{i+1}\", f\"y_{i+1}\", f\"z_{i+1}\"\n        # Ensure all necessary columns exist in toy_raw before trying to access them\n        if all(col in toy_raw.columns for col in [x_col, y_col, z_col]):\n            coords_tuple = tuple(toy_raw[[x_col, y_col, z_col]].to_numpy().flatten())\n            unique_structs_toy.add(coords_tuple)\n        else:\n            log.warning(f\"Coordinate columns for repeat {i+1} (e.g., {x_col}) not found in toy_raw DataFrame. Columns available: {toy_raw.columns.tolist()}\")\n\n\nif not toy_raw.empty:\n    log.info(f\"Toy example: Found {len(unique_structs_toy)} unique structures out of {num_toy_repeats} repeats.\")\n    if len(unique_structs_toy) < num_toy_repeats and len(unique_structs_toy) > 1 :\n        log.warning(f\"Toy example: Less than {num_toy_repeats} unique structures, but more than 1. Stochasticity is partial.\")\n    elif len(unique_structs_toy) == 1 and num_toy_repeats > 1: # Check only if more than 1 repeat was expected\n        log.error(\"Toy example: FAILURE - Only 1 unique structure found. Stochasticity is NOT working.\")\n    elif len(unique_structs_toy) == num_toy_repeats:\n        log.info(f\"Toy example: SUCCESS - {num_toy_repeats} unique structures found!\")\nelse:\n    log.warning(\"Toy example: toy_raw DataFrame is empty. Cannot check uniqueness.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:10:31.902867Z","iopub.execute_input":"2025-05-16T19:10:31.903280Z","iopub.status.idle":"2025-05-16T19:10:33.306387Z","shell.execute_reply.started":"2025-05-16T19:10:31.903244Z","shell.execute_reply":"2025-05-16T19:10:33.304982Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nCell 11: GENERATE PREDICTIONS & BUILD SUBMISSION\n------------------------------------------------\nWe'll predict (x_1, y_1, z_1) for each residue, \nthen replicate those coordinates for structures x_2..z_5.\nFinally, we'll align with sample_submission and save submission.csv.\n\"\"\"\n\n# Predict x_1, y_1, z_1\n#test_pred_x = model_x.predict(test_merged_imputed)\n#test_pred_y = model_y.predict(test_merged_imputed)\n#test_pred_z = model_z.predict(test_merged_imputed)\n\n# Build submission from test_clean_df\n#submission = test_clean_df.copy()\n\n# Add predicted coords for structure 1\n#submission['x_1'] = test_pred_x\n#submission['y_1'] = test_pred_y\n#submission['z_1'] = test_pred_z\n\n# For simplicity, replicate for structures 2..5\n#for i in [2,3,4,5]:\n#    submission[f'x_{i}'] = test_pred_x\n#    submission[f'y_{i}'] = test_pred_y\n#    submission[f'z_{i}'] = test_pred_z\n\n# Adjust ID format: ID + \"_\" + resid\n#submission['ID'] = submission['ID'] + \"_\"  + submission['resid'].astype(str)\n\n# Reorder columns to match sample_submission\n#final_cols = list(sample_submission.columns)  # ID, resname, resid, x_1..z_5\n#submission = submission[['ID','resname','resid',\n#                         'x_1','y_1','z_1',\n#                         'x_2','y_2','z_2',\n#                         'x_3','y_3','z_3',\n#                         'x_4','y_4','z_4',\n#                         'x_5','y_5','z_5']]\n\n# Merge with sample_submission to match row order\n#sample_submission['sort_order'] = range(len(sample_submission))\n#submission_merged = pd.merge(\n#    submission,\n#    sample_submission[['ID','sort_order']],\n#    on='ID',\n#    how='left'\n#).sort_values('sort_order').drop(columns='sort_order')\n\n# This is our final submission dataframe\n#submission_df = submission_merged.copy()\n\n# Save to CSV\n#submission_df.to_csv(\"submission.csv\", index=False)\n#logging.info(\"submission.csv created successfully.\")\n\n#print(\"Cell 11 complete: Submission file saved. Ready to submit!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:10:43.067818Z","iopub.execute_input":"2025-05-16T19:10:43.068210Z","iopub.status.idle":"2025-05-16T19:10:43.075969Z","shell.execute_reply.started":"2025-05-16T19:10:43.068176Z","shell.execute_reply":"2025-05-16T19:10:43.074668Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 12: CONCLUSIONS & NEXT STEPS\n# ---------------------------------\n'''\nWe've done:\n- Group-based imputation\n- Preserved resname\n- Hyperparameter tuning via RandomizedSearchCV\n- Final training on full combined data\n- Test predictions with the same coordinate repeated across 5 structures\n\nSuggestions for further improvement:\n- Fine-tune hyperparameters with a broader search or Bayesian optimization\n- Explore more advanced RNA 3D features\n- Generate truly distinct 5 structures instead of repeating the same coordinates\n'''\nlogging.info(\"Notebook complete. Good luck on the leaderboard!\")\nprint(\"All done! Submit 'submission.csv' to the competition.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:10:45.626246Z","iopub.execute_input":"2025-05-16T19:10:45.626596Z","iopub.status.idle":"2025-05-16T19:10:45.632229Z","shell.execute_reply.started":"2025-05-16T19:10:45.626571Z","shell.execute_reply":"2025-05-16T19:10:45.630904Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%bash\n# Cell: show whatâ€™s inside every mounted Kaggle dataset  ğŸ”\n# --------------------------------------------------------\necho -e \"\\nğŸ“‚  Listing the first two levels of /kaggle/working â€¦\\n\"\n\n# Change depth (-maxdepth) if you want more or fewer levels\nfind /kaggle/working -maxdepth 2 -mindepth 1 -print | sed 's|^|  |'\n\necho -e \"\\nâœ…  Done.\\n\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:10:48.660294Z","iopub.execute_input":"2025-05-16T19:10:48.660672Z","iopub.status.idle":"2025-05-16T19:10:48.676199Z","shell.execute_reply.started":"2025-05-16T19:10:48.660645Z","shell.execute_reply":"2025-05-16T19:10:48.675021Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell : sanity-check submission.csv against test_sequences.csv  âœ…\n# ----------------------------------------------------------------\nimport pandas as pd, pathlib, textwrap, sys, itertools, numpy as np\n\nTEST_CSV = \"/kaggle/input/stanford-rna-3d-folding/test_sequences.csv\"\nSUB_CSV  = \"submission.csv\"\nTOL      = 1.0  # Ã… â€“ treat coords within Â±1 Ã… as identical\n\n# â”€â”€ 0)  helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ndef auto_col(df, pref):\n    for c in pref:\n        if c in df.columns:\n            return c\n    return df.columns[0]\n\ndef preview(s, n=5):\n    lst = list(s)\n    return \", \".join(lst[:n]) + (\" â€¦\" if len(lst) > n else \"\")\n\n# â”€â”€ 1)  load / basic info â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nfor f in (TEST_CSV, SUB_CSV):\n    if not pathlib.Path(f).is_file():\n        sys.exit(f\"[ERROR] {f} not found!\")\n\ntest_sequences = pd.read_csv(TEST_CSV)\nsubmission     = pd.read_csv(SUB_CSV)\n\nid_col_test = auto_col(test_sequences, [\"ID\", \"id\", \"seq_id\", \"sequence_id\"])\nid_col_sub  = auto_col(submission,     [\"ID\", \"id\", \"seq_id\", \"sequence_id\"])\n\n# â”€â”€ 2)  expected vs actual rows â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nexpected_rows = test_sequences[\"sequence\"].str.len().sum()\nprint(\"\\nâ”â” Summary â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\nprint(f\"Expected rows        : {expected_rows:,}\")\nprint(f\"submission.csv rows  : {len(submission):,}\")\ndupes = submission[id_col_sub].duplicated().sum()\nprint(f\"Duplicate {id_col_sub!r} rows : {dupes:,}\")\n\n# â”€â”€ 3)  build the *full* ID set   \"<sequenceID>_<resIdx>\"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nfull_id_set = {\n    f\"{sid}_{idx}\"\n    for sid, seq in zip(test_sequences[id_col_test], test_sequences[\"sequence\"])\n    for idx in range(1, len(seq) + 1)\n}\nsub_id_set = set(submission[id_col_sub].astype(str))\n\nmissing = full_id_set - sub_id_set\nextra   = sub_id_set  - full_id_set\n\nprint(\"\\nâ”â” ID reconciliation â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\nprint(f\"IDs missing from submission : {len(missing):,}\")\nprint(f\"Unexpected extra IDs        : {len(extra):,}\")\nif missing: print(\"  â†’ first few missing :\", preview(missing))\nif extra:   print(\"  â†’ first few extras  :\", preview(extra))\n\n# â”€â”€ 4)  per-sequence coverage (how many residues per sequence?) â”€â”€â”€â”€â”€â”€â”€â”€\nseq_len = test_sequences.set_index(id_col_test)[\"sequence\"].str.len()\n\n# **FIXED LINE BELOW** â€“ use expand=True to ensure a 1-D Series (avoids ndarray shape (n, 3))\nprefixes = (\n    submission[id_col_sub]\n    .astype(str)\n    .str.rsplit(\"_\", n=1, expand=True)[0]   # returns a Series, not a nested ndarray\n)\n\ncoverage = prefixes.value_counts().reindex(seq_len.index).fillna(0).astype(int)\nbad_cov  = coverage[coverage != seq_len]\n\nprint(\"\\nâ”â” Per-sequence coverage â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\nprint(f\"Sequences with wrong #rows : {len(bad_cov):,}\")\nif len(bad_cov):\n    print(\"  id  | expected | got\")\n    for sid, got in itertools.islice(bad_cov.items(), 5):\n        print(f\" {sid:<6}| {seq_len[sid]:>8} | {got}\")\n\n# â”€â”€ 5)  column sanity â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nREQ_COLS = [\"ID\", \"resname\", \"resid\"] + [f\"{ax}_{i}\" for i in range(1, 6) for ax in \"xyz\"]\nmissing_cols = [c for c in REQ_COLS if c not in submission.columns]\n\nprint(\"\\nâ”â” Column sanity â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\nprint(f\"Missing required columns   : {len(missing_cols)}\")\nif missing_cols:\n    print(textwrap.fill(\", \".join(missing_cols), width=88))\n\n# â”€â”€ 6)  structure-repeat uniqueness â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ntrip_cols = np.array([[f\"{ax}_{i}\" for ax in \"xyz\"] for i in range(1, 6)])\ncoords = submission[trip_cols.flatten()].values.reshape(len(submission), 5, 3)\n\ndef unique_triplet_count(row):\n    \"\"\"Return #unique (x,y,z) triplets in a 5Ã—3 slice.\"\"\"\n    uniq = []\n    for v in row:\n        if not any(np.allclose(v, u, atol=TOL) for u in uniq):\n            uniq.append(v)\n    return len(uniq)\n\n# ğŸ‘‰ replace apply_along_axis with a 1-liner list-comprehension  âœ…\nuniq_counts = np.array([unique_triplet_count(row) for row in coords])\n\nall_identical = (uniq_counts == 1).sum()\ntruly_unique  = (uniq_counts > 1).sum()\n\nprint(\"\\nâ”â” Structure-repeat uniqueness â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\nprint(f\"Rows where 5 structures are identical : {all_identical:,}\")\nprint(f\"Rows with â‰¥2 distinct triplets         : {truly_unique:,}\")\n\n# Per-sequence share of unique repeats\nsub_seq_id = prefixes.to_numpy()   # 1-D array of sequence IDs\nper_seq_unique = (\n    pd.Series(uniq_counts > 1, index=sub_seq_id)\n      .groupby(level=0).mean()\n      .sort_values(ascending=False)\n)\n\nprint(\"\\nTop 5 sequences with most unique repeats:\")\nfor sid, frac in per_seq_unique.head(5).items():\n    print(f\"  {sid:<6}: {frac:6.1%} rows diversified\")\n\nprint(\"\\nâœ…  Sanity check finished.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:10:52.085507Z","iopub.execute_input":"2025-05-16T19:10:52.085878Z","iopub.status.idle":"2025-05-16T19:10:52.110042Z","shell.execute_reply.started":"2025-05-16T19:10:52.085848Z","shell.execute_reply":"2025-05-16T19:10:52.108388Z"}},"outputs":[],"execution_count":null}]}
=====
RNA_PREDICT Pipeline in Kaggle: Notebook Workflow and Refactoring Plan

Current Notebook Workflow: Training, Evaluation & Inference

Training Phase: In the current rna-predict.ipynb pipeline, model training is not performed within the Kaggle notebook â€“ instead a pre-trained model is used for inference. The codebase does include a training script (rna_predict/training/train.py) that leverages PyTorch Lightning to train pipeline models, but the notebook itself did not run a full training loop for any stage ï¿¼. This implies that the heavy lifting (training Stage Bâ€™s torsion predictor, etc.) was done offline or in a separate process. For example, the Stage B TorsionBERT model is loaded from a checkpoint (/kaggle/working/rna_torsionBERT) rather than trained from scratch in the notebook ï¿¼ ï¿¼. If fine-tuning were desired, one could utilize the provided training script or implement a manual training loop (since the stage scripts themselves donâ€™t contain an epoch-based loop ï¿¼), but in the Kaggle context the notebook sticks to using pre-trained weights for speed.

Evaluation Phase: The notebook does not explicitly perform a separate evaluation on a validation set during its run. While the Kaggle dataset provides a validation set (with ~12 RNAs) and their labels, the pipeline doesnâ€™t compute metrics like TM-score in the notebook. Instead, any validation would be done offline or by examining sample outputs. (Kaggleâ€™s official metric is TM-score, ranging 0â€“1, comparing predicted vs. true 3D coordinates ï¿¼.) The pipeline does include a â€œtoy sanity-checkâ€ where a small known RNA structure is predicted and compared, essentially verifying that the reconstruction is sensible. In the logs, we see a short sequence ACGUACGU run through the pipeline and a toy output printed for comparison ï¿¼ ï¿¼. This suggests the authors manually checked prediction accuracy on a tiny example (possibly comparing predicted coordinates to known coordinates for 5 residues labeled TOY_1â€¦TOY_5). Beyond this, the notebookâ€™s focus is generating the submission for the test set rather than quantitatively evaluating predictions within the notebook.

Inference & Submission Generation: The core of the notebook is the inference pipeline that processes the Kaggle test sequences and produces the submission file. The workflow is roughly:
	â€¢	Data Loading: The notebook reads the test sequences from test_sequences.csv (provided in the competition data). Each RNA sequence (string of nucleotides) is taken as input for prediction. In the Kaggle environment, the input data directory stanford-rna-3d-folding/ contains test_sequences.csv, train_sequences.csv (and .v2), train_labels (as PDB files), etc ï¿¼ ï¿¼. The code likely iterates through each test target_id and its sequence.
	â€¢	Stage B â€“ Torsion Angle Prediction: For each sequence, the notebook invokes the Stage B TorsionBERT predictor to obtain backbone torsion angles. This stage uses a HuggingFace Transformer-based model (a â€œlanguage modelâ€ for RNA) that reads the RNA sequence (and potentially an MSA or other features) and outputs predicted torsion angles per residue ï¿¼ ï¿¼. In the logs, we see Stage B being initialized and the TorsionBERT model loaded ï¿¼. The model outputs 7 values per nucleotide (corresponding to 7 torsion angles in the RNA backbone + glycosidic bond). The pipeline performs a post-processing step to ensure the angles are in degrees: the log shows that the output dimension is 7 (matching the expected number of angles) and a warning that the values â€œlook like radians, converting to degreesâ€ ï¿¼. This suggests the model might output angles in radians which are then converted to degrees for consistency with Stage Câ€™s expectations. No LoRA adaptation is applied during inference (the log confirms LoRA was not enabled or configured, so all model parameters remain as loaded ï¿¼).
	â€¢	Stage C â€“ 3D Coordinate Reconstruction: Next, the predicted torsion angles feed into Stage C reconstruction to build 3D coordinates of the RNAâ€™s atoms. Stage C uses an Mp-NERF based forward-kinematics approach to convert dihedral angles into Cartesian coordinates ï¿¼ ï¿¼. In practice, Stage C takes each sequenceâ€™s torsion angle set and produces coordinates for the chainâ€™s backbone and sugar (and places bases if enabled). The configuration in the logs shows Stage C is running with method: "mp_nerf" and various options: ring closure enforcement, base placement, a fixed sugar pucker (C3'-endo), etc ï¿¼. All Stage C computation was done on CPU in the notebook (device set to cpu in config) ï¿¼. Despite running on CPU, Stage C is fast (e.g. ~0.2â€“0.5s for ~70â€“150 residues) given itâ€™s a deterministic geometry construction. The output of Stage C is a set of 3D coordinates for each atom in the RNA. Crucially, for submission we only need the coordinates of the C1â€² atom of each nucleotide (the carbon atom connecting the base to the sugar, used as the representative position of the nucleotide). The pipeline extracts those: we see in the log an output table with columns ID, resname, resid, x_1, y_1, z_1 (and further columns for additional predictions) ï¿¼. Each row corresponds to one nucleotideâ€™s C1â€² coordinates. For example, after Stage C for a toy sequence, the log shows residues 1â€“5 (A, C, G, U, A) and their coordinates ï¿¼. Similarly, for actual test sequences, Stage C outputs each residueâ€™s coordinates (the log shows lines with each resid and coordinates for sequences of length 69, 157, etc. in the test set) ï¿¼ ï¿¼.
	â€¢	Submission Assembly: As each test sequence is processed, its predicted coordinates are accumulated into a submission format. The Kaggle submission file requires a row for every nucleotide of every target, with specific columns (explained in detail below). The notebook likely either builds a pandas DataFrame or writes lines incrementally. To ensure the output matches the required format, the code uses the provided sample_submission.csv as a template. We see at the end of the logs that after processing all sequences, the notebook prints â€œAll done! Submit â€˜submission.csvâ€™ to the competition.â€ and lists the file ï¿¼. It then reports the submission file has 2,515 rows with no missing or extra IDs ï¿¼, indicating it exactly matches the sample submission indices. This means the submission covers every residue of each test RNA once, with no duplicates, as expected.

In summary, the current notebook essentially loads a pre-trained Stage B model, runs Stage B and Stage C for each RNA sequence in the test set, and writes out the C1â€² atom coordinates (five times per residue, as columns, to satisfy the competitionâ€™s multi-prediction requirement) in submission.csv. There is no model training happening in-notebook and no explicit metric evaluation; it is a straight pipeline from sequence to predicted structure.

Key Components and Dependencies

Stage B â€“ TorsionBERT Angle Predictor

Stage B is powered by TorsionBERT, a Transformer-based model specialized for RNA. It takes an RNA sequence (and potentially structural context like base-pair adjacency or an MSA) and outputs predicted torsion angles for each residue ï¿¼ ï¿¼. In the RNA_PREDICT pipeline, StageBTorsionBertPredictor is the class wrapping this model. The implementation builds on HuggingFace Transformers, so it includes a tokenizer and model loaded from a model name or path. In the Kaggle notebook, the model was loaded from the working directory path /kaggle/working/rna_torsionBERT ï¿¼ (likely a directory with a pre-trained model checkpoint).

Outputs: TorsionBERT produces 7 angles per nucleotide, corresponding to the RNA backboneâ€™s dihedral angles (typically Î±, Î², Î³, Î´, Îµ, Î¶, and the Ï‡ glycosidic torsion). These may be represented or predicted in radians internally. The pipeline checks the output dimension (7) and then issues warnings about unit conversion: â€œAssuming model outputs degrees directlyâ€¦ Values look like radians, converting to degrees.â€ ï¿¼. Thus, the angles are converted to degrees before passing to Stage C. The Stage B module ensures the angle data shape and type are correct. It also logs the model configuration used (model path, max length, device, etc.) for transparency ï¿¼. Notably, the pipeline had a feature for LoRA (Low-Rank Adapters) to allow fine-tuning part of the model, but in this run LoRA was not applied (the log explicitly says â€œLoRA not appliedâ€¦ All params trainableâ€ and it proceeded with the base model) ï¿¼. This means the full transformer weights were used as-is, with no lightweight adaptation in place.

Dependencies: Stage B depends on HuggingFace for the model architecture and tokenizer. It likely uses a BERT-like architecture pre-trained on RNA sequences with known structures. For input features, Stage B can incorporate secondary structure (adjacency matrix from Stage A) or MSA data, as hinted by the design (the pipelineâ€™s plan was to feed Stage B with base-pair info) ï¿¼. However, in the Kaggle notebook run, Stage A was skipped and adjacency_matrix=None was passed into Stage B. The TorsionBERT in this context probably just used the raw sequence (and possibly the provided MSA indirectly, if the model or code was configured to use MSA features â€“ though thereâ€™s no explicit log of MSA usage). For simplicity, one can assume Stage B here operated purely sequence-to-angles.

In a refactored setup, Stage Bâ€™s main requirement is the availability of a trained TorsionBERT model. We will either load this from a checkpoint (for inference) or have the capability to train/fine-tune it on the Kaggle training data. If training from scratch, we need the train labels converted to torsion angles. (The Kaggle train_labels.csv gives atomic coordinates, so an offline preprocessing to derive torsion angles would be needed to supervise TorsionBERT. Given the complexity, using the already pre-trained model is the quickest path.) For the Kaggle wrapper, we will treat TorsionBERT as a black-box predictor: initialize it, feed sequences, get angle predictions.

Stage C â€“ 3D Structure Reconstruction

Stage C takes the torsion angles and constructs 3D coordinates for the RNA. The StageCReconstruction component implements a deterministic conversion using an algorithm akin to Nerf (Natural Extension Reference Frame) for building coordinates from dihedrals. In this pipeline, Stage C is configured to use an in-house â€œmp_nerfâ€ method (likely optimized for RNA) ï¿¼ ï¿¼. It enforces proper geometry such as closing the sugar ring and placing the bases. Key parameters include: do_ring_closure=True (ensures the ribose ring is closed properly), place_bases=True (attaches bases to the sugar-phosphate backbone), and a fixed sugar pucker conformation ("C3'-endo", the typical RNA sugar pucker) ï¿¼. These choices mean Stage C does not predict these geometric variations â€“ it uses standard values to place atoms.

Outputs: Stage C outputs the full 3D coordinates of each atom in the RNA chain. For an RNA with N residues, the total atoms could be ~NÃ—44 (if including all atoms and hydrogen), but heavy-atom count is around NÃ—20â€“25. The log confirms the scale: e.g., for a 69-residue RNA, Stage C produced 1464 atoms ï¿¼ (â‰ˆ21 atoms per residue, likely heavy atoms only). Each residueâ€™s key atoms (phosphate, sugars, bases) are positioned. Among them, the C1â€² atom of each residue is singled out for evaluation and submission. The pipeline after Stage C extracts each residueâ€™s C1â€² coordinates to form the output table. In the log snippet for the toy example, we see one line per residue with resname (nucleotide), resid (residue index), and coordinates ï¿¼. The ID column in submission is a combination of the target ID and residue index (like 101D_1 for target 101D, residue 1) ï¿¼ ï¿¼. The notebook ensures these IDs match the sample submission.

Stage C has no learnable parameters; itâ€™s purely a function of the input angles. Its dependencies are numerical libraries (PyTorch for tensor math and geometry) and possibly some custom code for the mp_nerf algorithm (as outlined in docs/pipeline/stageC/mp_nerf.md). Because Stage C is deterministic and fast, it can be run on CPU. In fact, in the Kaggle notebook it ran on CPU for all sequences without issue ï¿¼. For a refactored solution, Stage C can remain largely as-is: we just need to call the appropriate function to convert predicted angles to coordinates. The output then needs filtering to pick C1â€² atoms.

Kaggle Submission Format and Requirements

The Stanford RNA 3D Folding competition has a specific output format. Competitors must submit five distinct 3D predictions for each RNA target, in a single CSV file ï¿¼ ï¿¼. The rationale is to allow multiple tries per target (Kaggle will evaluate all five and use the best scoring one for that target). The submission CSV format is summarized as follows ï¿¼:
	â€¢	Each row corresponds to one nucleotide (residue) of a target RNA.
	â€¢	Columns:
	â€¢	ID: a unique identifier combining the target ID and the residue number (for example, targetID_resIndex, like 101D_1 for residue 1 of target 101D) ï¿¼.
	â€¢	resname: the nucleotide name (A, C, G, U for standard bases).
	â€¢	resid: the residue index (1-indexed integer).
	â€¢	x_1, y_1, z_1: the predicted coordinates of that residueâ€™s C1â€² atom for Model 1.
	â€¢	x_2, y_2, z_2: coordinates for Model 2.
	â€¢	â€¦ up to x_5, y_5, z_5 for Model 5.

Thus, there are 18 columns in total: ID, resname, resid, and 15 coordinates (5 triples). The submission file should contain every residue of each test sequence. The provided sample_submission.csv in the data outlines all the required ID rows (2515 rows in this case, which matches the total number of nucleotides across all test RNAs) ï¿¼. A valid submission must have exactly those IDs (no missing or extra), which the notebook double-checks ï¿¼.

In terms of content, since our pipeline currently produces one structure per target (not five), a common strategy is to repeat the same prediction across all five model columns (or introduce slight stochastic variations if possible). The Kaggle scoring will take the best of the five, so having identical predictions simply means all five are the same â€“ it satisfies the format, though it doesnâ€™t give any diversity. The log from the toy sanity-check suggests how the pipeline handles multiple predictions: they printed columns for x_1â€¦x_2 (two model outputs) which in that case were identical ï¿¼. By extension, the final submission likely had the same coordinates in x_1, y_1, z_1 through x_5, y_5, z_5 for each residue (since only one modelâ€™s output was available). This meets the requirement that five predictions are present, even if they donâ€™t differ.

The evaluation metric on Kaggleâ€™s backend is TM-score ï¿¼. TM-score evaluates the similarity of a predicted structure to the true structure (itâ€™s length-normalized and ranges from 0 to 1, higher is better). Kaggle will compute the TM-score for each of the five models per target against the true structure and take the highest one as that targetâ€™s score ï¿¼. Our job in the pipeline is just to output coordinates; we donâ€™t calculate TM-score ourselves in submission. (If we wanted to gauge performance locally, we could compute TM-score on the validation set where true structures are known, but the current notebook did not do this internally.)

In short, the submission format demands careful ordering and completeness (all IDs). Our pipeline, as evidenced by the final log, followed the sample submission ordering exactly (no missing IDs, no duplicates) ï¿¼. The refactored wrapper will need to do the same: likely by reading the sample_submission.csv as a template, then filling in the coordinate columns for each ID.

Model Export Considerations

While Kaggleâ€™s competition is scored by CSV submissions, itâ€™s often important to export trained models for future use or for the private test phase. In this project, â€œmodel exportâ€ likely refers to saving the trained weights (for Stage B and any other trainable components) in a reusable form. The codebase suggests that a proper checkpointing system was not yet fully in place â€“ for example, an analysis noted the absence of a centralized state save/load utility and the need to manually use torch.save for saving model state dicts ï¿¼. In practice, for our Kaggle wrapper:
	â€¢	After training or fine-tuning Stage B on the provided training set, we should save the model weights (e.g., as a .pt file or HuggingFace model directory). Kaggle notebooks can write to the /kaggle/working directory; those files can then be downloaded or turned into Kaggle Datasets for reuse. Exporting could also mean converting to an ONNX or TorchScript for portability, but since weâ€™ll be using Python in Kaggle inference, a state dict save is sufficient.
	â€¢	If using PyTorch Lightning for training, weâ€™d rely on its checkpoint callback to save the best model. If using a custom loop, weâ€™d call torch.save(model.state_dict(), "model.pth") at the end. The key is to ensure we capture the trainable parameters of Stage B (and Stage B Pairformer if used). Given that Stage C has no learned parameters, and Stage A was skipped, Stage Bâ€™s model is the main artifact to export.
	â€¢	Additionally, any preprocessing artifacts (for example, if we computed torsion-angle labels or processed MSAs) could be saved if needed, but likely not necessary for inference.

The model export expectation in the docs may also hint at Kaggleâ€™s requirement for sharing the model in later stages (some competitions require the top teams to provide their models for verification). In our context, we ensure the wrapper can output a trained model file and instructions to load it for inference.

Plan for Refactoring into a Kaggle-Friendly Wrapper

To make the pipeline more straightforward and modular for Kaggle use, we propose refactoring the notebook into a simpler wrapper with clear components. The goal is to support the following modes of operation cleanly: (1) Training (and validation), (2) Inference, (3) Model exporting, and (4) Submission file generation. Below is the plan for each component:
	â€¢	1. Inference Module: We will create a function or script (e.g., run_inference()) that encapsulates the sequence â†’ structure prediction process. This will:
	â€¢	Load the pre-trained Stage B TorsionBERT model (from a checkpoint or saved weights). For reproducibility, this could use a specific Kaggle dataset or a weight file packaged with our code. Initialization of the model will be done once. (We can use the StageBTorsionBertPredictor class directly, pointing it to the model path and device, bypassing Hydra for simplicity.)
	â€¢	Iterate over input sequences. For each sequence (or possibly batch of sequences if using vectorized inference), use the Stage B model to predict torsion angles ï¿¼. Ensure the output is in degrees as needed (we can incorporate the radian-to-degree conversion as in the original code ï¿¼).
	â€¢	Pass the angles into Stage C reconstruction. We will call a Stage C function (e.g., run_stageC(sequence, angles)) that returns the 3D coordinates. This function will internally handle all the geometry â€“ we will configure it with the same options as before (mp_nerf, ring closure, etc.) but we can simplify by hardcoding those options in the function call or using a lightweight config object. The output will be an array of coordinates for each atom; we will extract the C1â€² atoms for each residue. Because our pipeline knows the ordering of atoms, we can map each residueâ€™s C1â€² easily (Stage C likely labels atoms or we know the index pattern of C1â€²).
	â€¢	Collect the results in a structured form (e.g., a list of dictionaries or a DataFrame) where each entry has: target_id, residue index, nucleotide, and the predicted (x, y, z).
	â€¢	If we are generating multiple models per target (to have diverse predictions in the five outputs), this inference module can be looped or randomized. For instance, we could run the prediction 5 times with different random seeds or slight perturbations (if the model or Stage C can be stochastic, perhaps by slight noise on angles). For now, the simple implementation will just duplicate the one prediction.
	â€¢	2. Training & Evaluation Module: A separate function or script (train_and_evaluate()) will handle model training on the Kaggle train set and optional validation:
	â€¢	Data loading: Use train_sequences.csv and train_labels.csv (the latter provided via PDB_RNA structures or train_labels.csv with coordinates ï¿¼). We will need to compute torsion angles from the true structures to serve as training targets for Stage B. (If time is short, one might skip training and rely on the pre-trained model, but for completeness the module will be there.)
	â€¢	Model initialization: Initialize the TorsionBERT model (either from scratch or load pre-trained and fine-tune). If fine-tuning, perhaps freeze some layers or use LoRA in the future, but initial simple approach is to allow full fine-tuning if data is sufficient.
	â€¢	Training loop: Iterate over epochs, batches of sequences. For each, compute modelâ€™s predicted angles; compare to ground truth angles; compute a loss (e.g., mean absolute error on angles, or cosine distance if using sin/cos representation). Backpropagate and update model weights. This can be done either with pure PyTorch or via PyTorch Lightning. The codebaseâ€™s analysis suggested Lightning was not deeply integrated into pipeline modules ï¿¼, so using Lightningâ€™s Trainer now could be an â€œupgradeâ€ path. A simpler custom loop might be more transparent in Kaggle. We will also be mindful of the limited Kaggle runtime/GPU â€“ perhaps training only a few epochs or on a subset for demonstration.
	â€¢	Evaluation: After training, evaluate on the validation set (if provided). The validation data (12 sequences from CASP15 as per competition description ï¿¼) have true structures. We can run our inference pipeline on those and compute TM-score or RMSD to assess performance. This is optional but helps gauge if the model improved.
	â€¢	Checkpointing: During training, save the best model weights. For example, if using Lightning, use ModelCheckpoint callback to save the model with lowest validation loss. If manual, keep track and use torch.save. This produces the model file to be used for inference.
	â€¢	3. Model Export: After training, we will explicitly export the model. In Kaggle, this means writing the weight file (e.g., torsionbert_final.pth or a HuggingFace save folder) to the output. The user can then add this to a Kaggle dataset for future use. In our wrapper, model export is essentially part of training completion â€“ we ensure the final or best model is saved. If using the pre-trained model without changes, we can still provide a utility to export it (perhaps converting to a Kaggle dataset or simply noting the path). Since the pipeline code didnâ€™t have a built-in export, we are adding it for convenience ï¿¼.
	â€¢	4. Submission File Generation: Finally, the wrapper will have a utility to create the submission.csv in the required format using the inference results:
	â€¢	We will use the sample submission as a template. By reading sample_submission.csv, we get the correct ordering of IDs (which are sorted by target and residue). We then simply need to fill in the coordinate columns.
	â€¢	Using the DataFrame of predictions from the inference module, merge or align it to the sample submission by ID. Then populate x_1, y_1, z_1, â€¦ x_5, y_5, z_5. If we only have one modelâ€™s coords, we duplicate them across all five sets.
	â€¢	Write out the new CSV. The logs in the original notebook show a reconciliation step (checking for missing or extra IDs) ï¿¼; our process of using the provided template inherently guarantees correctness.
	â€¢	Weâ€™ll print a small preview and the count of rows to reassure that it matches (e.g., 2515 rows, etc., as in the original run).

Simplification and Integration Considerations: To streamline this for Kaggle:
	â€¢	We will minimize external dependencies. The core pipeline already uses PyTorch, Hydra, etc. In a Kaggle notebook, we might avoid the complexity of Hydra configurations (the original pipeline is Hydra-heavy). Instead, we can define needed parameters directly in code or use simple YAMLs. For example, rather than full default.yaml and config composition, we can directly specify that Stage B model path, device, etc., and Stage C options in our functions. This reduces setup overhead.
	â€¢	The wrapper can be organized as a Python module with a CLI or simply as well-defined functions that the Kaggle notebook calls in sequence. For instance, the Kaggle notebook might first call train_and_evaluate() (if training is desired), then run_inference() with the resulting model, then use a provided helper to output the submission file.
	â€¢	We will focus on Stage B and Stage C only for the initial version (Stage A â€“ secondary structure â€“ can be incorporated later for potential accuracy gains, and Stage D â€“ diffusion refinement â€“ is beyond the minimal scope). This keeps the pipeline lightweight: sequence â†’ angles â†’ coords is the main path.
	â€¢	Logging and debugging info can be toned down. The current logs are very verbose (due to debug settings). The wrapper can log key events (like â€œLoaded modelâ€, â€œPredicting structure for XYZâ€¦â€) at info level. This makes it easier to follow during Kaggle runs without overwhelming output.
	â€¢	Ensure that the same random seed or deterministic behavior is used if we want repeatable results (especially if producing multiple predictions per target). Alternatively, if time permits, incorporate slight randomness to generate diverse models 2â€“5 (e.g., random initialization of transformer dropout each run, etc.).

By implementing these components, we achieve a modular pipeline that is easier to maintain and adapt. A researcher or competitor could use the training module offline to improve the model, then plug the trained model into the inference module to generate Kaggle submissions quickly. Overall, this refactoring isolates the concerns: one part for model training, one for inference, and a clear path to produce the final output in the required format, focusing on the critical Stage B (TorsionBERT) and Stage C (geometry builder) pieces of the pipeline.

References:
	â€¢	Kaggle Competition Overview and Data Formats ï¿¼ ï¿¼
	â€¢	Pipeline Logs (Stage B and C execution) ï¿¼ ï¿¼
	â€¢	Pipeline Design Documents (Stage B TorsionBERT vs. full pipeline) ï¿¼ ï¿¼
	â€¢	Pipeline Execution Summary (Submission assembly) ï¿¼