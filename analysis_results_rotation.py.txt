
=== CODESCENE ANALYSIS ===
Please systematically review the following CodeScene analysis results and provide a detailed summary of the findings. Then plan out the necessary refactoring steps based on the CodeScene analysis.

{"score":10.0,"review":[]}
=== MYPY ANALYSIS ===

<?xml-stylesheet type="text/xsl" href="mypy-html.xslt"?><mypy-report-index name="index"><file module="rna_predict.pipeline.stageA.input_embedding.current.utils.rotation" name="rna_predict/pipeline/stageA/input_embedding/current/utils/rotation.py" total="243" any="18" empty="159" imprecise="0" precise="66" unanalyzed="0"/></mypy-report-index>
=== RUFF FIX OUTPUT ===

All checks passed!

=======
PROMPT:
**=======**
REFACTOR:
=======
The major types of code refactoring mentioned include:

1. **Extract Function**: Extracting code into a function or method (also referred to as Extract Method).
2. **Extract Variable**: Extracting code into a variable.
3. **Inline Function**: The inverse of Extract Function, where a function is inlined back into its calling code.
4. **Inline Variable**: The inverse of Extract Variable, where a variable is inlined back into its usage.
5. **Change Function Declaration**: Changing the names or arguments of functions.
6. **Rename Variable**: Renaming variables for clarity.
7. **Encapsulate Variable**: Encapsulating a variable to manage its visibility.
8. **Introduce Parameter Object**: Combining common arguments into a single object.
9. **Combine Functions into Class**: Grouping functions with the data they operate on into a class.
10. **Combine Functions into Transform**: Merging functions particularly useful with read-only data.
11. **Split Phase**: Organizing modules into distinct processing phases.

These refactorings focus on improving code clarity and maintainability without altering its observable behavior.

For more detailed information, you might consider using tools that could provide further insights or examples related to these refactoring types.


====
FULL CODE:
====
show the full file dont drop comments or existing functionality

**====**
FULL CODE:
**====**
# protenix/model/utils.py
# Copyright 2024 ByteDance and/or its affiliates.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Rotation and transformation utility functions for RNA structure prediction.
"""

from typing import Optional

import torch
from scipy.spatial.transform import Rotation

from .tensor_ops import expand_at_dim


def _apply_centering(
    x_input_coords: torch.Tensor,
    mask: Optional[torch.Tensor] = None,
    eps: float = 1e-12,
) -> torch.Tensor:
    """Center the coordinates by subtracting the mean.

    Args:
        x_input_coords: Input coordinates [..., N_atom, 3]
        mask: Optional mask for the coordinates [..., N_atom]
        eps: Small number for numerical stability

    Returns:
        Centered coordinates [..., N_atom, 3]
    """
    if mask is None:
        return x_input_coords - torch.mean(input=x_input_coords, dim=-2, keepdim=True)

    # Ensure mask has compatible dimensions for broadcasting
    while mask.ndim < x_input_coords.ndim - 1:
        mask = mask.unsqueeze(0)

    if mask.shape[:-1] != x_input_coords.shape[:-2]:
        # Attempt to expand mask batch dims to match x_input_coords
        try:
            mask = mask.expand(*x_input_coords.shape[:-2], -1)
        except RuntimeError as e:
            raise RuntimeError(
                f"Cannot expand mask shape {mask.shape} to match coords {x_input_coords.shape} for centering. Error: {e}"
            ) from e

    center = (x_input_coords * mask.unsqueeze(dim=-1)).sum(dim=-2) / (
        mask.sum(dim=-1, keepdim=True) + eps
    )
    return x_input_coords - center.unsqueeze(dim=-2)


def _apply_random_transformation(
    centered_coords: torch.Tensor, N_sample: int, s_trans: float
) -> torch.Tensor:
    """Apply random rotation and translation to centered coordinates.

    Args:
        centered_coords: Centered coordinates [..., N_sample, N_atom, 3]
        N_sample: Number of samples
        s_trans: Scale factor for translation

    Returns:
        Transformed coordinates [..., N_sample, N_atom, 3]
    """
    device = centered_coords.device
    N_atom = centered_coords.size(-2)
    N_augment = torch.numel(centered_coords[..., 0, 0])
    batch_size_shape = centered_coords.shape[:-3]

    # Generate random rotation matrices
    rot_matrix_random = (
        uniform_random_rotation(N_sample=N_augment)
        .to(device)
        .reshape(*batch_size_shape, N_sample, 3, 3)
    ).detach()  # [..., N_sample, 3, 3]

    # Generate random translations
    trans_random = s_trans * torch.randn(size=(*batch_size_shape, N_sample, 3)).to(
        device
    )

    # Apply rotation and translation
    return rot_vec_mul(
        r=expand_at_dim(rot_matrix_random, dim=-3, n=N_atom), t=centered_coords
    ) + trans_random.unsqueeze(-2)


class AugmentationConfig:
    """Configuration for coordinate augmentation."""

    def __init__(
        self,
        n_sample: int = 1,
        s_trans: float = 1.0,
        centre_only: bool = False,
        eps: float = 1e-12,
    ):
        self.n_sample = n_sample
        self.s_trans = s_trans
        self.centre_only = centre_only
        self.eps = eps

    @classmethod
    def from_kwargs(cls, **kwargs) -> "AugmentationConfig":
        """Create a config from keyword arguments."""
        return cls(
            n_sample=kwargs.get("N_sample", 1),
            s_trans=kwargs.get("s_trans", 1.0),
            centre_only=kwargs.get("centre_only", False),
            eps=kwargs.get("eps", 1e-12),
        )


def centre_random_augmentation(x_input_coords: torch.Tensor, **kwargs) -> torch.Tensor:
    """Implements Algorithm 19 in AF3

    Args:
        x_input_coords (torch.Tensor): input coords [..., N_atom, 3]
        **kwargs: Configuration options including:
            N_sample (int, optional): the total number of augmentation. Defaults to 1.
            s_trans (float, optional): scale factor of trans. Defaults to 1.0.
            centre_only (bool, optional): if set true, will only perform centering without applying random translation and rotation.
            mask (torch.Tensor, optional): masking for the coords [..., N_atom]
            eps (float, optional): small number used for masked mean

    Returns:
        torch.Tensor: the Augmentation version of input coords [..., N_sample, N_atom, 3]
    """
    # Extract mask from kwargs to handle it separately
    mask = kwargs.pop("mask", None)

    # Create config object from remaining kwargs
    config = AugmentationConfig.from_kwargs(**kwargs)

    # Center the coordinates
    centered_coords = _apply_centering(x_input_coords, mask, config.eps)

    # Expand to [..., N_sample, N_atom, 3]
    expanded_coords = expand_at_dim(centered_coords, dim=-3, n=config.n_sample)

    # Return centered coordinates if no augmentation is requested
    if config.centre_only:
        return expanded_coords

    # Apply random rotation and translation
    return _apply_random_transformation(
        expanded_coords, config.n_sample, config.s_trans
    )


def uniform_random_rotation(N_sample: int = 1) -> torch.Tensor:
    """Generate random rotation matrices with scipy.spatial.transform.Rotation

    Args:
        N_sample (int, optional): the total number of augmentation. Defaults to 1.

    Returns:
        torch.Tensor: N_sample rot matrics
            [N_sample, 3, 3]
    """
    rotation = Rotation.random(num=N_sample)
    rot_matrix = torch.from_numpy(rotation.as_matrix()).float()  # [N_sample, 3, 3]
    return rot_matrix


def _handle_standard_case(r: torch.Tensor, t: torch.Tensor) -> torch.Tensor:
    """Handle the standard case where r and t have compatible dimensions for einsum.

    Args:
        r (torch.Tensor): Rotation matrix [..., 3, 3]
        t (torch.Tensor): Vector [..., 3]

    Returns:
        torch.Tensor: Rotated vector
    """
    try:
        return torch.einsum("...ij,...j->...i", r, t)
    except RuntimeError as e:
        # Fallback: try matmul if shapes allow direct application
        if r.shape == (3, 3) and t.ndim >= 2:
            try:
                return torch.matmul(t, r.transpose(-1, -2))
            except RuntimeError:
                raise RuntimeError(
                    f"Matrix multiplication failed: r={r.shape}, t={t.shape}"
                ) from e
        raise RuntimeError(f"Einsum failed: r={r.shape}, t={t.shape}") from e


def _handle_ndim_plus_one_case(r: torch.Tensor, t: torch.Tensor) -> torch.Tensor:
    """Handle the case where r.ndim == t.ndim + 1.

    Args:
        r (torch.Tensor): Rotation matrix [..., N, 3, 3]
        t (torch.Tensor): Vector [..., N, 3]

    Returns:
        torch.Tensor: Rotated vector
    """
    # Check if batch dimensions are compatible for matmul
    if r.shape[:-3] == t.shape[:-2]:
        t_unsqueeze = t.unsqueeze(-1)  # [..., N, 3, 1]
        # Perform batch matrix vector product
        rotated_t = torch.matmul(r, t_unsqueeze)
        return rotated_t.squeeze(-1)  # [..., N, 3]

    # Fallback to einsum if direct matmul broadcasting fails
    try:
        return torch.einsum("...nij,...nj->...ni", r, t)
    except RuntimeError as e:
        raise RuntimeError(
            f"Einsum failed in ndim+1 case: r={r.shape}, t={t.shape}"
        ) from e


def rot_vec_mul(r: torch.Tensor, t: torch.Tensor) -> torch.Tensor:
    """Apply rotation matrix to vector.
    Applies a rotation to a vector. Written out by hand to avoid transfer
    to avoid AMP downcasting.

    Args:
        r (torch.Tensor): the rotation matrices [..., 3, 3]
        t (torch.Tensor): the coordinate tensors [..., 3]

    Returns:
        torch.Tensor: Rotated coordinates, shape [..., 3].
    """
    # Validate input shapes
    if not (r.shape[-2:] == (3, 3) and t.shape[-1] == 3):
        raise ValueError(
            f"Invalid shapes: r={r.shape}, t={t.shape}. Expected r[...3,3] and t[...3]"
        )

    # Case 1: r.ndim == t.ndim + 1 (e.g., r=[..., N, 3, 3], t=[..., N, 3])
    if r.ndim == t.ndim + 1:
        return _handle_ndim_plus_one_case(r, t)

    # Case 2: Standard case with compatible dimensions
    if r.ndim >= 2 and t.ndim >= 1:
        return _handle_standard_case(r, t)

    # If we get here, shapes are fundamentally incompatible
    raise ValueError(f"Incompatible shapes for rot_vec_mul: r={r.shape}, t={t.shape}")
