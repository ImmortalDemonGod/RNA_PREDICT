RNA Pipeline Combined Output
Generated on: 2025-04-08 04:19:21
================================================================================


================================================================================
Output from: rna_predict/pipeline/stageA/run_stageA.py
Timestamp: 2025-04-08 04:19:21
================================================================================

STDOUT:
[Info] File already exists and is valid zip, skipping download: RFold/checkpoints.zip
[Unzip] Extracting RFold/checkpoints.zip into RFold
[INFO] Adjacency shape: (352, 352)
[VARNA] Running: java -cp RFold/VARNAv3-93.jar fr.orsay.lri.varna.applications.VARNAcmd -i test_seq.ct -o test_seq.png -resolution 8.0
[VARNA] Visualization saved to test_seq.png


================================================================================
Output from: rna_predict/pipeline/stageB/main.py
Timestamp: 2025-04-08 04:19:26
================================================================================

STDOUT:
[2025-04-08 04:19:27,918] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to mps (auto detect)
[Stage A] adjacency shape = torch.Size([8, 8])
[Stage B] angles shape = torch.Size([8, 16])
[Stage C] coords shape = torch.Size([24, 3]), #atoms = 24

=== Now Running Gradient Flow Test ===
Running gradient flow test on device: cpu
q.shape: torch.Size([16, 8, 4]), k.shape: torch.Size([16, 8, 4]), v.shape: torch.Size([16, 8, 4])
q.shape: torch.Size([16, 8, 4]), k.shape: torch.Size([16, 8, 4]), v.shape: torch.Size([16, 8, 4])
Loss: 0.3211982250213623

--- Grad Check ---
  [final_head_s] weight, grad sum=2.3798e+01
  [final_head_s] bias, grad sum=5.5441e-01
  [final_head_angles] weight, grad sum=8.4986e+00
  [final_head_angles] bias, grad sum=5.5441e-01
  [final_head_z] weight, grad sum=3.3871e+00
  [final_head_z] bias, grad sum=5.5441e-01
  [pairformer] stack.blocks.0.tri_mul_out.linear_g.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_mul_out.linear_g.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_mul_out.linear_z.weight, grad sum=1.6082e+01
  [pairformer] stack.blocks.0.tri_mul_out.linear_z.bias, grad sum=4.9543e-01
  [pairformer] stack.blocks.0.tri_mul_out.layer_norm_in.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_mul_out.layer_norm_in.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_mul_out.layer_norm_out.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_mul_out.layer_norm_out.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_mul_out.linear_a_p.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_mul_out.linear_a_p.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_mul_out.linear_a_g.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_mul_out.linear_a_g.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_mul_out.linear_b_p.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_mul_out.linear_b_p.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_mul_out.linear_b_g.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_mul_out.linear_b_g.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_mul_in.linear_g.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_mul_in.linear_g.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_mul_in.linear_z.weight, grad sum=1.6655e+01
  [pairformer] stack.blocks.0.tri_mul_in.linear_z.bias, grad sum=5.2237e-01
  [pairformer] stack.blocks.0.tri_mul_in.layer_norm_in.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_mul_in.layer_norm_in.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_mul_in.layer_norm_out.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_mul_in.layer_norm_out.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_mul_in.linear_a_p.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_mul_in.linear_a_p.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_mul_in.linear_a_g.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_mul_in.linear_a_g.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_mul_in.linear_b_p.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_mul_in.linear_b_p.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_mul_in.linear_b_g.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_mul_in.linear_b_g.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_att_start.layer_norm.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_att_start.layer_norm.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_att_start.linear.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_att_start.mha.linear_q.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_att_start.mha.linear_k.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_att_start.mha.linear_v.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_att_start.mha.linear_o.weight, grad sum=1.0198e+01
  [pairformer] stack.blocks.0.tri_att_start.mha.linear_o.bias, grad sum=6.8151e-01
  [pairformer] stack.blocks.0.tri_att_start.mha.linear_g.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_att_start.mha.linear_g.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_att_end.layer_norm.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_att_end.layer_norm.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_att_end.linear.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_att_end.mha.linear_q.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_att_end.mha.linear_k.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_att_end.mha.linear_v.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_att_end.mha.linear_o.weight, grad sum=5.8770e+00
  [pairformer] stack.blocks.0.tri_att_end.mha.linear_o.bias, grad sum=6.6256e-01
  [pairformer] stack.blocks.0.tri_att_end.mha.linear_g.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.tri_att_end.mha.linear_g.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.pair_transition.layernorm1.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.pair_transition.layernorm1.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.pair_transition.linear_no_bias_a.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.pair_transition.linear_no_bias_b.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.pair_transition.linear_no_bias.weight, grad sum=4.3184e+00
  [pairformer] stack.blocks.0.attention_pair_bias.layernorm_a.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.attention_pair_bias.layernorm_a.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.attention_pair_bias.layernorm_z.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.attention_pair_bias.layernorm_z.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.attention_pair_bias.linear_nobias_z.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.attention_pair_bias.attention.gating_bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.attention_pair_bias.attention.to_q.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.attention_pair_bias.attention.to_k.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.attention_pair_bias.attention.to_v.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.attention_pair_bias.attention.to_out.weight, grad sum=2.2123e+01
  [pairformer] stack.blocks.0.attention_pair_bias.attention.to_out.bias, grad sum=1.0134e+00
  [pairformer] stack.blocks.0.attention_pair_bias.attention.gating_linear.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.attention_pair_bias.attention.gating_linear.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.single_transition.layernorm1.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.single_transition.layernorm1.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.single_transition.linear_no_bias_a.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.single_transition.linear_no_bias_b.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.0.single_transition.linear_no_bias.weight, grad sum=3.2720e+01
  [pairformer] stack.blocks.1.tri_mul_out.linear_g.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_mul_out.linear_g.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_mul_out.linear_z.weight, grad sum=1.5061e+01
  [pairformer] stack.blocks.1.tri_mul_out.linear_z.bias, grad sum=4.8876e-01
  [pairformer] stack.blocks.1.tri_mul_out.layer_norm_in.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_mul_out.layer_norm_in.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_mul_out.layer_norm_out.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_mul_out.layer_norm_out.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_mul_out.linear_a_p.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_mul_out.linear_a_p.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_mul_out.linear_a_g.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_mul_out.linear_a_g.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_mul_out.linear_b_p.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_mul_out.linear_b_p.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_mul_out.linear_b_g.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_mul_out.linear_b_g.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_mul_in.linear_g.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_mul_in.linear_g.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_mul_in.linear_z.weight, grad sum=1.5622e+01
  [pairformer] stack.blocks.1.tri_mul_in.linear_z.bias, grad sum=4.8165e-01
  [pairformer] stack.blocks.1.tri_mul_in.layer_norm_in.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_mul_in.layer_norm_in.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_mul_in.layer_norm_out.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_mul_in.layer_norm_out.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_mul_in.linear_a_p.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_mul_in.linear_a_p.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_mul_in.linear_a_g.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_mul_in.linear_a_g.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_mul_in.linear_b_p.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_mul_in.linear_b_p.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_mul_in.linear_b_g.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_mul_in.linear_b_g.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_att_start.layer_norm.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_att_start.layer_norm.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_att_start.linear.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_att_start.mha.linear_q.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_att_start.mha.linear_k.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_att_start.mha.linear_v.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_att_start.mha.linear_o.weight, grad sum=1.0761e+01
  [pairformer] stack.blocks.1.tri_att_start.mha.linear_o.bias, grad sum=6.8868e-01
  [pairformer] stack.blocks.1.tri_att_start.mha.linear_g.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_att_start.mha.linear_g.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_att_end.layer_norm.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_att_end.layer_norm.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_att_end.linear.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_att_end.mha.linear_q.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_att_end.mha.linear_k.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_att_end.mha.linear_v.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_att_end.mha.linear_o.weight, grad sum=5.8045e+00
  [pairformer] stack.blocks.1.tri_att_end.mha.linear_o.bias, grad sum=7.2852e-01
  [pairformer] stack.blocks.1.tri_att_end.mha.linear_g.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.tri_att_end.mha.linear_g.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.pair_transition.layernorm1.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.pair_transition.layernorm1.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.pair_transition.linear_no_bias_a.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.pair_transition.linear_no_bias_b.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.pair_transition.linear_no_bias.weight, grad sum=4.4649e+00
  [pairformer] stack.blocks.1.attention_pair_bias.layernorm_a.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.attention_pair_bias.layernorm_a.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.attention_pair_bias.layernorm_z.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.attention_pair_bias.layernorm_z.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.attention_pair_bias.linear_nobias_z.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.attention_pair_bias.attention.gating_bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.attention_pair_bias.attention.to_q.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.attention_pair_bias.attention.to_k.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.attention_pair_bias.attention.to_v.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.attention_pair_bias.attention.to_out.weight, grad sum=2.3616e+01
  [pairformer] stack.blocks.1.attention_pair_bias.attention.to_out.bias, grad sum=1.0134e+00
  [pairformer] stack.blocks.1.attention_pair_bias.attention.gating_linear.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.attention_pair_bias.attention.gating_linear.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.single_transition.layernorm1.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.single_transition.layernorm1.bias, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.single_transition.linear_no_bias_a.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.single_transition.linear_no_bias_b.weight, grad sum=0.0000e+00
  [pairformer] stack.blocks.1.single_transition.linear_no_bias.weight, grad sum=3.2694e+01
  [torsion_bert] model.dnabert.embeddings.word_embeddings.weight, grad sum=1.3840e+01
  [torsion_bert] model.dnabert.embeddings.position_embeddings.weight, grad sum=1.5724e+01
  [torsion_bert] model.dnabert.embeddings.token_type_embeddings.weight, grad sum=8.1043e+00
STDERR:
W0408 04:19:28.808000 8676640832 torch/distributed/elastic/multiprocessing/redirects.py:27] NOTE: Redirects are currently not supported in Windows or MacOs.


================================================================================
Output from: rna_predict/pipeline/stageC/stage_c_reconstruction.py
Timestamp: 2025-04-08 04:19:56
================================================================================

STDOUT:
RNA coords shape: torch.Size([4, 21, 3])  total atoms: 84


================================================================================
Output from: rna_predict/pipeline/stageD/run_stageD.py
Timestamp: 2025-04-08 04:19:58
================================================================================

STDOUT:
[2025-04-08 04:20:00,379] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to mps (auto detect)
[DEBUG] s_trunk shape: torch.Size([1, 25, 384])
[DEBUG] s_inputs shape: torch.Size([1, 25, 449])
[DEBUG] Before sample_diffusion:
  coords_init shape: torch.Size([1, 25, 3])
  s_trunk shape: torch.Size([1, 25, 384])
  s_inputs shape: torch.Size([1, 25, 449])
[DEBUG] Determined true_batch_shape: torch.Size([1])
[DEBUG][Generator Loop 0] Before denoise_net - x_noisy: torch.Size([1, 1, 25, 3]), t_hat: torch.Size([1, 1])
[DEBUG PRE-CAT] z_trunk shape: torch.Size([1, 25, 25, 128]), relpe_output shape: torch.Size([1, 25, 25, 128])
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 16, actual size: 2500 (from torch.Size([1, 1, 4, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 16, actual size: 2500 (from torch.Size([1, 1, 4, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 16, actual size: 2500 (from torch.Size([1, 1, 4, 25, 25])). Skipping bias application for stability.
[DEBUG AGG] a_atom shape: torch.Size([1, 1, 25, 768])
[DEBUG AGG] atom_to_token_idx shape: torch.Size([1, 25])
[DEBUG AGG] num_tokens: 25
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 16, actual size: 2500 (from torch.Size([1, 1, 4, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 16, actual size: 2500 (from torch.Size([1, 1, 4, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 16, actual size: 2500 (from torch.Size([1, 1, 4, 25, 25])). Skipping bias application for stability.
[DEBUG][DiffusionModule.forward] Returning x_denoised shape: torch.Size([1, 1, 25, 3])
[DEBUG][Generator Loop 1] Before denoise_net - x_noisy: torch.Size([1, 1, 25, 3]), t_hat: torch.Size([1, 1])
[DEBUG PRE-CAT] z_trunk shape: torch.Size([1, 25, 25, 128]), relpe_output shape: torch.Size([1, 25, 25, 128])
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 16, actual size: 2500 (from torch.Size([1, 1, 4, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 16, actual size: 2500 (from torch.Size([1, 1, 4, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 16, actual size: 2500 (from torch.Size([1, 1, 4, 25, 25])). Skipping bias application for stability.
[DEBUG AGG] a_atom shape: torch.Size([1, 1, 25, 768])
[DEBUG AGG] atom_to_token_idx shape: torch.Size([1, 25])
[DEBUG AGG] num_tokens: 25
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 16, actual size: 2500 (from torch.Size([1, 1, 4, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 16, actual size: 2500 (from torch.Size([1, 1, 4, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 16, actual size: 2500 (from torch.Size([1, 1, 4, 25, 25])). Skipping bias application for stability.
[DEBUG][DiffusionModule.forward] Returning x_denoised shape: torch.Size([1, 1, 25, 3])
[DEBUG][Generator Loop 2] Before denoise_net - x_noisy: torch.Size([1, 1, 25, 3]), t_hat: torch.Size([1, 1])
[DEBUG PRE-CAT] z_trunk shape: torch.Size([1, 25, 25, 128]), relpe_output shape: torch.Size([1, 25, 25, 128])
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 16, actual size: 2500 (from torch.Size([1, 1, 4, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 16, actual size: 2500 (from torch.Size([1, 1, 4, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 16, actual size: 2500 (from torch.Size([1, 1, 4, 25, 25])). Skipping bias application for stability.
[DEBUG AGG] a_atom shape: torch.Size([1, 1, 25, 768])
[DEBUG AGG] atom_to_token_idx shape: torch.Size([1, 25])
[DEBUG AGG] num_tokens: 25
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 16, actual size: 2500 (from torch.Size([1, 1, 4, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 16, actual size: 2500 (from torch.Size([1, 1, 4, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 16, actual size: 2500 (from torch.Size([1, 1, 4, 25, 25])). Skipping bias application for stability.
[DEBUG][DiffusionModule.forward] Returning x_denoised shape: torch.Size([1, 1, 25, 3])
[DEBUG][Generator Loop 3] Before denoise_net - x_noisy: torch.Size([1, 1, 25, 3]), t_hat: torch.Size([1, 1])
[DEBUG PRE-CAT] z_trunk shape: torch.Size([1, 25, 25, 128]), relpe_output shape: torch.Size([1, 25, 25, 128])
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 16, actual size: 2500 (from torch.Size([1, 1, 4, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 16, actual size: 2500 (from torch.Size([1, 1, 4, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 16, actual size: 2500 (from torch.Size([1, 1, 4, 25, 25])). Skipping bias application for stability.
[DEBUG AGG] a_atom shape: torch.Size([1, 1, 25, 768])
[DEBUG AGG] atom_to_token_idx shape: torch.Size([1, 25])
[DEBUG AGG] num_tokens: 25
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 16, actual size: 2500 (from torch.Size([1, 1, 4, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 16, actual size: 2500 (from torch.Size([1, 1, 4, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 16, actual size: 2500 (from torch.Size([1, 1, 4, 25, 25])). Skipping bias application for stability.
[DEBUG][DiffusionModule.forward] Returning x_denoised shape: torch.Size([1, 1, 25, 3])
[DEBUG][Generator Loop 4] Before denoise_net - x_noisy: torch.Size([1, 1, 25, 3]), t_hat: torch.Size([1, 1])
[DEBUG PRE-CAT] z_trunk shape: torch.Size([1, 25, 25, 128]), relpe_output shape: torch.Size([1, 25, 25, 128])
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 16, actual size: 2500 (from torch.Size([1, 1, 4, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 16, actual size: 2500 (from torch.Size([1, 1, 4, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 16, actual size: 2500 (from torch.Size([1, 1, 4, 25, 25])). Skipping bias application for stability.
[DEBUG AGG] a_atom shape: torch.Size([1, 1, 25, 768])
[DEBUG AGG] atom_to_token_idx shape: torch.Size([1, 25])
[DEBUG AGG] num_tokens: 25
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 256, actual size: 10000 (from torch.Size([1, 1, 16, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 16, actual size: 2500 (from torch.Size([1, 1, 4, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 16, actual size: 2500 (from torch.Size([1, 1, 4, 25, 25])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 16, actual size: 2500 (from torch.Size([1, 1, 4, 25, 25])). Skipping bias application for stability.
[DEBUG][DiffusionModule.forward] Returning x_denoised shape: torch.Size([1, 1, 25, 3])
[DEBUG][sample_diffusion] Returning _chunk_sample_diffusion output shape: torch.Size([1, 1, 25, 3])
[DEBUG] After sample_diffusion:
  coords_final shape before squeeze: torch.Size([1, 1, 25, 3])
[DEBUG] Final coords_final shape (handling N_sample=1): torch.Size([1, 25, 3])
[DEBUG] After inference call: 's_inputs' in internal? True, 's_inputs' in original? True
STDERR:
W0408 04:20:01.814000 8676640832 torch/distributed/elastic/multiprocessing/redirects.py:27] NOTE: Redirects are currently not supported in Windows or MacOs.
/Users/tomriddle1/RNA_PREDICT/rna_predict/pipeline/stageD/diffusion/run_stageD_unified.py:182: UserWarning: input_features not provided, using basic fallback based on partial_coords.
  warnings.warn(
/Users/tomriddle1/RNA_PREDICT/rna_predict/pipeline/stageA/input_embedding/current/transformer/encoder_components/feature_processing.py:199: UserWarning: ref_space_uid has wrong shape torch.Size([1, 25]), expected [..., 3]. Setting to zeros.
  warnings.warn(
/Users/tomriddle1/RNA_PREDICT/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/Users/tomriddle1/RNA_PREDICT/rna_predict/pipeline/stageA/input_embedding/current/transformer/atom_attention_decoder.py:173: UserWarning: Conditioning signal 's' has incorrect feature dim 128, expected 384. Adapting.
  warnings.warn(


================================================================================
Output from: rna_predict/interface.py
Timestamp: 2025-04-08 04:20:13
================================================================================

STDOUT:
   ID resname  resid       x_1  ...  z_4       x_5       y_5  z_5
0   1       A      1  0.000000  ...  0.0  0.000000  0.000000  0.0
1   2       C      2  1.000000  ...  0.0  1.000000  0.000000  0.0
2   3       G      3 -1.930694  ...  0.0 -1.930694  2.862970  0.0
3   4       U      4 -5.791832  ...  0.0 -5.791832  2.284892  0.0
4   5       A      5 -8.769547  ...  0.0 -8.769547 -0.565381  0.0

[5 rows x 18 columns]


================================================================================
Output from: rna_predict/main.py
Timestamp: 2025-04-08 04:20:20
================================================================================

STDOUT:
Running demo_run_input_embedding()...
Now streaming the bprna-spot dataset...
Showing the full dataset structure for the first row...
Demo completed successfully.


================================================================================
Output from: rna_predict/print_rna_pipeline_output.py
Timestamp: 2025-04-08 04:20:20
================================================================================

STDOUT:
[2025-04-08 04:20:21,051] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to mps (auto detect)
Running RNA prediction pipeline on sequence: AUGCAUGG
Stage D available: True
q.shape: torch.Size([16, 8, 4]), k.shape: torch.Size([16, 8, 4]), v.shape: torch.Size([16, 8, 4])
q.shape: torch.Size([16, 8, 4]), k.shape: torch.Size([16, 8, 4]), v.shape: torch.Size([16, 8, 4])
[Debug] Tensor shapes for merger:
  adjacency: torch.Size([8, 8])
  torsion_angles: torch.Size([8, 32])
  s_emb: torch.Size([8, 64])
  z_emb: torch.Size([8, 8, 32])
[Debug] Creating MLP with dimensions: 128 -> 128
[DEBUG] Cached 'sing' as 's_inputs'
[DEBUG] s_trunk shape: torch.Size([1, 24, 64])
[DEBUG] s_inputs shape: torch.Size([1, 24, 449])
[DEBUG] z_trunk shape: torch.Size([1, 24, 24, 32])
[DEBUG] Before sample_diffusion:
  coords_init shape: torch.Size([1, 24, 3])
  s_trunk shape: torch.Size([1, 24, 64])
  s_inputs shape: torch.Size([1, 24, 449])
  z_trunk shape: torch.Size([1, 24, 24, 32])
[DEBUG] Determined true_batch_shape: torch.Size([1])
[DEBUG][Generator Loop 0] Before denoise_net - x_noisy: torch.Size([1, 1, 24, 3]), t_hat: torch.Size([1, 1])
[DEBUG PRE-CAT] z_trunk shape: torch.Size([1, 24, 24, 32]), relpe_output shape: torch.Size([1, 24, 24, 32])
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG AGG] a_atom shape: torch.Size([1, 1, 24, 768])
[DEBUG AGG] atom_to_token_idx shape: torch.Size([1, 24])
[DEBUG AGG] num_tokens: 24
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG][DiffusionModule.forward] Returning x_denoised shape: torch.Size([1, 1, 24, 3])
[DEBUG][Generator Loop 1] Before denoise_net - x_noisy: torch.Size([1, 1, 24, 3]), t_hat: torch.Size([1, 1])
[DEBUG PRE-CAT] z_trunk shape: torch.Size([1, 24, 24, 32]), relpe_output shape: torch.Size([1, 24, 24, 32])
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG AGG] a_atom shape: torch.Size([1, 1, 24, 768])
[DEBUG AGG] atom_to_token_idx shape: torch.Size([1, 24])
[DEBUG AGG] num_tokens: 24
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG][DiffusionModule.forward] Returning x_denoised shape: torch.Size([1, 1, 24, 3])
[DEBUG][Generator Loop 2] Before denoise_net - x_noisy: torch.Size([1, 1, 24, 3]), t_hat: torch.Size([1, 1])
[DEBUG PRE-CAT] z_trunk shape: torch.Size([1, 24, 24, 32]), relpe_output shape: torch.Size([1, 24, 24, 32])
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG AGG] a_atom shape: torch.Size([1, 1, 24, 768])
[DEBUG AGG] atom_to_token_idx shape: torch.Size([1, 24])
[DEBUG AGG] num_tokens: 24
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG][DiffusionModule.forward] Returning x_denoised shape: torch.Size([1, 1, 24, 3])
[DEBUG][Generator Loop 3] Before denoise_net - x_noisy: torch.Size([1, 1, 24, 3]), t_hat: torch.Size([1, 1])
[DEBUG PRE-CAT] z_trunk shape: torch.Size([1, 24, 24, 32]), relpe_output shape: torch.Size([1, 24, 24, 32])
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG AGG] a_atom shape: torch.Size([1, 1, 24, 768])
[DEBUG AGG] atom_to_token_idx shape: torch.Size([1, 24])
[DEBUG AGG] num_tokens: 24
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG][DiffusionModule.forward] Returning x_denoised shape: torch.Size([1, 1, 24, 3])
[DEBUG][Generator Loop 4] Before denoise_net - x_noisy: torch.Size([1, 1, 24, 3]), t_hat: torch.Size([1, 1])
[DEBUG PRE-CAT] z_trunk shape: torch.Size([1, 24, 24, 32]), relpe_output shape: torch.Size([1, 24, 24, 32])
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG AGG] a_atom shape: torch.Size([1, 1, 24, 768])
[DEBUG AGG] atom_to_token_idx shape: torch.Size([1, 24])
[DEBUG AGG] num_tokens: 24
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG][DiffusionModule.forward] Returning x_denoised shape: torch.Size([1, 1, 24, 3])
[DEBUG][Generator Loop 5] Before denoise_net - x_noisy: torch.Size([1, 1, 24, 3]), t_hat: torch.Size([1, 1])
[DEBUG PRE-CAT] z_trunk shape: torch.Size([1, 24, 24, 32]), relpe_output shape: torch.Size([1, 24, 24, 32])
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG AGG] a_atom shape: torch.Size([1, 1, 24, 768])
[DEBUG AGG] atom_to_token_idx shape: torch.Size([1, 24])
[DEBUG AGG] num_tokens: 24
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG][DiffusionModule.forward] Returning x_denoised shape: torch.Size([1, 1, 24, 3])
[DEBUG][Generator Loop 6] Before denoise_net - x_noisy: torch.Size([1, 1, 24, 3]), t_hat: torch.Size([1, 1])
[DEBUG PRE-CAT] z_trunk shape: torch.Size([1, 24, 24, 32]), relpe_output shape: torch.Size([1, 24, 24, 32])
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG AGG] a_atom shape: torch.Size([1, 1, 24, 768])
[DEBUG AGG] atom_to_token_idx shape: torch.Size([1, 24])
[DEBUG AGG] num_tokens: 24
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG][DiffusionModule.forward] Returning x_denoised shape: torch.Size([1, 1, 24, 3])
[DEBUG][Generator Loop 7] Before denoise_net - x_noisy: torch.Size([1, 1, 24, 3]), t_hat: torch.Size([1, 1])
[DEBUG PRE-CAT] z_trunk shape: torch.Size([1, 24, 24, 32]), relpe_output shape: torch.Size([1, 24, 24, 32])
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG AGG] a_atom shape: torch.Size([1, 1, 24, 768])
[DEBUG AGG] atom_to_token_idx shape: torch.Size([1, 24])
[DEBUG AGG] num_tokens: 24
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG][DiffusionModule.forward] Returning x_denoised shape: torch.Size([1, 1, 24, 3])
[DEBUG][Generator Loop 8] Before denoise_net - x_noisy: torch.Size([1, 1, 24, 3]), t_hat: torch.Size([1, 1])
[DEBUG PRE-CAT] z_trunk shape: torch.Size([1, 24, 24, 32]), relpe_output shape: torch.Size([1, 24, 24, 32])
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG AGG] a_atom shape: torch.Size([1, 1, 24, 768])
[DEBUG AGG] atom_to_token_idx shape: torch.Size([1, 24])
[DEBUG AGG] num_tokens: 24
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG][DiffusionModule.forward] Returning x_denoised shape: torch.Size([1, 1, 24, 3])
[DEBUG][Generator Loop 9] Before denoise_net - x_noisy: torch.Size([1, 1, 24, 3]), t_hat: torch.Size([1, 1])
[DEBUG PRE-CAT] z_trunk shape: torch.Size([1, 24, 24, 32]), relpe_output shape: torch.Size([1, 24, 24, 32])
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG AGG] a_atom shape: torch.Size([1, 1, 24, 768])
[DEBUG AGG] atom_to_token_idx shape: torch.Size([1, 24])
[DEBUG AGG] num_tokens: 24
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG][DiffusionModule.forward] Returning x_denoised shape: torch.Size([1, 1, 24, 3])
[DEBUG][Generator Loop 10] Before denoise_net - x_noisy: torch.Size([1, 1, 24, 3]), t_hat: torch.Size([1, 1])
[DEBUG PRE-CAT] z_trunk shape: torch.Size([1, 24, 24, 32]), relpe_output shape: torch.Size([1, 24, 24, 32])
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG AGG] a_atom shape: torch.Size([1, 1, 24, 768])
[DEBUG AGG] atom_to_token_idx shape: torch.Size([1, 24])
[DEBUG AGG] num_tokens: 24
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG][DiffusionModule.forward] Returning x_denoised shape: torch.Size([1, 1, 24, 3])
[DEBUG][Generator Loop 11] Before denoise_net - x_noisy: torch.Size([1, 1, 24, 3]), t_hat: torch.Size([1, 1])
[DEBUG PRE-CAT] z_trunk shape: torch.Size([1, 24, 24, 32]), relpe_output shape: torch.Size([1, 24, 24, 32])
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG AGG] a_atom shape: torch.Size([1, 1, 24, 768])
[DEBUG AGG] atom_to_token_idx shape: torch.Size([1, 24])
[DEBUG AGG] num_tokens: 24
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG][DiffusionModule.forward] Returning x_denoised shape: torch.Size([1, 1, 24, 3])
[DEBUG][Generator Loop 12] Before denoise_net - x_noisy: torch.Size([1, 1, 24, 3]), t_hat: torch.Size([1, 1])
[DEBUG PRE-CAT] z_trunk shape: torch.Size([1, 24, 24, 32]), relpe_output shape: torch.Size([1, 24, 24, 32])
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG AGG] a_atom shape: torch.Size([1, 1, 24, 768])
[DEBUG AGG] atom_to_token_idx shape: torch.Size([1, 24])
[DEBUG AGG] num_tokens: 24
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG][DiffusionModule.forward] Returning x_denoised shape: torch.Size([1, 1, 24, 3])
[DEBUG][Generator Loop 13] Before denoise_net - x_noisy: torch.Size([1, 1, 24, 3]), t_hat: torch.Size([1, 1])
[DEBUG PRE-CAT] z_trunk shape: torch.Size([1, 24, 24, 32]), relpe_output shape: torch.Size([1, 24, 24, 32])
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG AGG] a_atom shape: torch.Size([1, 1, 24, 768])
[DEBUG AGG] atom_to_token_idx shape: torch.Size([1, 24])
[DEBUG AGG] num_tokens: 24
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG][DiffusionModule.forward] Returning x_denoised shape: torch.Size([1, 1, 24, 3])
[DEBUG][Generator Loop 14] Before denoise_net - x_noisy: torch.Size([1, 1, 24, 3]), t_hat: torch.Size([1, 1])
[DEBUG PRE-CAT] z_trunk shape: torch.Size([1, 24, 24, 32]), relpe_output shape: torch.Size([1, 24, 24, 32])
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG AGG] a_atom shape: torch.Size([1, 1, 24, 768])
[DEBUG AGG] atom_to_token_idx shape: torch.Size([1, 24])
[DEBUG AGG] num_tokens: 24
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG][DiffusionModule.forward] Returning x_denoised shape: torch.Size([1, 1, 24, 3])
[DEBUG][Generator Loop 15] Before denoise_net - x_noisy: torch.Size([1, 1, 24, 3]), t_hat: torch.Size([1, 1])
[DEBUG PRE-CAT] z_trunk shape: torch.Size([1, 24, 24, 32]), relpe_output shape: torch.Size([1, 24, 24, 32])
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG AGG] a_atom shape: torch.Size([1, 1, 24, 768])
[DEBUG AGG] atom_to_token_idx shape: torch.Size([1, 24])
[DEBUG AGG] num_tokens: 24
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG][DiffusionModule.forward] Returning x_denoised shape: torch.Size([1, 1, 24, 3])
[DEBUG][Generator Loop 16] Before denoise_net - x_noisy: torch.Size([1, 1, 24, 3]), t_hat: torch.Size([1, 1])
[DEBUG PRE-CAT] z_trunk shape: torch.Size([1, 24, 24, 32]), relpe_output shape: torch.Size([1, 24, 24, 32])
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG AGG] a_atom shape: torch.Size([1, 1, 24, 768])
[DEBUG AGG] atom_to_token_idx shape: torch.Size([1, 24])
[DEBUG AGG] num_tokens: 24
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG][DiffusionModule.forward] Returning x_denoised shape: torch.Size([1, 1, 24, 3])
[DEBUG][Generator Loop 17] Before denoise_net - x_noisy: torch.Size([1, 1, 24, 3]), t_hat: torch.Size([1, 1])
[DEBUG PRE-CAT] z_trunk shape: torch.Size([1, 24, 24, 32]), relpe_output shape: torch.Size([1, 24, 24, 32])
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG AGG] a_atom shape: torch.Size([1, 1, 24, 768])
[DEBUG AGG] atom_to_token_idx shape: torch.Size([1, 24])
[DEBUG AGG] num_tokens: 24
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG][DiffusionModule.forward] Returning x_denoised shape: torch.Size([1, 1, 24, 3])
[DEBUG][Generator Loop 18] Before denoise_net - x_noisy: torch.Size([1, 1, 24, 3]), t_hat: torch.Size([1, 1])
[DEBUG PRE-CAT] z_trunk shape: torch.Size([1, 24, 24, 32]), relpe_output shape: torch.Size([1, 24, 24, 32])
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG AGG] a_atom shape: torch.Size([1, 1, 24, 768])
[DEBUG AGG] atom_to_token_idx shape: torch.Size([1, 24])
[DEBUG AGG] num_tokens: 24
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG][DiffusionModule.forward] Returning x_denoised shape: torch.Size([1, 1, 24, 3])
[DEBUG][Generator Loop 19] Before denoise_net - x_noisy: torch.Size([1, 1, 24, 3]), t_hat: torch.Size([1, 1])
[DEBUG PRE-CAT] z_trunk shape: torch.Size([1, 24, 24, 32]), relpe_output shape: torch.Size([1, 24, 24, 32])
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG AGG] a_atom shape: torch.Size([1, 1, 24, 768])
[DEBUG AGG] atom_to_token_idx shape: torch.Size([1, 24])
[DEBUG AGG] num_tokens: 24
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
Warning: Selected bias shape mismatch in _process_small_tensors. Expected size: 4, actual size: 1152 (from torch.Size([1, 1, 2, 24, 24])). Skipping bias application for stability.
[DEBUG][DiffusionModule.forward] Returning x_denoised shape: torch.Size([1, 1, 24, 3])
[DEBUG][sample_diffusion] Returning _chunk_sample_diffusion output shape: torch.Size([1, 1, 24, 3])
[DEBUG] After sample_diffusion:
  coords_final shape before squeeze: torch.Size([1, 1, 24, 3])
[DEBUG] Final coords_final shape (handling N_sample=1): torch.Size([1, 24, 3])
[DEBUG] After inference call: 's_inputs' in internal? True, 's_inputs' in original? False
[DEBUG] Copying cached 's_inputs' back to original dictionary.

--- Pipeline Output with Examples ---
  adjacency: shape=(8, 8)
  Example values: [[1.  0.8 0.  0.  0. , ...],
 [0.8 1.  0.8 0.  0. , ...],
 [0.  0.8 1.  0.8 0. , ...],
 [0.  0.  0.8 1.  0.8, ...],
 [0.  0.  0.  0.8 1. , ...],
  ...]

  torsion_angles: shape=(8, 32)
  Example values: [[ 0.1115 -0.4197 -0.8013  0.052   0.1078, ...],
 [ 0.1134 -0.4173 -0.7996  0.0517  0.1068, ...],
 [ 0.1145 -0.4215 -0.8004  0.0561  0.1121, ...],
 [ 0.1134 -0.4195 -0.8027  0.0519  0.1078, ...],
 [ 0.1156 -0.4322 -0.8058  0.0553  0.1171, ...],
  ...]

  s_embeddings: shape=(8, 64)
  Example values: [[ 1.3768 -1.3341  1.4607  0.5553 -0.3277, ...],
 [ 0.116   1.5895 -0.3712 -0.5584 -0.7241, ...],
 [ 1.1794 -1.9502  2.058   0.5528  1.1624, ...],
 [ 1.2487 -0.3409 -1.4988  0.3886  0.1273, ...],
 [ 0.1132  0.0289 -1.9271 -0.2907  1.3734, ...],
  ...]

  z_embeddings: shape=(8, 8, 32)
  Example values: First slice: [[ 9.9865586e-01  1.0023137e+00  1.0037416e+00  1.0100254e+00
   1.0110590e+00]
 [ 7.8815770e-01  7.9581714e-01  8.1203026e-01  7.9436237e-01
   8.0601925e-01]
 [ 3.5307112e-03 -5.8537852e-03  3.6094582e-03  8.4572220e-03
  -2.1261089e-03]
 [-4.1962615e-03  2.5407465e-03 -8.9950627e-03  5.9476483e-04
  -1.3187018e-03]
 [ 1.6022746e-02 -7.5559947e-03 -3.3749982e-03  7.7691451e-03
   6.0201031e-03]]

  partial_coords: shape=(1, 24, 3)
  Example values: First slice: [[0. 0. 0.]
 [0. 0. 0.]
 [0. 0. 0.]
 [0. 0. 0.]
 [0. 0. 0.]]

  unified_latent: shape=(8, 128)
  Example values: [[ 0.0947  0.0853  0.0416 -0.0712 -0.1406, ...],
 [-0.2321  0.0162 -0.0692 -0.314  -0.242 , ...],
 [-0.1354  0.311  -0.0728 -0.3027 -0.1641, ...],
 [ 0.1386  0.394   0.0039 -0.0696 -0.2674, ...],
 [ 0.1886  0.3607 -0.1226 -0.1297 -0.1553, ...],
  ...]

  final_coords: shape=(1, 24, 3)
  Example values: First slice: [[-17587.04     7957.8687    298.9839]
 [ -1968.7919   1115.8903   3882.69  ]
 [  -563.11     3840.3645  -4582.777 ]
 [  1976.9454   2013.9163  -4547.1157]
 [ 12662.3125 -11725.589    5778.773 ]]

Done.
STDERR:
W0408 04:20:21.647000 8676640832 torch/distributed/elastic/multiprocessing/redirects.py:27] NOTE: Redirects are currently not supported in Windows or MacOs.
/Users/tomriddle1/RNA_PREDICT/rna_predict/pipeline/stageD/diffusion/run_stageD_unified.py:182: UserWarning: input_features not provided, using basic fallback based on partial_coords.
  warnings.warn(
/Users/tomriddle1/RNA_PREDICT/rna_predict/pipeline/stageD/diffusion/run_stageD_unified.py:58: UserWarning: Adjusting sequence length for s_trunk from 8 to 24
  warnings.warn(
/Users/tomriddle1/RNA_PREDICT/rna_predict/pipeline/stageD/diffusion/run_stageD_unified.py:88: UserWarning: Adjusting sequence lengths for pair from (8, 8) to (24, 24)
  warnings.warn(
/Users/tomriddle1/RNA_PREDICT/rna_predict/pipeline/stageA/input_embedding/current/transformer/encoder_components/feature_processing.py:199: UserWarning: ref_space_uid has wrong shape torch.Size([1, 24]), expected [..., 3]. Setting to zeros.
  warnings.warn(
/Users/tomriddle1/RNA_PREDICT/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/Users/tomriddle1/RNA_PREDICT/rna_predict/pipeline/stageA/input_embedding/current/transformer/atom_attention_decoder.py:173: UserWarning: Conditioning signal 's' has incorrect feature dim 128, expected 64. Adapting.
  warnings.warn(

