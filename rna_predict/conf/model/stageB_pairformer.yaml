# rna_predict/conf/model/stageB_pairformer.yaml

defaults:
  - _self_
  - protenix_integration@protenix_integration

# Core model parameters
n_blocks: 1                 # Minimal number of Pairformer blocks
n_heads: 1                  # Minimal number of attention heads
c_z: 2                      # Minimal pair representation dimension
c_token: 384                # Token representation dimension
c_atom: 128                 # Atom representation dimension
c_pair: 32                  # Pair representation dimension
dropout: 0.0                # Top-level dropout for Pairformer
freeze_params: false

device: ${device}  # Inherit from global device setting

protenix_integration:
  c_token: 2
  restype_dim: 2
  profile_dim: 2
  c_atom: 2
  c_pair: 2
  num_heads: 1
  num_layers: 1
  r_max: 2
  s_max: 2
  use_optimized: false

# Pair stack config
c_s: 0  # No single representation in pair stack; set here for clarity and Hydra best practice

# MSA parameters (minimal values, disabled)
msa:
  c_m: 2                    # Minimal hidden dimension for MSA embedding
  c: 2                      # Minimal hidden dimension for MSA components
  c_z: 2                    # Minimal hidden dimension for pair embedding
  dropout: 0.0              # No dropout for MSA components
  n_blocks: 1               # Minimal number of MSA blocks
  enable: false             # Whether to use MSA embedding
  strategy: random          # Strategy for MSA sampling
  train_cutoff: 1           # Minimal MSA sample cutoff during training
  test_cutoff: 1            # Minimal MSA sample cutoff during testing
  train_lowerb: 1           # Minimum MSA sample size during training
  test_lowerb: 1            # Minimum MSA sample size during testing
  n_heads: 1                # Minimal number of attention heads for MSA pair weighted averaging
  pair_dropout: 0.0         # No dropout for pair stack in MSA block
  c_s_inputs: 2             # Minimal hidden dimension for single embedding from InputFeatureEmbedder
  blocks_per_ckpt: 1        # Minimal number of MSA blocks in each activation checkpoint
  input_feature_dims:
    msa: 2
    has_deletion: 1
    deletion_value: 1

# Template parameters (minimal values, disabled)
template:
  n_blocks: 1                # Minimal number of blocks for TemplateEmbedder
  c: 2                       # Minimal hidden dimension of TemplateEmbedder
  c_z: 2                     # Minimal hidden dimension for pair embedding
  dropout: 0.0               # No dropout for PairformerStack
  blocks_per_ckpt: null      # Number of blocks per checkpoint, null for no checkpointing
  input_feature_dims:
    feature1:
      template_distogram: 1
      b_template_backbone_frame_mask: 1
      template_unit_vector: 1
      b_template_pseudo_beta_mask: 1
    feature2:
      template_restype_i: 1
      template_restype_j: 1
  distogram:
    max_bin: 1
    min_bin: 1
    no_bins: 1

# Memory optimization flags
use_memory_efficient_kernel: false # Default memory optimization setting
use_deepspeed_evo_attention: false
use_lma: false
inplace_safe: false
chunk_size: null             # Default chunk size for attention

# Triangle Attention parameters
c_hidden_mul: 1
c_hidden_pair_att: 2
no_heads_pair: 1

# Adjacency logic (keep default as false)
init_z_from_adjacency: false

# Debug logging for Pairformer (added for testing/logging control)
debug_logging: false  # [UNIQUE-ERR-STAGEB-DEBUGLOGGING-001] Default off for test override compatibility

# Optional LoRA configuration
lora:
  enabled: false
  r: 1
  alpha: 1
  dropout: 0.0
  target_modules:
    - query
    - value
