"""
test_run_full_pipeline.py

A comprehensive test suite validating the functionality of `run_full_pipeline`
and `SimpleLatentMerger` in `run_full_pipeline.py`. It unifies the best practices
from multiple versions of tests (V1â€“V5) while addressing their criticisms:

1. Detailed documentation and clear docstrings throughout.
2. Coverage of normal, error, and edge-case scenarios.
3. Property-based testing with Hypothesis for dimension fuzzing and sequence randomness.
4. Mocks to isolate external dependencies (Stage D).
5. Thorough checking of final outputs, shapes, and expected errors.

To run:
    python -m unittest test_run_full_pipeline.py

You can also measure coverage (e.g., with pytest-cov or coverage.py) to ensure
this suite meets your desired coverage goals.
"""

import unittest
from unittest.mock import MagicMock, patch

import numpy as np
import torch

# Hypothesis for property-based (fuzz) testing
from hypothesis import HealthCheck, assume, given, reject, settings
from hypothesis import strategies as st

# Import target items from your pipeline code
from rna_predict.run_full_pipeline import SimpleLatentMerger, run_full_pipeline


# =============================================================================
#                                SimpleLatentMerger Tests
# =============================================================================
class TestSimpleLatentMerger(unittest.TestCase):
    """
    Comprehensive tests for the SimpleLatentMerger class, ensuring that:
      - Constructor handles initialization and dimension tracking.
      - Forward pass merges adjacency, angles, single embeddings, pair embeddings,
        plus optional partial coordinates.
      - MLP internally reinitializes if dimension changes are detected.
      - Hypothesis-based tests verify robust handling of random dimension shapes.
    """

    def setUp(self):
        """
        Create a default instance of SimpleLatentMerger for repeated usage.
        By default, we choose dim_angles=5, dim_s=6, dim_z=7, and dim_out=10.
        """
        self.dim_angles = 5
        self.dim_s = 6
        self.dim_z = 7
        self.dim_out = 10

        # Instantiate the merger on CPU for simplicity
        self.merger = SimpleLatentMerger(
            dim_angles=self.dim_angles,
            dim_s=self.dim_s,
            dim_z=self.dim_z,
            dim_out=self.dim_out,
        ).to("cpu")

    def test_constructor_fields(self):
        """
        Confirm that the constructor sets each dimension field appropriately
        and that the initial MLP exists.
        """
        self.assertEqual(self.merger.expected_dim_angles, self.dim_angles)
        self.assertEqual(self.merger.expected_dim_s, self.dim_s)
        self.assertEqual(self.merger.expected_dim_z, self.dim_z)
        self.assertEqual(self.merger.dim_out, self.dim_out)
        self.assertIsNotNone(
            self.merger.mlp, "MLP submodule should be defined in constructor"
        )

    def test_forward_normal_usage(self):
        """
        Test a forward pass in normal usage with consistent input shapes,
        verifying the output shape is (N, dim_out) and that it doesn't contain NaNs.
        """
        N = 4  # number of residues
        adjacency = torch.rand((N, N), dtype=torch.float32)
        angles = torch.rand((N, self.dim_angles), dtype=torch.float32)
        s_emb = torch.rand((N, self.dim_s), dtype=torch.float32)
        z_emb = torch.rand((N, N, self.dim_z), dtype=torch.float32)
        partial_coords = torch.rand((N, 3), dtype=torch.float32)

        output = self.merger(
            adjacency=adjacency,
            angles=angles,
            s_emb=s_emb,
            z_emb=z_emb,
            partial_coords=partial_coords,
        )
        self.assertEqual(output.shape, (N, self.dim_out), "Output shape mismatch")
        self.assertFalse(
            torch.isnan(output).any(), "Output contains NaNs, unexpected behavior"
        )

    def test_forward_device_relocation(self):
        """
        If the MLP is on CPU but input tensors are (supposedly) on another device,
        the code logic moves the MLP to match the angles' device.
        Here, we only run CPU vs. CPU, but confirm no crash occurs.
        """
        N = 2
        adjacency = torch.rand((N, N))
        angles = torch.rand((N, self.dim_angles))
        s_emb = torch.rand((N, self.dim_s))
        z_emb = torch.rand((N, N, self.dim_z))

        # This should not fail; MLP will be moved if needed
        out = self.merger(adjacency, angles, s_emb, z_emb)
        self.assertEqual(out.shape, (N, self.dim_out))

    @given(
        N=st.integers(min_value=1, max_value=5),
        dim_angles=st.integers(min_value=1, max_value=8),
        dim_s=st.integers(min_value=1, max_value=8),
        dim_z=st.integers(min_value=1, max_value=8),
        dim_out=st.integers(min_value=1, max_value=16),
    )
    @settings(deadline=None, suppress_health_check=[HealthCheck.filter_too_much, HealthCheck.too_slow])
    def test_forward_hypothesis_fuzz(self, N, dim_angles, dim_s, dim_z, dim_out):
        """
        Fuzz test: random shapes for adjacency, angles, s_emb, z_emb, verifying
        that forward() returns the correct shape (N, dim_out) or handles shape issues.
        """
        merger = SimpleLatentMerger(dim_angles, dim_s, dim_z, dim_out)
        adjacency = torch.rand((N, N))
        angles = torch.rand((N, dim_angles))
        s_emb = torch.rand((N, dim_s))
        z_emb = torch.rand((N, N, dim_z))

        try:
            output = merger(
                adjacency=adjacency,
                angles=angles,
                s_emb=s_emb,
                z_emb=z_emb,
            )
            self.assertEqual(output.shape, (N, dim_out))
        except RuntimeError:
            # In case of shape mismatch or reinit issues, we handle it gracefully
            reject()


# =============================================================================
#                            run_full_pipeline Tests
# =============================================================================
class TestRunFullPipeline(unittest.TestCase):
    """
    Tests for the run_full_pipeline function, orchestrating:
      Stage A adjacency -> Stage B torsion and pair embeddings -> optional Stage C ->
      optional merging -> optional Stage D.
    Includes edge cases like empty sequences, invalid device, missing config keys,
    plus property-based fuzzing of sequences.
    """

    def setUp(self):
        """
        Create a default minimal config that includes:
          - A dummy StageA predictor
          - Dummy Torsion and Pairformer models
          - No Stage C, merging, or Stage D by default (those are toggled as needed).
        """

        class DummyStageAPredictor:
            def predict_adjacency(self, seq: str) -> np.ndarray:
                N = len(seq)
                arr = np.eye(N, dtype=np.float32)
                # Add an off-diagonal link if N > 1
                if N > 1:
                    arr[0, 1] = arr[1, 0] = 1.0
                return arr

        class DummyTorsionModel(torch.nn.Module):
            def __init__(self):
                super().__init__()
                self.c_s = 64  # Single-residue embedding dimension
                self.c_z = 32  # Pair embedding dimension

            def forward(self, sequence, adjacency=None):
                # Return (torsion angles, single-res embeddings)
                N = len(sequence)
                angles = torch.zeros((N, 7))
                s_emb = torch.zeros((N, self.c_s))
                return {"torsion_angles": angles, "s_embeddings": s_emb}

            def __call__(self, sequence, adjacency=None):
                return self.forward(sequence, adjacency)

        class DummyPairformerModel(torch.nn.Module):
            def __init__(self):
                super().__init__()
                self.c_s = 64  # Single-residue embedding dimension
                self.c_z = 32  # Pair embedding dimension

            def forward(self, init_s, init_z, pair_mask=None):
                # Return (s_up, z_up) where:
                # s_up: shape (1, N, c_s)
                # z_up: shape (1, N, N, c_z)
                N = init_s.shape[1]
                s_up = torch.zeros((1, N, self.c_s))
                z_up = torch.zeros((1, N, N, self.c_z))
                return s_up, z_up

            def __call__(self, init_s, init_z, pair_mask=None):
                return self.forward(init_s, init_z, pair_mask)

        self.default_config = {
            "stageA_predictor": DummyStageAPredictor(),
            "torsion_bert_model": DummyTorsionModel(),
            "pairformer_model": DummyPairformerModel(),
            "enable_stageC": False,
            "init_z_from_adjacency": False,
            "merge_latent": False,
            "run_stageD": False,
        }

    def test_basic_pipeline_run(self):
        """
        Basic test with the default config.
        Ensures we get adjacency, torsion_angles, s_embeddings, z_embeddings, and None for optional outputs.
        """
        seq = "AUGC"
        result = run_full_pipeline(seq, self.default_config, device="cpu")

        self.assertIn("adjacency", result)
        self.assertIn("torsion_angles", result)
        self.assertIn("s_embeddings", result)
        self.assertIn("z_embeddings", result)
        self.assertIsNone(
            result["partial_coords"],
            "Stage C is disabled, partial_coords should be None",
        )
        self.assertIsNone(
            result["unified_latent"], "Merging disabled, unified_latent should be None"
        )
        self.assertIsNone(
            result["final_coords"], "Stage D disabled, final_coords should be None"
        )

        N = len(seq)
        self.assertEqual(result["adjacency"].shape, (N, N))
        self.assertEqual(result["torsion_angles"].shape, (N, 7))
        self.assertEqual(result["s_embeddings"].shape, (N, 64))
        self.assertEqual(result["z_embeddings"].shape, (N, N, 32))

    def test_empty_sequence(self):
        """
        Edge case: an empty sequence.
        The function should return zero-sized adjacency, angles, embeddings, etc.
        """
        seq = ""
        result = run_full_pipeline(seq, self.default_config, device="cpu")

        self.assertEqual(result["adjacency"].shape, (0, 0))
        self.assertEqual(result["torsion_angles"].shape, (0, 7))
        self.assertEqual(result["s_embeddings"].shape, (0, 64))
        self.assertEqual(result["z_embeddings"].shape, (0, 0, 32))
        self.assertIsNone(result["partial_coords"])
        self.assertIsNone(result["unified_latent"])
        self.assertIsNone(result["final_coords"])

    def test_invalid_device_raises(self):
        """
        Attempting to run the pipeline on an invalid device string should raise a PyTorch RuntimeError.
        """
        seq = "AUGC"
        with self.assertRaises(RuntimeError):
            run_full_pipeline(seq, self.default_config, device="invalid_device")

    def test_missing_stageA_predictor_raises(self):
        """
        If 'stageA_predictor' is absent, the pipeline must raise a ValueError.
        """
        cfg = dict(self.default_config)
        del cfg["stageA_predictor"]
        with self.assertRaises(ValueError) as ctx:
            run_full_pipeline("AUGC", cfg, device="cpu")
        self.assertIn("stageA_predictor", str(ctx.exception))

    def test_missing_torsion_model_raises(self):
        """
        If 'torsion_bert_model' is absent, the pipeline must raise ValueError.
        """
        cfg = dict(self.default_config)
        del cfg["torsion_bert_model"]
        with self.assertRaises(ValueError) as ctx:
            run_full_pipeline("AUGC", cfg, device="cpu")
        self.assertIn("torsion_bert_model", str(ctx.exception))

    def test_missing_pairformer_model_raises(self):
        """
        If 'pairformer_model' is absent, the pipeline must raise ValueError.
        """
        cfg = dict(self.default_config)
        del cfg["pairformer_model"]
        with self.assertRaises(ValueError) as ctx:
            run_full_pipeline("AUGC", cfg, device="cpu")
        self.assertIn("pairformer_model", str(ctx.exception))

    def test_merge_latent_no_merger_raises(self):
        """
        If merge_latent=True but no 'merger' object is provided, pipeline raises ValueError.
        """
        cfg = dict(self.default_config)
        cfg["merge_latent"] = True  # no merger
        with self.assertRaises(ValueError) as ctx:
            run_full_pipeline("AUGC", cfg, device="cpu")
        self.assertIn("no 'merger' object provided", str(ctx.exception))

    def test_enable_stageC_produces_coords(self):
        """
        With Stage C enabled, partial_coords should be a non-None tensor.
        We mock StageCReconstruction to control what gets returned.
        """
        seq = "AUGC"
        cfg = dict(self.default_config)
        cfg["enable_stageC"] = True

        with patch("rna_predict.run_full_pipeline.StageCReconstruction") as mock_stageC:
            mock_instance = MagicMock()
            # Suppose it returns (N, 3) coords
            mock_instance.return_value = {"coords": torch.zeros((4, 3))}
            mock_stageC.return_value = mock_instance

            result = run_full_pipeline(seq, cfg, device="cpu")
            self.assertIsNotNone(result["partial_coords"])
            self.assertEqual(result["partial_coords"].shape, (4, 3))

    def test_merge_latent_with_merger(self):
        """
        If merge_latent=True and a valid 'merger' object is provided,
        the pipeline should produce a unified_latent tensor.
        """
        seq = "AUGC"
        cfg = dict(self.default_config)
        cfg["merge_latent"] = True
        cfg["merger"] = SimpleLatentMerger(
            dim_angles=7, dim_s=64, dim_z=32, dim_out=128
        )

        result = run_full_pipeline(seq, cfg, device="cpu")
        self.assertIsNotNone(result["unified_latent"])
        self.assertEqual(result["unified_latent"].shape, (4, 128))

    def test_run_stageD_no_manager_raises(self):
        """
        If run_stageD=True but no 'diffusion_manager' is provided, pipeline raises ValueError.
        """
        seq = "AUGC"
        cfg = dict(self.default_config)
        cfg["run_stageD"] = True
        with self.assertRaises(ValueError) as ctx:
            run_full_pipeline(seq, cfg, device="cpu")
        self.assertIn("diffusion_manager", str(ctx.exception))

    def test_run_stageD_with_mock(self):
        """
        If run_stageD=True and a mock diffusion_manager is provided,
        final_coords should not be None, and the run_stageD_diffusion call is triggered.
        """
        seq = "AUGC"
        cfg = dict(self.default_config)
        cfg["run_stageD"] = True
        cfg["diffusion_manager"] = MagicMock()
        cfg["stageD_config"] = {}

        with (
            patch("rna_predict.run_full_pipeline.STAGE_D_AVAILABLE", True),
            patch(
                "rna_predict.run_full_pipeline.run_stageD_diffusion",
                return_value=torch.ones((1, 20, 3)),
            ),
        ):
            result = run_full_pipeline(seq, cfg, device="cpu")
            self.assertIsNotNone(result["final_coords"])
            self.assertEqual(result["final_coords"].shape, (1, 20, 3))

    @given(sequence=st.text(min_size=1, max_size=10))
    @settings(
        deadline=None,
        suppress_health_check=[HealthCheck.too_slow, HealthCheck.filter_too_much],
    )
    def test_fuzz_pipeline_random_sequences(self, sequence):
        """
        Property-based test that tries random short sequences (1-10 chars).
        We'll skip if it's empty or purely whitespace, but otherwise we run the pipeline.
        """
        assume(len(sequence.strip()) > 0)
        cfg = dict(self.default_config)
        try:
            result = run_full_pipeline(sequence, cfg, device="cpu")
            self.assertIn("adjacency", result)
        except ValueError as e:
            # If there's a known config error, it's acceptable; otherwise we reject.
            known_config_errors = [
                "stageA_predictor",
                "torsion_bert_model",
                "pairformer_model",
                "diffusion_manager",
            ]
            msg = str(e)
            if not any(k in msg for k in known_config_errors):
                reject()


# -----------------------------------------------------------------------------
#                   End of Consolidated, Verbose Test Suite
# -----------------------------------------------------------------------------
if __name__ == "__main__":
    # Execute all tests from this file using the standard unittest runner.
    unittest.main()
